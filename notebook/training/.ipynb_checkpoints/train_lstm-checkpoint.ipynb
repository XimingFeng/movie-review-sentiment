{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.lstm import lstm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data exists, load directly from pickle file\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_classifier(num_wds=200, \n",
    "                        embed_size=300,\n",
    "                        lstm_size=128, \n",
    "                        dense_size=[1024, 256], \n",
    "                        class_num=2, \n",
    "                        learning_rate=0.0003,\n",
    "                        batch_size=256, \n",
    "                        keep_prob=0.5\n",
    "                        root_dir=module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sample, y_sample = lstm_model.data_helper.get_next_batch(epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.805246, accuracy: 0.558594\n",
      "Training loss: 1.03323, accuracy: 0.4375\n",
      "Training loss: 0.635367, accuracy: 0.496094\n",
      "Training loss: 0.606268, accuracy: 0.621094\n",
      "Training loss: 0.625849, accuracy: 0.621094\n",
      "Training loss: 0.621216, accuracy: 0.621094\n",
      "Training loss: 0.609152, accuracy: 0.621094\n",
      "Training loss: 0.599064, accuracy: 0.621094\n",
      "Training loss: 0.596206, accuracy: 0.621094\n",
      "Training loss: 0.598596, accuracy: 0.628906\n",
      "Training loss: 0.596784, accuracy: 0.640625\n",
      "Training loss: 0.592813, accuracy: 0.640625\n",
      "Training loss: 0.590457, accuracy: 0.632813\n",
      "Training loss: 0.589878, accuracy: 0.628906\n",
      "Training loss: 0.589674, accuracy: 0.632813\n",
      "Training loss: 0.588365, accuracy: 0.636719\n",
      "Training loss: 0.586017, accuracy: 0.636719\n",
      "Training loss: 0.583895, accuracy: 0.636719\n",
      "Training loss: 0.583496, accuracy: 0.632813\n",
      "Training loss: 0.583137, accuracy: 0.632813\n",
      "Training loss: 0.580644, accuracy: 0.636719\n",
      "Training loss: 0.578265, accuracy: 0.640625\n",
      "Training loss: 0.57861, accuracy: 0.636719\n",
      "Training loss: 0.576126, accuracy: 0.640625\n",
      "Training loss: 0.574288, accuracy: 0.636719\n",
      "Training loss: 0.573359, accuracy: 0.640625\n",
      "Training loss: 0.570346, accuracy: 0.640625\n",
      "Training loss: 0.568963, accuracy: 0.648438\n",
      "Training loss: 0.56753, accuracy: 0.648438\n",
      "Training loss: 0.564856, accuracy: 0.648438\n",
      "Training loss: 0.563875, accuracy: 0.648438\n",
      "Training loss: 0.561308, accuracy: 0.648438\n",
      "Training loss: 0.559371, accuracy: 0.652344\n",
      "Training loss: 0.557659, accuracy: 0.65625\n",
      "Training loss: 0.555143, accuracy: 0.65625\n",
      "Training loss: 0.553578, accuracy: 0.648438\n",
      "Training loss: 0.550924, accuracy: 0.652344\n",
      "Training loss: 0.548651, accuracy: 0.652344\n",
      "Training loss: 0.545834, accuracy: 0.65625\n",
      "Training loss: 0.542416, accuracy: 0.65625\n",
      "Training loss: 0.539528, accuracy: 0.660156\n",
      "Training loss: 0.535068, accuracy: 0.660156\n",
      "Training loss: 0.530353, accuracy: 0.65625\n",
      "Training loss: 0.527346, accuracy: 0.652344\n",
      "Training loss: 0.540447, accuracy: 0.667969\n",
      "Training loss: 0.533967, accuracy: 0.617188\n",
      "Training loss: 0.519113, accuracy: 0.683594\n",
      "Training loss: 0.521054, accuracy: 0.664063\n",
      "Training loss: 0.516663, accuracy: 0.667969\n",
      "Training loss: 0.504357, accuracy: 0.699219\n",
      "Training loss: 0.499338, accuracy: 0.671875\n",
      "Training loss: 0.505003, accuracy: 0.6875\n",
      "Training loss: 0.512262, accuracy: 0.667969\n",
      "Training loss: 0.481735, accuracy: 0.683594\n",
      "Training loss: 0.501172, accuracy: 0.683594\n",
      "Training loss: 0.484316, accuracy: 0.683594\n",
      "Training loss: 0.478471, accuracy: 0.683594\n",
      "Training loss: 0.483123, accuracy: 0.691406\n",
      "Training loss: 0.459666, accuracy: 0.730469\n",
      "Training loss: 0.471645, accuracy: 0.707031\n",
      "Training loss: 0.443774, accuracy: 0.75\n",
      "Training loss: 0.457798, accuracy: 0.71875\n",
      "Training loss: 0.435417, accuracy: 0.761719\n",
      "Training loss: 0.427868, accuracy: 0.765625\n",
      "----------------- Step 0: validation accuracy 0.51584 ----------------\n",
      "Training loss: 1.32404, accuracy: 0.53125\n",
      "Training loss: 0.939361, accuracy: 0.53125\n",
      "Training loss: 0.687515, accuracy: 0.570313\n",
      "Training loss: 0.614495, accuracy: 0.585938\n",
      "Training loss: 0.59127, accuracy: 0.5625\n",
      "Training loss: 0.581566, accuracy: 0.605469\n",
      "Training loss: 0.578894, accuracy: 0.617188\n",
      "Training loss: 0.58093, accuracy: 0.617188\n",
      "Training loss: 0.58467, accuracy: 0.621094\n",
      "Training loss: 0.579024, accuracy: 0.613281\n",
      "Training loss: 0.574472, accuracy: 0.636719\n",
      "Training loss: 0.573255, accuracy: 0.644531\n",
      "Training loss: 0.572557, accuracy: 0.640625\n",
      "Training loss: 0.570991, accuracy: 0.640625\n",
      "Training loss: 0.568418, accuracy: 0.644531\n",
      "Training loss: 0.565967, accuracy: 0.644531\n",
      "Training loss: 0.56358, accuracy: 0.648438\n",
      "Training loss: 0.563192, accuracy: 0.644531\n",
      "Training loss: 0.561757, accuracy: 0.648438\n",
      "Training loss: 0.559661, accuracy: 0.644531\n",
      "Training loss: 0.558152, accuracy: 0.644531\n",
      "Training loss: 0.556031, accuracy: 0.652344\n",
      "Training loss: 0.55487, accuracy: 0.648438\n",
      "Training loss: 0.553868, accuracy: 0.636719\n",
      "Training loss: 0.551549, accuracy: 0.648438\n",
      "Training loss: 0.549857, accuracy: 0.65625\n",
      "Training loss: 0.547912, accuracy: 0.65625\n",
      "Training loss: 0.546459, accuracy: 0.652344\n",
      "Training loss: 0.543678, accuracy: 0.652344\n",
      "Training loss: 0.54065, accuracy: 0.652344\n",
      "Training loss: 0.537542, accuracy: 0.648438\n",
      "Training loss: 0.539398, accuracy: 0.660156\n",
      "Training loss: 0.568893, accuracy: 0.585938\n",
      "Training loss: 0.539206, accuracy: 0.667969\n",
      "Training loss: 0.54251, accuracy: 0.667969\n",
      "Training loss: 0.535838, accuracy: 0.667969\n",
      "Training loss: 0.540732, accuracy: 0.625\n",
      "Training loss: 0.537231, accuracy: 0.636719\n",
      "Training loss: 0.526179, accuracy: 0.660156\n",
      "Training loss: 0.529802, accuracy: 0.671875\n",
      "Training loss: 0.513622, accuracy: 0.667969\n",
      "Training loss: 0.518073, accuracy: 0.675781\n",
      "Training loss: 0.507818, accuracy: 0.667969\n",
      "Training loss: 0.510137, accuracy: 0.671875\n",
      "Training loss: 0.52321, accuracy: 0.652344\n",
      "Training loss: 0.511537, accuracy: 0.667969\n",
      "Training loss: 0.501903, accuracy: 0.675781\n",
      "Training loss: 0.499758, accuracy: 0.675781\n",
      "Training loss: 0.503461, accuracy: 0.683594\n",
      "Training loss: 0.495462, accuracy: 0.675781\n",
      "Training loss: 0.497397, accuracy: 0.667969\n",
      "Training loss: 0.482471, accuracy: 0.679688\n",
      "Training loss: 0.486721, accuracy: 0.703125\n",
      "Training loss: 0.475479, accuracy: 0.6875\n",
      "Training loss: 0.472584, accuracy: 0.695313\n",
      "Training loss: 0.472888, accuracy: 0.691406\n",
      "Training loss: 0.462499, accuracy: 0.714844\n",
      "Training loss: 0.472109, accuracy: 0.710938\n",
      "Training loss: 0.483368, accuracy: 0.691406\n",
      "Training loss: 0.455682, accuracy: 0.691406\n",
      "Training loss: 0.479983, accuracy: 0.695313\n",
      "Training loss: 0.485279, accuracy: 0.714844\n",
      "Training loss: 0.468564, accuracy: 0.699219\n",
      "Training loss: 0.497107, accuracy: 0.6875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.992369, accuracy: 0.515625\n",
      "Training loss: 0.802526, accuracy: 0.554688\n",
      "Training loss: 0.605192, accuracy: 0.582031\n",
      "Training loss: 0.592014, accuracy: 0.574219\n",
      "Training loss: 0.608929, accuracy: 0.574219\n",
      "Training loss: 0.610075, accuracy: 0.574219\n",
      "Training loss: 0.600574, accuracy: 0.574219\n",
      "Training loss: 0.590811, accuracy: 0.574219\n",
      "Training loss: 0.585307, accuracy: 0.59375\n",
      "Training loss: 0.584745, accuracy: 0.597656\n",
      "Training loss: 0.586459, accuracy: 0.601563\n",
      "Training loss: 0.586515, accuracy: 0.601563\n",
      "Training loss: 0.584708, accuracy: 0.601563\n",
      "Training loss: 0.582322, accuracy: 0.601563\n",
      "Training loss: 0.580334, accuracy: 0.609375\n",
      "Training loss: 0.579281, accuracy: 0.601563\n",
      "Training loss: 0.578951, accuracy: 0.609375\n",
      "Training loss: 0.578474, accuracy: 0.601563\n",
      "Training loss: 0.577259, accuracy: 0.605469\n",
      "Training loss: 0.575333, accuracy: 0.605469\n",
      "Training loss: 0.572692, accuracy: 0.613281\n",
      "Training loss: 0.569968, accuracy: 0.605469\n",
      "Training loss: 0.567388, accuracy: 0.625\n",
      "Training loss: 0.564885, accuracy: 0.617188\n",
      "Training loss: 0.562016, accuracy: 0.625\n",
      "Training loss: 0.5585, accuracy: 0.625\n",
      "Training loss: 0.554114, accuracy: 0.636719\n",
      "Training loss: 0.549345, accuracy: 0.617188\n",
      "Training loss: 0.545561, accuracy: 0.605469\n",
      "Training loss: 0.543408, accuracy: 0.613281\n",
      "Training loss: 0.537153, accuracy: 0.660156\n",
      "Training loss: 0.53519, accuracy: 0.640625\n",
      "Training loss: 0.53246, accuracy: 0.640625\n",
      "Training loss: 0.52804, accuracy: 0.6875\n",
      "Training loss: 0.527696, accuracy: 0.65625\n",
      "Training loss: 0.522274, accuracy: 0.671875\n",
      "Training loss: 0.52005, accuracy: 0.660156\n",
      "Training loss: 0.514362, accuracy: 0.710938\n",
      "Training loss: 0.510912, accuracy: 0.679688\n",
      "Training loss: 0.505274, accuracy: 0.675781\n",
      "Training loss: 0.49942, accuracy: 0.703125\n",
      "Training loss: 0.49538, accuracy: 0.695313\n",
      "Training loss: 0.487396, accuracy: 0.714844\n",
      "Training loss: 0.478928, accuracy: 0.761719\n",
      "Training loss: 0.471548, accuracy: 0.746094\n",
      "Training loss: 0.478738, accuracy: 0.703125\n",
      "Training loss: 0.571023, accuracy: 0.671875\n",
      "Training loss: 0.447275, accuracy: 0.78125\n",
      "Training loss: 0.520386, accuracy: 0.683594\n",
      "Training loss: 0.454133, accuracy: 0.734375\n",
      "Training loss: 0.480423, accuracy: 0.699219\n",
      "Training loss: 0.48464, accuracy: 0.699219\n",
      "Training loss: 0.462929, accuracy: 0.742188\n",
      "Training loss: 0.44293, accuracy: 0.734375\n",
      "Training loss: 0.467406, accuracy: 0.722656\n",
      "Training loss: 0.418088, accuracy: 0.789063\n",
      "Training loss: 0.431641, accuracy: 0.738281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.388689, accuracy: 0.820313\n",
      "Training loss: 0.436671, accuracy: 0.773438\n",
      "Training loss: 0.357111, accuracy: 0.832031\n",
      "Training loss: 0.37669, accuracy: 0.777344\n",
      "Training loss: 0.332328, accuracy: 0.855469\n",
      "Training loss: 0.34311, accuracy: 0.824219\n",
      "Training loss: 0.312926, accuracy: 0.859375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.1667, accuracy: 0.550781\n",
      "Training loss: 0.870234, accuracy: 0.558594\n",
      "Training loss: 0.635076, accuracy: 0.617188\n",
      "Training loss: 0.580193, accuracy: 0.644531\n",
      "Training loss: 0.572555, accuracy: 0.660156\n",
      "Training loss: 0.558535, accuracy: 0.675781\n",
      "Training loss: 0.547367, accuracy: 0.671875\n",
      "Training loss: 0.54412, accuracy: 0.679688\n",
      "Training loss: 0.543065, accuracy: 0.699219\n",
      "Training loss: 0.539466, accuracy: 0.726563\n",
      "Training loss: 0.533476, accuracy: 0.710938\n",
      "Training loss: 0.526099, accuracy: 0.699219\n",
      "Training loss: 0.517686, accuracy: 0.691406\n",
      "Training loss: 0.510303, accuracy: 0.695313\n",
      "Training loss: 0.503546, accuracy: 0.703125\n",
      "Training loss: 0.496265, accuracy: 0.707031\n",
      "Training loss: 0.486946, accuracy: 0.738281\n",
      "Training loss: 0.476545, accuracy: 0.746094\n",
      "Training loss: 0.468733, accuracy: 0.730469\n",
      "Training loss: 0.465298, accuracy: 0.753906\n",
      "Training loss: 0.457325, accuracy: 0.75\n",
      "Training loss: 0.443, accuracy: 0.753906\n",
      "Training loss: 0.430738, accuracy: 0.777344\n",
      "Training loss: 0.422896, accuracy: 0.792969\n",
      "Training loss: 0.411935, accuracy: 0.8125\n",
      "Training loss: 0.396547, accuracy: 0.816406\n",
      "Training loss: 0.38165, accuracy: 0.804688\n",
      "Training loss: 0.370208, accuracy: 0.832031\n",
      "Training loss: 0.353758, accuracy: 0.84375\n",
      "Training loss: 0.33503, accuracy: 0.847656\n",
      "Training loss: 0.321052, accuracy: 0.851563\n",
      "Training loss: 0.299579, accuracy: 0.863281\n",
      "Training loss: 0.28587, accuracy: 0.875\n",
      "Training loss: 0.259992, accuracy: 0.882813\n",
      "Training loss: 0.239098, accuracy: 0.902344\n",
      "Training loss: 0.236367, accuracy: 0.902344\n",
      "Training loss: 0.286574, accuracy: 0.871094\n",
      "Training loss: 0.214887, accuracy: 0.902344\n",
      "Training loss: 0.276574, accuracy: 0.871094\n",
      "Training loss: 0.163525, accuracy: 0.929688\n",
      "Training loss: 0.194676, accuracy: 0.925781\n",
      "Training loss: 0.174329, accuracy: 0.921875\n",
      "Training loss: 0.133729, accuracy: 0.949219\n",
      "Training loss: 0.118259, accuracy: 0.964844\n",
      "Training loss: 0.121377, accuracy: 0.964844\n",
      "Training loss: 0.108787, accuracy: 0.964844\n",
      "Training loss: 0.082361, accuracy: 0.972656\n",
      "Training loss: 0.0714203, accuracy: 0.980469\n",
      "Training loss: 0.0720481, accuracy: 0.964844\n",
      "Training loss: 0.0540696, accuracy: 0.984375\n",
      "Training loss: 0.0581549, accuracy: 0.980469\n",
      "Training loss: 0.045278, accuracy: 0.984375\n",
      "Training loss: 0.0313127, accuracy: 0.984375\n",
      "Training loss: 0.0316345, accuracy: 0.992188\n",
      "Training loss: 0.0215584, accuracy: 1.0\n",
      "Training loss: 0.0163416, accuracy: 1.0\n",
      "Training loss: 0.0142545, accuracy: 1.0\n",
      "Training loss: 0.0124262, accuracy: 1.0\n",
      "Training loss: 0.009966, accuracy: 1.0\n",
      "Training loss: 0.00766058, accuracy: 1.0\n",
      "Training loss: 0.00614418, accuracy: 1.0\n",
      "Training loss: 0.00529163, accuracy: 1.0\n",
      "Training loss: 0.00477759, accuracy: 1.0\n",
      "Training loss: 0.00435493, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.8235, accuracy: 0.664063\n",
      "Training loss: 1.57252, accuracy: 0.691406\n",
      "Training loss: 1.22198, accuracy: 0.71875\n",
      "Training loss: 0.8769, accuracy: 0.753906\n",
      "Training loss: 0.638821, accuracy: 0.765625\n",
      "Training loss: 0.501425, accuracy: 0.785156\n",
      "Training loss: 0.464097, accuracy: 0.800781\n",
      "Training loss: 0.480374, accuracy: 0.757813\n",
      "Training loss: 0.455755, accuracy: 0.773438\n",
      "Training loss: 0.412939, accuracy: 0.816406\n",
      "Training loss: 0.378876, accuracy: 0.835938\n",
      "Training loss: 0.353879, accuracy: 0.84375\n",
      "Training loss: 0.330465, accuracy: 0.855469\n",
      "Training loss: 0.30673, accuracy: 0.863281\n",
      "Training loss: 0.283211, accuracy: 0.867188\n",
      "Training loss: 0.257947, accuracy: 0.890625\n",
      "Training loss: 0.232984, accuracy: 0.914063\n",
      "Training loss: 0.207489, accuracy: 0.925781\n",
      "Training loss: 0.178163, accuracy: 0.941406\n",
      "Training loss: 0.150005, accuracy: 0.945313\n",
      "Training loss: 0.123092, accuracy: 0.957031\n",
      "Training loss: 0.10973, accuracy: 0.96875\n",
      "Training loss: 0.215346, accuracy: 0.890625\n",
      "Training loss: 0.0723893, accuracy: 0.984375\n",
      "Training loss: 0.207707, accuracy: 0.90625\n",
      "Training loss: 0.0618337, accuracy: 0.988281\n",
      "Training loss: 0.0801521, accuracy: 0.984375\n",
      "Training loss: 0.0910486, accuracy: 0.980469\n",
      "Training loss: 0.0807334, accuracy: 0.984375\n",
      "Training loss: 0.0599968, accuracy: 0.992188\n",
      "Training loss: 0.0379696, accuracy: 0.996094\n",
      "Training loss: 0.0243957, accuracy: 1.0\n",
      "Training loss: 0.0209539, accuracy: 1.0\n",
      "Training loss: 0.0206289, accuracy: 0.996094\n",
      "Training loss: 0.0163916, accuracy: 0.996094\n",
      "Training loss: 0.0115736, accuracy: 1.0\n",
      "Training loss: 0.0108447, accuracy: 1.0\n",
      "Training loss: 0.0110669, accuracy: 1.0\n",
      "Training loss: 0.0102248, accuracy: 1.0\n",
      "Training loss: 0.00859219, accuracy: 1.0\n",
      "Training loss: 0.0068677, accuracy: 1.0\n",
      "Training loss: 0.00557461, accuracy: 1.0\n",
      "Training loss: 0.00486725, accuracy: 1.0\n",
      "Training loss: 0.0046225, accuracy: 1.0\n",
      "Training loss: 0.00450892, accuracy: 1.0\n",
      "Training loss: 0.00418211, accuracy: 1.0\n",
      "Training loss: 0.00363856, accuracy: 1.0\n",
      "Training loss: 0.00312575, accuracy: 1.0\n",
      "Training loss: 0.00279213, accuracy: 1.0\n",
      "Training loss: 0.00259546, accuracy: 1.0\n",
      "Training loss: 0.00247629, accuracy: 1.0\n",
      "Training loss: 0.00239507, accuracy: 1.0\n",
      "Training loss: 0.00232095, accuracy: 1.0\n",
      "Training loss: 0.00223575, accuracy: 1.0\n",
      "Training loss: 0.00213577, accuracy: 1.0\n",
      "Training loss: 0.00202611, accuracy: 1.0\n",
      "Training loss: 0.00191634, accuracy: 1.0\n",
      "Training loss: 0.00181604, accuracy: 1.0\n",
      "Training loss: 0.00173007, accuracy: 1.0\n",
      "Training loss: 0.00165821, accuracy: 1.0\n",
      "Training loss: 0.00159895, accuracy: 1.0\n",
      "Training loss: 0.00154957, accuracy: 1.0\n",
      "Training loss: 0.00150833, accuracy: 1.0\n",
      "Training loss: 0.00147315, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.83193, accuracy: 0.640625\n",
      "Training loss: 1.29938, accuracy: 0.699219\n",
      "Training loss: 1.00102, accuracy: 0.753906\n",
      "Training loss: 0.792762, accuracy: 0.773438\n",
      "Training loss: 0.643542, accuracy: 0.804688\n",
      "Training loss: 0.528784, accuracy: 0.832031\n",
      "Training loss: 0.440285, accuracy: 0.839844\n",
      "Training loss: 0.383684, accuracy: 0.863281\n",
      "Training loss: 0.35349, accuracy: 0.875\n",
      "Training loss: 0.337019, accuracy: 0.898438\n",
      "Training loss: 0.3162, accuracy: 0.90625\n",
      "Training loss: 0.287864, accuracy: 0.910156\n",
      "Training loss: 0.257961, accuracy: 0.914063\n",
      "Training loss: 0.229888, accuracy: 0.917969\n",
      "Training loss: 0.204332, accuracy: 0.925781\n",
      "Training loss: 0.181674, accuracy: 0.929688\n",
      "Training loss: 0.161301, accuracy: 0.941406\n",
      "Training loss: 0.142812, accuracy: 0.945313\n",
      "Training loss: 0.126085, accuracy: 0.957031\n",
      "Training loss: 0.111617, accuracy: 0.960938\n",
      "Training loss: 0.0988287, accuracy: 0.96875\n",
      "Training loss: 0.0874522, accuracy: 0.96875\n",
      "Training loss: 0.0775395, accuracy: 0.972656\n",
      "Training loss: 0.0689113, accuracy: 0.980469\n",
      "Training loss: 0.0613543, accuracy: 0.992188\n",
      "Training loss: 0.054881, accuracy: 0.992188\n",
      "Training loss: 0.0493438, accuracy: 0.992188\n",
      "Training loss: 0.0446894, accuracy: 0.992188\n",
      "Training loss: 0.0408654, accuracy: 0.992188\n",
      "Training loss: 0.0377768, accuracy: 0.992188\n",
      "Training loss: 0.0352095, accuracy: 0.996094\n",
      "Training loss: 0.0330289, accuracy: 0.996094\n",
      "Training loss: 0.0313142, accuracy: 0.996094\n",
      "Training loss: 0.0299338, accuracy: 0.996094\n",
      "Training loss: 0.0288094, accuracy: 0.996094\n",
      "Training loss: 0.02786, accuracy: 0.996094\n",
      "Training loss: 0.0270525, accuracy: 0.996094\n",
      "Training loss: 0.0263517, accuracy: 0.996094\n",
      "Training loss: 0.0257266, accuracy: 0.996094\n",
      "Training loss: 0.0251629, accuracy: 0.996094\n",
      "Training loss: 0.024651, accuracy: 0.996094\n",
      "Training loss: 0.0241781, accuracy: 0.996094\n",
      "Training loss: 0.0237399, accuracy: 0.996094\n",
      "Training loss: 0.0233264, accuracy: 0.996094\n",
      "Training loss: 0.0229298, accuracy: 0.996094\n",
      "Training loss: 0.0225562, accuracy: 0.996094\n",
      "Training loss: 0.0221966, accuracy: 0.996094\n",
      "Training loss: 0.0218492, accuracy: 0.996094\n",
      "Training loss: 0.0215334, accuracy: 0.996094\n",
      "Training loss: 0.0212298, accuracy: 0.996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.020936, accuracy: 0.996094\n",
      "Training loss: 0.02065, accuracy: 0.996094\n",
      "Training loss: 0.0203657, accuracy: 0.996094\n",
      "Training loss: 0.0201159, accuracy: 0.996094\n",
      "Training loss: 0.0198663, accuracy: 0.996094\n",
      "Training loss: 0.019606, accuracy: 0.996094\n",
      "Training loss: 0.0193386, accuracy: 0.996094\n",
      "Training loss: 0.0190744, accuracy: 0.996094\n",
      "Training loss: 0.018809, accuracy: 0.996094\n",
      "Training loss: 0.0185439, accuracy: 0.996094\n",
      "Training loss: 0.0182721, accuracy: 0.996094\n",
      "Training loss: 0.0180215, accuracy: 0.996094\n",
      "Training loss: 0.0177778, accuracy: 0.996094\n",
      "Training loss: 0.0175225, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.53469, accuracy: 0.628906\n",
      "Training loss: 1.26609, accuracy: 0.6875\n",
      "Training loss: 0.954186, accuracy: 0.757813\n",
      "Training loss: 0.746931, accuracy: 0.800781\n",
      "Training loss: 0.61266, accuracy: 0.828125\n",
      "Training loss: 0.50136, accuracy: 0.859375\n",
      "Training loss: 0.411709, accuracy: 0.871094\n",
      "Training loss: 0.347547, accuracy: 0.886719\n",
      "Training loss: 0.304093, accuracy: 0.898438\n",
      "Training loss: 0.277166, accuracy: 0.914063\n",
      "Training loss: 0.25992, accuracy: 0.921875\n",
      "Training loss: 0.245826, accuracy: 0.945313\n",
      "Training loss: 0.228956, accuracy: 0.949219\n",
      "Training loss: 0.210266, accuracy: 0.953125\n",
      "Training loss: 0.193007, accuracy: 0.957031\n",
      "Training loss: 0.177681, accuracy: 0.960938\n",
      "Training loss: 0.165472, accuracy: 0.96875\n",
      "Training loss: 0.155219, accuracy: 0.96875\n",
      "Training loss: 0.146585, accuracy: 0.972656\n",
      "Training loss: 0.138792, accuracy: 0.972656\n",
      "Training loss: 0.131831, accuracy: 0.972656\n",
      "Training loss: 0.125484, accuracy: 0.972656\n",
      "Training loss: 0.119575, accuracy: 0.972656\n",
      "Training loss: 0.113816, accuracy: 0.972656\n",
      "Training loss: 0.108196, accuracy: 0.972656\n",
      "Training loss: 0.102944, accuracy: 0.976563\n",
      "Training loss: 0.098128, accuracy: 0.976563\n",
      "Training loss: 0.0938274, accuracy: 0.980469\n",
      "Training loss: 0.0900147, accuracy: 0.980469\n",
      "Training loss: 0.0866897, accuracy: 0.980469\n",
      "Training loss: 0.0836397, accuracy: 0.980469\n",
      "Training loss: 0.0807674, accuracy: 0.980469\n",
      "Training loss: 0.0780411, accuracy: 0.984375\n",
      "Training loss: 0.0753645, accuracy: 0.984375\n",
      "Training loss: 0.0727438, accuracy: 0.984375\n",
      "Training loss: 0.0701431, accuracy: 0.984375\n",
      "Training loss: 0.0676106, accuracy: 0.984375\n",
      "Training loss: 0.0651451, accuracy: 0.984375\n",
      "Training loss: 0.0628061, accuracy: 0.988281\n",
      "Training loss: 0.0606328, accuracy: 0.988281\n",
      "Training loss: 0.0585819, accuracy: 0.988281\n",
      "Training loss: 0.0566145, accuracy: 0.988281\n",
      "Training loss: 0.0547062, accuracy: 0.988281\n",
      "Training loss: 0.0528113, accuracy: 0.988281\n",
      "Training loss: 0.0509031, accuracy: 0.988281\n",
      "Training loss: 0.0489406, accuracy: 0.988281\n",
      "Training loss: 0.0468982, accuracy: 0.988281\n",
      "Training loss: 0.0447817, accuracy: 0.988281\n",
      "Training loss: 0.0425081, accuracy: 0.988281\n",
      "Training loss: 0.0400678, accuracy: 0.988281\n",
      "Training loss: 0.0375887, accuracy: 0.988281\n",
      "Training loss: 0.035142, accuracy: 0.988281\n",
      "Training loss: 0.032874, accuracy: 0.992188\n",
      "Training loss: 0.0308997, accuracy: 0.992188\n",
      "Training loss: 0.0291617, accuracy: 0.992188\n",
      "Training loss: 0.0275621, accuracy: 0.992188\n",
      "Training loss: 0.0260787, accuracy: 0.992188\n",
      "Training loss: 0.0247019, accuracy: 0.992188\n",
      "Training loss: 0.0233286, accuracy: 0.992188\n",
      "Training loss: 0.0219684, accuracy: 0.992188\n",
      "Training loss: 0.0206475, accuracy: 0.992188\n",
      "Training loss: 0.0193365, accuracy: 0.992188\n",
      "Training loss: 0.018066, accuracy: 0.992188\n",
      "Training loss: 0.0168471, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.29647, accuracy: 0.660156\n",
      "Training loss: 1.10728, accuracy: 0.675781\n",
      "Training loss: 0.850618, accuracy: 0.730469\n",
      "Training loss: 0.6426, accuracy: 0.808594\n",
      "Training loss: 0.502667, accuracy: 0.847656\n",
      "Training loss: 0.407984, accuracy: 0.878906\n",
      "Training loss: 0.340192, accuracy: 0.886719\n",
      "Training loss: 0.29232, accuracy: 0.921875\n",
      "Training loss: 0.257937, accuracy: 0.925781\n",
      "Training loss: 0.231196, accuracy: 0.925781\n",
      "Training loss: 0.209114, accuracy: 0.933594\n",
      "Training loss: 0.190842, accuracy: 0.9375\n",
      "Training loss: 0.175574, accuracy: 0.949219\n",
      "Training loss: 0.161775, accuracy: 0.964844\n",
      "Training loss: 0.148649, accuracy: 0.96875\n",
      "Training loss: 0.136677, accuracy: 0.972656\n",
      "Training loss: 0.125965, accuracy: 0.972656\n",
      "Training loss: 0.116723, accuracy: 0.976563\n",
      "Training loss: 0.109444, accuracy: 0.976563\n",
      "Training loss: 0.103745, accuracy: 0.976563\n",
      "Training loss: 0.0990616, accuracy: 0.976563\n",
      "Training loss: 0.0949334, accuracy: 0.976563\n",
      "Training loss: 0.0912775, accuracy: 0.976563\n",
      "Training loss: 0.0879216, accuracy: 0.976563\n",
      "Training loss: 0.0846919, accuracy: 0.976563\n",
      "Training loss: 0.0815269, accuracy: 0.976563\n",
      "Training loss: 0.0783867, accuracy: 0.976563\n",
      "Training loss: 0.0752784, accuracy: 0.976563\n",
      "Training loss: 0.0719227, accuracy: 0.976563\n",
      "Training loss: 0.0615744, accuracy: 0.980469\n",
      "Training loss: 0.058012, accuracy: 0.980469\n",
      "Training loss: 0.0553291, accuracy: 0.980469\n",
      "Training loss: 0.0527378, accuracy: 0.980469\n",
      "Training loss: 0.0502428, accuracy: 0.980469\n",
      "Training loss: 0.0477626, accuracy: 0.980469\n",
      "Training loss: 0.0452793, accuracy: 0.980469\n",
      "Training loss: 0.0428453, accuracy: 0.988281\n",
      "Training loss: 0.0405113, accuracy: 0.992188\n",
      "Training loss: 0.038297, accuracy: 0.992188\n",
      "Training loss: 0.0361569, accuracy: 0.992188\n",
      "Training loss: 0.0340996, accuracy: 0.992188\n",
      "Training loss: 0.0321469, accuracy: 0.996094\n",
      "Training loss: 0.0302906, accuracy: 0.996094\n",
      "Training loss: 0.0285246, accuracy: 0.996094\n",
      "Training loss: 0.0268307, accuracy: 0.996094\n",
      "Training loss: 0.0252103, accuracy: 0.996094\n",
      "Training loss: 0.0236686, accuracy: 0.996094\n",
      "Training loss: 0.0222118, accuracy: 0.996094\n",
      "Training loss: 0.0208511, accuracy: 0.996094\n",
      "Training loss: 0.0195967, accuracy: 0.996094\n",
      "Training loss: 0.0184284, accuracy: 0.996094\n",
      "Training loss: 0.0173449, accuracy: 0.996094\n",
      "Training loss: 0.0163391, accuracy: 0.996094\n",
      "Training loss: 0.0154017, accuracy: 0.996094\n",
      "Training loss: 0.0145265, accuracy: 0.996094\n",
      "Training loss: 0.0137091, accuracy: 1.0\n",
      "Training loss: 0.0129471, accuracy: 1.0\n",
      "Training loss: 0.0122178, accuracy: 1.0\n",
      "Training loss: 0.0115062, accuracy: 1.0\n",
      "Training loss: 0.0108244, accuracy: 1.0\n",
      "Training loss: 0.0101759, accuracy: 1.0\n",
      "Training loss: 0.00957215, accuracy: 1.0\n",
      "Training loss: 0.00900434, accuracy: 1.0\n",
      "Training loss: 0.00846821, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.21939, accuracy: 0.714844\n",
      "Training loss: 1.01421, accuracy: 0.765625\n",
      "Training loss: 0.757978, accuracy: 0.8125\n",
      "Training loss: 0.571614, accuracy: 0.847656\n",
      "Training loss: 0.428389, accuracy: 0.890625\n",
      "Training loss: 0.325603, accuracy: 0.90625\n",
      "Training loss: 0.248376, accuracy: 0.917969\n",
      "Training loss: 0.192097, accuracy: 0.933594\n",
      "Training loss: 0.152077, accuracy: 0.960938\n",
      "Training loss: 0.131776, accuracy: 0.96875\n",
      "Training loss: 0.117945, accuracy: 0.96875\n",
      "Training loss: 0.106741, accuracy: 0.972656\n",
      "Training loss: 0.0970439, accuracy: 0.984375\n",
      "Training loss: 0.0890293, accuracy: 0.984375\n",
      "Training loss: 0.082231, accuracy: 0.984375\n",
      "Training loss: 0.0764962, accuracy: 0.988281\n",
      "Training loss: 0.0709737, accuracy: 0.988281\n",
      "Training loss: 0.0647431, accuracy: 0.988281\n",
      "Training loss: 0.0582539, accuracy: 0.992188\n",
      "Training loss: 0.0530426, accuracy: 0.992188\n",
      "Training loss: 0.0479892, accuracy: 0.992188\n",
      "Training loss: 0.0433297, accuracy: 0.996094\n",
      "Training loss: 0.0404944, accuracy: 0.996094\n",
      "Training loss: 0.038218, accuracy: 0.996094\n",
      "Training loss: 0.0361774, accuracy: 0.996094\n",
      "Training loss: 0.0343864, accuracy: 0.996094\n",
      "Training loss: 0.0328725, accuracy: 0.996094\n",
      "Training loss: 0.0316098, accuracy: 0.996094\n",
      "Training loss: 0.03056, accuracy: 0.996094\n",
      "Training loss: 0.0296723, accuracy: 0.996094\n",
      "Training loss: 0.0288948, accuracy: 0.996094\n",
      "Training loss: 0.0281859, accuracy: 0.996094\n",
      "Training loss: 0.0275104, accuracy: 0.996094\n",
      "Training loss: 0.0268333, accuracy: 0.996094\n",
      "Training loss: 0.0261062, accuracy: 0.996094\n",
      "Training loss: 0.025246, accuracy: 0.996094\n",
      "Training loss: 0.0241172, accuracy: 0.996094\n",
      "Training loss: 0.0222254, accuracy: 0.996094\n",
      "Training loss: 0.0181493, accuracy: 0.996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0113745, accuracy: 1.0\n",
      "Training loss: 0.00987134, accuracy: 1.0\n",
      "Training loss: 0.00948948, accuracy: 1.0\n",
      "Training loss: 0.00922721, accuracy: 1.0\n",
      "Training loss: 0.00903469, accuracy: 1.0\n",
      "Training loss: 0.00883567, accuracy: 1.0\n",
      "Training loss: 0.00854201, accuracy: 1.0\n",
      "Training loss: 0.00825447, accuracy: 1.0\n",
      "Training loss: 0.0079987, accuracy: 1.0\n",
      "Training loss: 0.00776065, accuracy: 1.0\n",
      "Training loss: 0.00753305, accuracy: 1.0\n",
      "Training loss: 0.00731408, accuracy: 1.0\n",
      "Training loss: 0.00710301, accuracy: 1.0\n",
      "Training loss: 0.00690065, accuracy: 1.0\n",
      "Training loss: 0.00670724, accuracy: 1.0\n",
      "Training loss: 0.00652297, accuracy: 1.0\n",
      "Training loss: 0.00634735, accuracy: 1.0\n",
      "Training loss: 0.00618003, accuracy: 1.0\n",
      "Training loss: 0.0060215, accuracy: 1.0\n",
      "Training loss: 0.00587096, accuracy: 1.0\n",
      "Training loss: 0.00572805, accuracy: 1.0\n",
      "Training loss: 0.00559165, accuracy: 1.0\n",
      "Training loss: 0.00546167, accuracy: 1.0\n",
      "Training loss: 0.00533826, accuracy: 1.0\n",
      "Training loss: 0.00522198, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.25512, accuracy: 0.71875\n",
      "Training loss: 1.1506, accuracy: 0.734375\n",
      "Training loss: 0.983035, accuracy: 0.765625\n",
      "Training loss: 0.813059, accuracy: 0.796875\n",
      "Training loss: 0.663313, accuracy: 0.824219\n",
      "Training loss: 0.550086, accuracy: 0.859375\n",
      "Training loss: 0.474363, accuracy: 0.871094\n",
      "Training loss: 0.404233, accuracy: 0.875\n",
      "Training loss: 0.331177, accuracy: 0.902344\n",
      "Training loss: 0.283247, accuracy: 0.914063\n",
      "Training loss: 0.250977, accuracy: 0.921875\n",
      "Training loss: 0.228526, accuracy: 0.921875\n",
      "Training loss: 0.213255, accuracy: 0.933594\n",
      "Training loss: 0.202495, accuracy: 0.9375\n",
      "Training loss: 0.192131, accuracy: 0.941406\n",
      "Training loss: 0.180027, accuracy: 0.945313\n",
      "Training loss: 0.166466, accuracy: 0.949219\n",
      "Training loss: 0.152236, accuracy: 0.960938\n",
      "Training loss: 0.138404, accuracy: 0.964844\n",
      "Training loss: 0.125666, accuracy: 0.964844\n",
      "Training loss: 0.114899, accuracy: 0.964844\n",
      "Training loss: 0.105985, accuracy: 0.96875\n",
      "Training loss: 0.0983174, accuracy: 0.96875\n",
      "Training loss: 0.091438, accuracy: 0.96875\n",
      "Training loss: 0.0851273, accuracy: 0.96875\n",
      "Training loss: 0.0793425, accuracy: 0.976563\n",
      "Training loss: 0.0739601, accuracy: 0.976563\n",
      "Training loss: 0.068993, accuracy: 0.980469\n",
      "Training loss: 0.0641468, accuracy: 0.980469\n",
      "Training loss: 0.0594334, accuracy: 0.980469\n",
      "Training loss: 0.0547456, accuracy: 0.984375\n",
      "Training loss: 0.0502808, accuracy: 0.988281\n",
      "Training loss: 0.0463075, accuracy: 0.992188\n",
      "Training loss: 0.0428376, accuracy: 0.992188\n",
      "Training loss: 0.03976, accuracy: 0.992188\n",
      "Training loss: 0.0370241, accuracy: 0.992188\n",
      "Training loss: 0.0344969, accuracy: 0.996094\n",
      "Training loss: 0.032257, accuracy: 0.996094\n",
      "Training loss: 0.0302733, accuracy: 0.996094\n",
      "Training loss: 0.0284322, accuracy: 0.996094\n",
      "Training loss: 0.0266492, accuracy: 0.996094\n",
      "Training loss: 0.0249716, accuracy: 0.996094\n",
      "Training loss: 0.0232093, accuracy: 0.996094\n",
      "Training loss: 0.0213342, accuracy: 0.996094\n",
      "Training loss: 0.019269, accuracy: 0.996094\n",
      "Training loss: 0.0171268, accuracy: 0.996094\n",
      "Training loss: 0.0151392, accuracy: 1.0\n",
      "Training loss: 0.0136547, accuracy: 1.0\n",
      "Training loss: 0.0126367, accuracy: 1.0\n",
      "Training loss: 0.0119082, accuracy: 1.0\n",
      "Training loss: 0.0113162, accuracy: 1.0\n",
      "Training loss: 0.0107934, accuracy: 1.0\n",
      "Training loss: 0.0103223, accuracy: 1.0\n",
      "Training loss: 0.00989508, accuracy: 1.0\n",
      "Training loss: 0.00950602, accuracy: 1.0\n",
      "Training loss: 0.00914773, accuracy: 1.0\n",
      "Training loss: 0.0088145, accuracy: 1.0\n",
      "Training loss: 0.00850246, accuracy: 1.0\n",
      "Training loss: 0.00820818, accuracy: 1.0\n",
      "Training loss: 0.0079296, accuracy: 1.0\n",
      "Training loss: 0.00766618, accuracy: 1.0\n",
      "Training loss: 0.00741651, accuracy: 1.0\n",
      "Training loss: 0.00717908, accuracy: 1.0\n",
      "Training loss: 0.0069533, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.0769, accuracy: 0.746094\n",
      "Training loss: 0.908035, accuracy: 0.765625\n",
      "Training loss: 0.758486, accuracy: 0.800781\n",
      "Training loss: 0.643339, accuracy: 0.828125\n",
      "Training loss: 0.565635, accuracy: 0.839844\n",
      "Training loss: 0.489641, accuracy: 0.851563\n",
      "Training loss: 0.420027, accuracy: 0.871094\n",
      "Training loss: 0.364041, accuracy: 0.890625\n",
      "Training loss: 0.311195, accuracy: 0.894531\n",
      "Training loss: 0.260588, accuracy: 0.902344\n",
      "Training loss: 0.222497, accuracy: 0.925781\n",
      "Training loss: 0.197898, accuracy: 0.933594\n",
      "Training loss: 0.177396, accuracy: 0.945313\n",
      "Training loss: 0.160122, accuracy: 0.957031\n",
      "Training loss: 0.145966, accuracy: 0.960938\n",
      "Training loss: 0.133956, accuracy: 0.964844\n",
      "Training loss: 0.123333, accuracy: 0.964844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-84da3eb8407b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Projects\\movie-review\\src\\lstm.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, steps, epochs, verbose_every)\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                     _, loss_val, accuracy_val = sess.run([self.train, self.loss, self.accuracy],\n\u001b[1;32m---> 81\u001b[1;33m                                                          feed_dict={self.X: X_train_batch, self.y_true: y_train_batch})\n\u001b[0m\u001b[0;32m     82\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training loss: {}, accuracy: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model.train_model(steps=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
