{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lstm import lstm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:26: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:27: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Cleaned data exists, load directly from pickle file\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:33: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "No meta graph found. Start to build graph from scratch\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:63: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:69: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:73: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:75: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/ximing/anaconda3/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ximing/anaconda3/envs/tfgpu/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f563d3b5668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f563d3b5668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f563d3b5668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7f563d3b5668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:80: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301a7320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301a7320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301a7320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301a7320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301bac18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301bac18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301bac18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f56301bac18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:89: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/ximing/dl/projects/movie-review/src/lstm.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Graph built successfully!\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_classifier(num_wds=200, \n",
    "                        embed_size=300,\n",
    "                        lstm_size=128, \n",
    "                        dense_size=[1024, 256], \n",
    "                        class_num=2, \n",
    "                        learning_rate=0.001,\n",
    "                        batch_size=64, \n",
    "                        root_dir=module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [n.name for n in lstm_model.graph.as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sample, y_sample = lstm_model.data_helper.get_next_batch(epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.680621, accuracy: 0.59375\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 0: validation accuracy 0.504 ----------------\n",
      "Training loss: 0.674884, accuracy: 0.59375\n",
      "Training loss: 0.826987, accuracy: 0.40625\n",
      "Training loss: 0.765152, accuracy: 0.4375\n",
      "Training loss: 0.70991, accuracy: 0.609375\n",
      "Training loss: 0.73863, accuracy: 0.59375\n",
      "Training loss: 0.706198, accuracy: 0.53125\n",
      "Training loss: 0.74606, accuracy: 0.40625\n",
      "Training loss: 0.699543, accuracy: 0.4375\n",
      "Training loss: 0.686817, accuracy: 0.625\n",
      "Training loss: 0.698351, accuracy: 0.484375\n",
      "Training loss: 0.694036, accuracy: 0.578125\n",
      "Training loss: 0.699801, accuracy: 0.4375\n",
      "Training loss: 0.699125, accuracy: 0.546875\n",
      "Training loss: 0.68806, accuracy: 0.515625\n",
      "Training loss: 0.686105, accuracy: 0.59375\n",
      "Training loss: 0.730933, accuracy: 0.453125\n",
      "Training loss: 0.690041, accuracy: 0.5\n",
      "Training loss: 0.714755, accuracy: 0.5\n",
      "Training loss: 0.756479, accuracy: 0.390625\n",
      "Training loss: 0.703539, accuracy: 0.46875\n",
      "Training loss: 0.710256, accuracy: 0.484375\n",
      "Training loss: 0.725509, accuracy: 0.421875\n",
      "Training loss: 0.729414, accuracy: 0.4375\n",
      "Training loss: 0.691644, accuracy: 0.53125\n",
      "Training loss: 0.706611, accuracy: 0.484375\n",
      "Training loss: 0.681656, accuracy: 0.5625\n",
      "Training loss: 0.689479, accuracy: 0.5625\n",
      "Training loss: 0.701733, accuracy: 0.46875\n",
      "Training loss: 0.732485, accuracy: 0.40625\n",
      "Training loss: 0.698579, accuracy: 0.5\n",
      "Training loss: 0.675454, accuracy: 0.59375\n",
      "Training loss: 0.681098, accuracy: 0.609375\n",
      "Training loss: 0.690897, accuracy: 0.5\n",
      "Training loss: 0.7038, accuracy: 0.453125\n",
      "Training loss: 0.683566, accuracy: 0.609375\n",
      "Training loss: 0.717755, accuracy: 0.453125\n",
      "Training loss: 0.699882, accuracy: 0.484375\n",
      "Training loss: 0.694548, accuracy: 0.484375\n",
      "Training loss: 0.682042, accuracy: 0.59375\n",
      "Training loss: 0.700711, accuracy: 0.515625\n",
      "Training loss: 0.706658, accuracy: 0.46875\n",
      "Training loss: 0.668818, accuracy: 0.65625\n",
      "Training loss: 0.65287, accuracy: 0.65625\n",
      "Training loss: 0.80174, accuracy: 0.453125\n",
      "Training loss: 0.677375, accuracy: 0.609375\n",
      "Training loss: 0.714059, accuracy: 0.578125\n",
      "Training loss: 0.726417, accuracy: 0.46875\n",
      "Training loss: 0.665432, accuracy: 0.625\n",
      "Training loss: 0.70344, accuracy: 0.546875\n",
      "Training loss: 0.687503, accuracy: 0.578125\n",
      "Training loss: 0.684716, accuracy: 0.5\n",
      "Training loss: 0.717343, accuracy: 0.453125\n",
      "Training loss: 0.688961, accuracy: 0.53125\n",
      "Training loss: 0.698306, accuracy: 0.484375\n",
      "Training loss: 0.693629, accuracy: 0.578125\n",
      "Training loss: 0.688101, accuracy: 0.53125\n",
      "Training loss: 0.700384, accuracy: 0.578125\n",
      "Training loss: 0.711336, accuracy: 0.484375\n",
      "Training loss: 0.679445, accuracy: 0.578125\n",
      "Training loss: 0.717539, accuracy: 0.46875\n",
      "Training loss: 0.710452, accuracy: 0.4375\n",
      "Training loss: 0.687962, accuracy: 0.546875\n",
      "Training loss: 0.682646, accuracy: 0.5625\n",
      "Training loss: 0.709316, accuracy: 0.4375\n",
      "Training loss: 0.682067, accuracy: 0.578125\n",
      "Training loss: 0.746557, accuracy: 0.40625\n",
      "Training loss: 0.67236, accuracy: 0.578125\n",
      "Training loss: 0.683652, accuracy: 0.59375\n",
      "Training loss: 0.714232, accuracy: 0.390625\n",
      "Training loss: 0.708142, accuracy: 0.46875\n",
      "Training loss: 0.691985, accuracy: 0.578125\n",
      "Training loss: 0.721113, accuracy: 0.421875\n",
      "Training loss: 0.705413, accuracy: 0.4375\n",
      "Training loss: 0.712652, accuracy: 0.515625\n",
      "Training loss: 0.699775, accuracy: 0.390625\n",
      "Training loss: 0.702324, accuracy: 0.390625\n",
      "Training loss: 0.683063, accuracy: 0.5625\n",
      "Training loss: 0.710742, accuracy: 0.453125\n",
      "Training loss: 0.701294, accuracy: 0.515625\n",
      "Training loss: 0.695434, accuracy: 0.59375\n",
      "Training loss: 0.678258, accuracy: 0.640625\n",
      "Training loss: 0.689825, accuracy: 0.5\n",
      "Training loss: 0.680966, accuracy: 0.609375\n",
      "Training loss: 0.722212, accuracy: 0.4375\n",
      "Training loss: 0.688557, accuracy: 0.5625\n",
      "Training loss: 0.678883, accuracy: 0.546875\n",
      "Training loss: 0.692254, accuracy: 0.515625\n",
      "Training loss: 0.689715, accuracy: 0.515625\n",
      "Training loss: 0.689087, accuracy: 0.53125\n",
      "Training loss: 0.705113, accuracy: 0.484375\n",
      "Training loss: 0.695596, accuracy: 0.453125\n",
      "Training loss: 0.703711, accuracy: 0.515625\n",
      "Training loss: 0.69232, accuracy: 0.5\n",
      "Training loss: 0.700059, accuracy: 0.421875\n",
      "Training loss: 0.719381, accuracy: 0.421875\n",
      "Training loss: 0.685824, accuracy: 0.5625\n",
      "Training loss: 0.672925, accuracy: 0.578125\n",
      "Training loss: 0.693932, accuracy: 0.546875\n",
      "Training loss: 0.692829, accuracy: 0.53125\n",
      "Training loss: 0.711156, accuracy: 0.46875\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 100: validation accuracy 0.50528 ----------------\n",
      "Training loss: 0.707387, accuracy: 0.515625\n",
      "Training loss: 0.693751, accuracy: 0.5\n",
      "Training loss: 0.722015, accuracy: 0.40625\n",
      "Training loss: 0.704853, accuracy: 0.546875\n",
      "Training loss: 0.688905, accuracy: 0.53125\n",
      "Training loss: 0.695497, accuracy: 0.515625\n",
      "Training loss: 0.68912, accuracy: 0.53125\n",
      "Training loss: 0.710149, accuracy: 0.46875\n",
      "Training loss: 0.681368, accuracy: 0.578125\n",
      "Training loss: 0.77815, accuracy: 0.40625\n",
      "Training loss: 0.703824, accuracy: 0.53125\n",
      "Training loss: 0.689428, accuracy: 0.40625\n",
      "Training loss: 0.709271, accuracy: 0.40625\n",
      "Training loss: 0.728441, accuracy: 0.453125\n",
      "Training loss: 0.696704, accuracy: 0.5\n",
      "Training loss: 0.700614, accuracy: 0.46875\n",
      "Training loss: 0.706891, accuracy: 0.4375\n",
      "Training loss: 0.69369, accuracy: 0.515625\n",
      "Training loss: 0.6871, accuracy: 0.515625\n",
      "Training loss: 0.691765, accuracy: 0.515625\n",
      "Training loss: 0.670254, accuracy: 0.609375\n",
      "Training loss: 0.734884, accuracy: 0.453125\n",
      "Training loss: 0.707897, accuracy: 0.484375\n",
      "Training loss: 0.701021, accuracy: 0.515625\n",
      "Training loss: 0.716561, accuracy: 0.484375\n",
      "Training loss: 0.69766, accuracy: 0.5625\n",
      "Training loss: 0.710862, accuracy: 0.421875\n",
      "Training loss: 0.696039, accuracy: 0.53125\n",
      "Training loss: 0.682988, accuracy: 0.609375\n",
      "Training loss: 0.693643, accuracy: 0.53125\n",
      "Training loss: 0.731587, accuracy: 0.484375\n",
      "Training loss: 0.711493, accuracy: 0.46875\n",
      "Training loss: 0.766909, accuracy: 0.40625\n",
      "Training loss: 0.702655, accuracy: 0.546875\n",
      "Training loss: 0.697061, accuracy: 0.390625\n",
      "Training loss: 0.708917, accuracy: 0.453125\n",
      "Training loss: 0.689948, accuracy: 0.53125\n",
      "Training loss: 0.688089, accuracy: 0.59375\n",
      "Training loss: 0.684691, accuracy: 0.5625\n",
      "Training loss: 0.714678, accuracy: 0.515625\n",
      "Training loss: 0.743949, accuracy: 0.4375\n",
      "Training loss: 0.684386, accuracy: 0.53125\n",
      "Training loss: 0.745933, accuracy: 0.4375\n",
      "Training loss: 0.71431, accuracy: 0.5\n",
      "Training loss: 0.71639, accuracy: 0.46875\n",
      "Training loss: 0.696633, accuracy: 0.453125\n",
      "Training loss: 0.686948, accuracy: 0.515625\n",
      "Training loss: 0.695851, accuracy: 0.453125\n",
      "Training loss: 0.721709, accuracy: 0.453125\n",
      "Training loss: 0.708877, accuracy: 0.484375\n",
      "Training loss: 0.704481, accuracy: 0.546875\n",
      "Training loss: 0.701645, accuracy: 0.53125\n",
      "Training loss: 0.691769, accuracy: 0.515625\n",
      "Training loss: 0.693915, accuracy: 0.53125\n",
      "Training loss: 0.695319, accuracy: 0.53125\n",
      "Training loss: 0.679019, accuracy: 0.53125\n",
      "Training loss: 0.69567, accuracy: 0.5\n",
      "Training loss: 0.693256, accuracy: 0.453125\n",
      "Training loss: 0.686798, accuracy: 0.609375\n",
      "Training loss: 0.718442, accuracy: 0.453125\n",
      "Training loss: 0.703539, accuracy: 0.4375\n",
      "Training loss: 0.696179, accuracy: 0.5\n",
      "Training loss: 0.690224, accuracy: 0.515625\n",
      "Training loss: 0.689963, accuracy: 0.578125\n",
      "Training loss: 0.67705, accuracy: 0.625\n",
      "Training loss: 0.681859, accuracy: 0.640625\n",
      "Training loss: 0.70933, accuracy: 0.40625\n",
      "Training loss: 0.710432, accuracy: 0.46875\n",
      "Training loss: 0.715874, accuracy: 0.375\n",
      "Training loss: 0.717488, accuracy: 0.46875\n",
      "Training loss: 0.668311, accuracy: 0.65625\n",
      "Training loss: 0.706141, accuracy: 0.421875\n",
      "Training loss: 0.694253, accuracy: 0.453125\n",
      "Training loss: 0.682279, accuracy: 0.59375\n",
      "Training loss: 0.684332, accuracy: 0.515625\n",
      "Training loss: 0.701577, accuracy: 0.4375\n",
      "Training loss: 0.694834, accuracy: 0.421875\n",
      "Training loss: 0.701652, accuracy: 0.515625\n",
      "Training loss: 0.707664, accuracy: 0.484375\n",
      "Training loss: 0.6914, accuracy: 0.515625\n",
      "Training loss: 0.69254, accuracy: 0.5625\n",
      "Training loss: 0.697276, accuracy: 0.515625\n",
      "Training loss: 0.701547, accuracy: 0.453125\n",
      "Training loss: 0.687784, accuracy: 0.53125\n",
      "Training loss: 0.715657, accuracy: 0.46875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.699575, accuracy: 0.46875\n",
      "Training loss: 0.669323, accuracy: 0.59375\n",
      "Training loss: 0.705636, accuracy: 0.546875\n",
      "Training loss: 0.700849, accuracy: 0.46875\n",
      "Training loss: 0.705637, accuracy: 0.46875\n",
      "Training loss: 0.696244, accuracy: 0.5625\n",
      "Training loss: 0.691843, accuracy: 0.578125\n",
      "Training loss: 0.698076, accuracy: 0.484375\n",
      "Training loss: 0.680653, accuracy: 0.609375\n",
      "Training loss: 0.698325, accuracy: 0.46875\n",
      "Training loss: 0.71104, accuracy: 0.4375\n",
      "Training loss: 0.713246, accuracy: 0.484375\n",
      "Training loss: 0.695921, accuracy: 0.5\n",
      "Training loss: 0.722961, accuracy: 0.375\n",
      "Training loss: 0.696779, accuracy: 0.515625\n",
      "----------------- Step 200: validation accuracy 0.50528 ----------------\n",
      "Training loss: 0.699394, accuracy: 0.53125\n",
      "Training loss: 0.713658, accuracy: 0.4375\n",
      "Training loss: 0.69837, accuracy: 0.484375\n",
      "Training loss: 0.700448, accuracy: 0.484375\n",
      "Training loss: 0.691885, accuracy: 0.53125\n",
      "Training loss: 0.696582, accuracy: 0.53125\n",
      "Training loss: 0.695938, accuracy: 0.53125\n",
      "Training loss: 0.697463, accuracy: 0.515625\n",
      "Training loss: 0.698107, accuracy: 0.484375\n",
      "Training loss: 0.679089, accuracy: 0.53125\n",
      "Training loss: 0.690416, accuracy: 0.5\n",
      "Training loss: 0.695988, accuracy: 0.5\n",
      "Training loss: 0.701661, accuracy: 0.390625\n",
      "Training loss: 0.686321, accuracy: 0.515625\n",
      "Training loss: 0.696164, accuracy: 0.453125\n",
      "Training loss: 0.701241, accuracy: 0.484375\n",
      "Training loss: 0.70303, accuracy: 0.484375\n",
      "Training loss: 0.695289, accuracy: 0.46875\n",
      "Training loss: 0.694003, accuracy: 0.46875\n",
      "Training loss: 0.690251, accuracy: 0.5\n",
      "Training loss: 0.689267, accuracy: 0.546875\n",
      "Training loss: 0.693255, accuracy: 0.578125\n",
      "Training loss: 0.691334, accuracy: 0.5625\n",
      "Training loss: 0.680652, accuracy: 0.5625\n",
      "Training loss: 0.702522, accuracy: 0.453125\n",
      "Training loss: 0.686637, accuracy: 0.53125\n",
      "Training loss: 0.702475, accuracy: 0.625\n",
      "Training loss: 0.693298, accuracy: 0.53125\n",
      "Training loss: 0.681995, accuracy: 0.53125\n",
      "Training loss: 0.687489, accuracy: 0.515625\n",
      "Training loss: 0.683729, accuracy: 0.5625\n",
      "Training loss: 0.677231, accuracy: 0.609375\n",
      "Training loss: 0.708669, accuracy: 0.53125\n",
      "Training loss: 0.681018, accuracy: 0.578125\n",
      "Training loss: 0.682917, accuracy: 0.515625\n",
      "Training loss: 0.675562, accuracy: 0.546875\n",
      "Training loss: 0.670997, accuracy: 0.546875\n",
      "Training loss: 0.660068, accuracy: 0.625\n",
      "Training loss: 0.668901, accuracy: 0.578125\n",
      "Training loss: 0.690041, accuracy: 0.53125\n",
      "Training loss: 0.712812, accuracy: 0.46875\n",
      "Training loss: 0.658543, accuracy: 0.59375\n",
      "Training loss: 0.682182, accuracy: 0.5625\n",
      "Training loss: 0.650067, accuracy: 0.609375\n",
      "Training loss: 0.658557, accuracy: 0.640625\n",
      "Training loss: 0.681402, accuracy: 0.546875\n",
      "Training loss: 0.657285, accuracy: 0.625\n",
      "Training loss: 0.658747, accuracy: 0.625\n",
      "Training loss: 0.712302, accuracy: 0.5625\n",
      "Training loss: 0.662471, accuracy: 0.609375\n",
      "Training loss: 0.614007, accuracy: 0.71875\n",
      "Training loss: 0.662145, accuracy: 0.609375\n",
      "Training loss: 0.612876, accuracy: 0.65625\n",
      "Training loss: 0.647796, accuracy: 0.703125\n",
      "Training loss: 0.572701, accuracy: 0.734375\n",
      "Training loss: 0.559086, accuracy: 0.796875\n",
      "Training loss: 0.60792, accuracy: 0.6875\n",
      "Training loss: 0.60544, accuracy: 0.703125\n",
      "Training loss: 0.561238, accuracy: 0.703125\n",
      "Training loss: 0.641375, accuracy: 0.65625\n",
      "Training loss: 0.61452, accuracy: 0.6875\n",
      "Training loss: 0.691931, accuracy: 0.59375\n",
      "Training loss: 0.690652, accuracy: 0.5625\n",
      "Training loss: 0.725852, accuracy: 0.546875\n",
      "Training loss: 0.617068, accuracy: 0.671875\n",
      "Training loss: 0.757115, accuracy: 0.59375\n",
      "Training loss: 0.643763, accuracy: 0.625\n",
      "Training loss: 0.669581, accuracy: 0.65625\n",
      "Training loss: 0.599647, accuracy: 0.6875\n",
      "Training loss: 0.562788, accuracy: 0.734375\n",
      "Training loss: 0.570455, accuracy: 0.71875\n",
      "Training loss: 0.572273, accuracy: 0.734375\n",
      "Training loss: 0.619094, accuracy: 0.671875\n",
      "Training loss: 0.628786, accuracy: 0.671875\n",
      "Training loss: 0.696176, accuracy: 0.640625\n",
      "Training loss: 0.600869, accuracy: 0.671875\n",
      "Training loss: 0.623872, accuracy: 0.625\n",
      "Training loss: 0.574099, accuracy: 0.71875\n",
      "Training loss: 0.577151, accuracy: 0.71875\n",
      "Training loss: 0.568948, accuracy: 0.71875\n",
      "Training loss: 0.590772, accuracy: 0.640625\n",
      "Training loss: 0.610506, accuracy: 0.609375\n",
      "Training loss: 0.565719, accuracy: 0.671875\n",
      "Training loss: 0.632108, accuracy: 0.6875\n",
      "Training loss: 0.559906, accuracy: 0.6875\n",
      "Training loss: 0.496548, accuracy: 0.8125\n",
      "Training loss: 0.626761, accuracy: 0.640625\n",
      "Training loss: 0.63145, accuracy: 0.65625\n",
      "Training loss: 0.595267, accuracy: 0.65625\n",
      "Training loss: 0.723455, accuracy: 0.546875\n",
      "Training loss: 0.525322, accuracy: 0.8125\n",
      "Training loss: 0.65126, accuracy: 0.609375\n",
      "Training loss: 0.617842, accuracy: 0.640625\n",
      "Training loss: 0.619634, accuracy: 0.65625\n",
      "Training loss: 0.603914, accuracy: 0.640625\n",
      "Training loss: 0.684062, accuracy: 0.59375\n",
      "Training loss: 0.573288, accuracy: 0.75\n",
      "Training loss: 0.626029, accuracy: 0.625\n",
      "Training loss: 0.615439, accuracy: 0.671875\n",
      "Training loss: 0.63949, accuracy: 0.671875\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 300: validation accuracy 0.63056 ----------------\n",
      "Training loss: 0.543269, accuracy: 0.6875\n",
      "Training loss: 0.585857, accuracy: 0.671875\n",
      "Training loss: 0.657306, accuracy: 0.59375\n",
      "Training loss: 0.560176, accuracy: 0.734375\n",
      "Training loss: 0.591675, accuracy: 0.671875\n",
      "Training loss: 0.592445, accuracy: 0.671875\n",
      "Training loss: 0.561515, accuracy: 0.734375\n",
      "Training loss: 0.611951, accuracy: 0.703125\n",
      "Training loss: 0.638268, accuracy: 0.625\n",
      "Training loss: 0.625217, accuracy: 0.671875\n",
      "Training loss: 0.607572, accuracy: 0.6875\n",
      "Training loss: 0.572241, accuracy: 0.671875\n",
      "Training loss: 0.660523, accuracy: 0.625\n",
      "Training loss: 0.540793, accuracy: 0.78125\n",
      "Training loss: 0.593417, accuracy: 0.71875\n",
      "Training loss: 0.517732, accuracy: 0.796875\n",
      "Training loss: 0.498411, accuracy: 0.75\n",
      "Training loss: 0.568624, accuracy: 0.6875\n",
      "Training loss: 0.534054, accuracy: 0.75\n",
      "Training loss: 0.68922, accuracy: 0.671875\n",
      "Training loss: 0.498055, accuracy: 0.78125\n",
      "Training loss: 0.57982, accuracy: 0.734375\n",
      "Training loss: 0.648332, accuracy: 0.65625\n",
      "Training loss: 0.606815, accuracy: 0.703125\n",
      "Training loss: 0.623369, accuracy: 0.734375\n",
      "Training loss: 0.602737, accuracy: 0.71875\n",
      "Training loss: 0.753922, accuracy: 0.59375\n",
      "Training loss: 0.542276, accuracy: 0.734375\n",
      "Training loss: 0.555152, accuracy: 0.703125\n",
      "Training loss: 0.533906, accuracy: 0.765625\n",
      "Training loss: 0.593684, accuracy: 0.65625\n",
      "Training loss: 0.499831, accuracy: 0.796875\n",
      "Training loss: 0.558404, accuracy: 0.75\n",
      "Training loss: 0.565219, accuracy: 0.75\n",
      "Training loss: 0.646569, accuracy: 0.65625\n",
      "Training loss: 0.564669, accuracy: 0.671875\n",
      "Training loss: 0.682592, accuracy: 0.5625\n",
      "Training loss: 0.600444, accuracy: 0.65625\n",
      "Training loss: 0.605452, accuracy: 0.609375\n",
      "Training loss: 0.602068, accuracy: 0.734375\n",
      "Training loss: 0.577871, accuracy: 0.6875\n",
      "Training loss: 0.635593, accuracy: 0.65625\n",
      "Training loss: 0.652297, accuracy: 0.640625\n",
      "Training loss: 0.596364, accuracy: 0.71875\n",
      "Training loss: 0.647636, accuracy: 0.609375\n",
      "Training loss: 0.660573, accuracy: 0.65625\n",
      "Training loss: 0.55905, accuracy: 0.6875\n",
      "Training loss: 0.557097, accuracy: 0.75\n",
      "Training loss: 0.636025, accuracy: 0.65625\n",
      "Training loss: 0.58106, accuracy: 0.65625\n",
      "Training loss: 0.582912, accuracy: 0.6875\n",
      "Training loss: 0.655589, accuracy: 0.640625\n",
      "Training loss: 0.591121, accuracy: 0.71875\n",
      "Training loss: 0.637005, accuracy: 0.65625\n",
      "Training loss: 0.567305, accuracy: 0.703125\n",
      "Training loss: 0.613113, accuracy: 0.640625\n",
      "Training loss: 0.647545, accuracy: 0.65625\n",
      "Training loss: 0.502632, accuracy: 0.78125\n",
      "Training loss: 0.538414, accuracy: 0.703125\n",
      "Training loss: 0.582676, accuracy: 0.734375\n",
      "Training loss: 0.539176, accuracy: 0.765625\n",
      "Training loss: 0.670349, accuracy: 0.625\n",
      "Training loss: 0.655585, accuracy: 0.609375\n",
      "Training loss: 0.558558, accuracy: 0.6875\n",
      "Training loss: 0.566658, accuracy: 0.734375\n",
      "Training loss: 0.476539, accuracy: 0.765625\n",
      "Training loss: 0.576675, accuracy: 0.703125\n",
      "Training loss: 0.525429, accuracy: 0.734375\n",
      "Training loss: 0.502746, accuracy: 0.75\n",
      "Training loss: 0.568596, accuracy: 0.703125\n",
      "Training loss: 0.521453, accuracy: 0.765625\n",
      "Training loss: 0.517072, accuracy: 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.582783, accuracy: 0.703125\n",
      "Training loss: 0.530977, accuracy: 0.78125\n",
      "Training loss: 0.517983, accuracy: 0.734375\n",
      "Training loss: 0.495196, accuracy: 0.75\n",
      "Training loss: 0.58221, accuracy: 0.671875\n",
      "Training loss: 0.525913, accuracy: 0.765625\n",
      "Training loss: 0.661318, accuracy: 0.59375\n",
      "Training loss: 0.610573, accuracy: 0.65625\n",
      "Training loss: 0.575557, accuracy: 0.703125\n",
      "Training loss: 0.611838, accuracy: 0.6875\n",
      "Training loss: 0.587651, accuracy: 0.671875\n",
      "Training loss: 0.635901, accuracy: 0.625\n",
      "Training loss: 0.657052, accuracy: 0.578125\n",
      "Training loss: 0.52687, accuracy: 0.734375\n",
      "Training loss: 0.621859, accuracy: 0.703125\n",
      "Training loss: 0.501115, accuracy: 0.71875\n",
      "Training loss: 0.60539, accuracy: 0.640625\n",
      "Training loss: 0.607741, accuracy: 0.671875\n",
      "Training loss: 0.67975, accuracy: 0.625\n",
      "Training loss: 0.598433, accuracy: 0.703125\n",
      "Training loss: 0.630754, accuracy: 0.6875\n",
      "Training loss: 0.647663, accuracy: 0.640625\n",
      "Training loss: 0.539117, accuracy: 0.8125\n",
      "Training loss: 0.64959, accuracy: 0.703125\n",
      "Training loss: 0.568765, accuracy: 0.671875\n",
      "Training loss: 0.540445, accuracy: 0.75\n",
      "Training loss: 0.613913, accuracy: 0.640625\n",
      "Training loss: 0.524876, accuracy: 0.765625\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 400: validation accuracy 0.68288 ----------------\n",
      "Training loss: 0.640115, accuracy: 0.59375\n",
      "Training loss: 0.588611, accuracy: 0.6875\n",
      "Training loss: 0.602659, accuracy: 0.65625\n",
      "Training loss: 0.546863, accuracy: 0.78125\n",
      "Training loss: 0.547861, accuracy: 0.765625\n",
      "Training loss: 0.518134, accuracy: 0.75\n",
      "Training loss: 0.582512, accuracy: 0.671875\n",
      "Training loss: 0.421848, accuracy: 0.8125\n",
      "Training loss: 0.483607, accuracy: 0.78125\n",
      "Training loss: 0.561653, accuracy: 0.75\n",
      "Training loss: 0.577818, accuracy: 0.71875\n",
      "Training loss: 0.414002, accuracy: 0.8125\n",
      "Training loss: 0.410513, accuracy: 0.84375\n",
      "Training loss: 0.511488, accuracy: 0.703125\n",
      "Training loss: 0.553148, accuracy: 0.765625\n",
      "Training loss: 0.44877, accuracy: 0.8125\n",
      "Training loss: 0.456369, accuracy: 0.796875\n",
      "Training loss: 0.40616, accuracy: 0.828125\n",
      "Training loss: 0.545568, accuracy: 0.75\n",
      "Training loss: 0.508141, accuracy: 0.78125\n",
      "Training loss: 0.522159, accuracy: 0.796875\n",
      "Training loss: 0.587525, accuracy: 0.671875\n",
      "Training loss: 0.538318, accuracy: 0.78125\n",
      "Training loss: 0.538765, accuracy: 0.8125\n",
      "Training loss: 0.582578, accuracy: 0.703125\n",
      "Training loss: 0.503895, accuracy: 0.796875\n",
      "Training loss: 0.458454, accuracy: 0.8125\n",
      "Training loss: 0.520663, accuracy: 0.78125\n",
      "Training loss: 0.541701, accuracy: 0.75\n",
      "Training loss: 0.583371, accuracy: 0.71875\n",
      "Training loss: 0.534013, accuracy: 0.765625\n",
      "Training loss: 0.582668, accuracy: 0.65625\n",
      "Training loss: 0.495479, accuracy: 0.796875\n",
      "Training loss: 0.556116, accuracy: 0.765625\n",
      "Training loss: 0.582705, accuracy: 0.671875\n",
      "Training loss: 0.512418, accuracy: 0.765625\n",
      "Training loss: 0.544791, accuracy: 0.734375\n",
      "Training loss: 0.447233, accuracy: 0.78125\n",
      "Training loss: 0.471176, accuracy: 0.765625\n",
      "Training loss: 0.605484, accuracy: 0.703125\n",
      "Training loss: 0.445894, accuracy: 0.8125\n",
      "Training loss: 0.466245, accuracy: 0.828125\n",
      "Training loss: 0.592642, accuracy: 0.65625\n",
      "Training loss: 0.518088, accuracy: 0.8125\n",
      "Training loss: 0.591179, accuracy: 0.703125\n",
      "Training loss: 0.500082, accuracy: 0.765625\n",
      "Training loss: 0.589334, accuracy: 0.703125\n",
      "Training loss: 0.52475, accuracy: 0.734375\n",
      "Training loss: 0.442178, accuracy: 0.796875\n",
      "Training loss: 0.500753, accuracy: 0.796875\n",
      "Training loss: 0.626692, accuracy: 0.671875\n",
      "Training loss: 0.468187, accuracy: 0.796875\n",
      "Training loss: 0.548908, accuracy: 0.78125\n",
      "Training loss: 0.488588, accuracy: 0.8125\n",
      "Training loss: 0.593661, accuracy: 0.703125\n",
      "Training loss: 0.513471, accuracy: 0.734375\n",
      "Training loss: 0.427236, accuracy: 0.828125\n",
      "Training loss: 0.505282, accuracy: 0.828125\n",
      "Training loss: 0.468964, accuracy: 0.84375\n",
      "Training loss: 0.384032, accuracy: 0.859375\n",
      "Training loss: 0.472581, accuracy: 0.765625\n",
      "Training loss: 0.501762, accuracy: 0.75\n",
      "Training loss: 0.445424, accuracy: 0.796875\n",
      "Training loss: 0.407053, accuracy: 0.828125\n",
      "Training loss: 0.414042, accuracy: 0.828125\n",
      "Training loss: 0.650412, accuracy: 0.71875\n",
      "Training loss: 0.555213, accuracy: 0.75\n",
      "Training loss: 0.521501, accuracy: 0.78125\n",
      "Training loss: 0.458984, accuracy: 0.84375\n",
      "Training loss: 0.427628, accuracy: 0.765625\n",
      "Training loss: 0.553913, accuracy: 0.75\n",
      "Training loss: 0.383788, accuracy: 0.84375\n",
      "Training loss: 0.447362, accuracy: 0.8125\n",
      "Training loss: 0.443292, accuracy: 0.84375\n",
      "Training loss: 0.448372, accuracy: 0.8125\n",
      "Training loss: 0.388704, accuracy: 0.828125\n",
      "Training loss: 0.473706, accuracy: 0.734375\n",
      "Training loss: 0.485986, accuracy: 0.796875\n",
      "Training loss: 0.382531, accuracy: 0.8125\n",
      "Training loss: 0.589807, accuracy: 0.75\n",
      "Training loss: 0.520771, accuracy: 0.765625\n",
      "Training loss: 0.457589, accuracy: 0.78125\n",
      "Training loss: 0.379592, accuracy: 0.890625\n",
      "Training loss: 0.415354, accuracy: 0.84375\n",
      "Training loss: 0.671342, accuracy: 0.75\n",
      "Training loss: 0.483666, accuracy: 0.796875\n",
      "Training loss: 0.546352, accuracy: 0.75\n",
      "Training loss: 0.514349, accuracy: 0.71875\n",
      "Training loss: 0.476726, accuracy: 0.78125\n",
      "Training loss: 0.353142, accuracy: 0.875\n",
      "Training loss: 0.447761, accuracy: 0.8125\n",
      "Training loss: 0.429427, accuracy: 0.828125\n",
      "Training loss: 0.379238, accuracy: 0.859375\n",
      "Training loss: 0.528493, accuracy: 0.8125\n",
      "Training loss: 0.444143, accuracy: 0.828125\n",
      "Training loss: 0.403844, accuracy: 0.859375\n",
      "Training loss: 0.367495, accuracy: 0.8125\n",
      "Training loss: 0.485704, accuracy: 0.765625\n",
      "Training loss: 0.420273, accuracy: 0.8125\n",
      "Training loss: 0.555419, accuracy: 0.78125\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 500: validation accuracy 0.78144 ----------------\n",
      "Training loss: 0.505016, accuracy: 0.765625\n",
      "Training loss: 0.429452, accuracy: 0.859375\n",
      "Training loss: 0.43041, accuracy: 0.84375\n",
      "Training loss: 0.48605, accuracy: 0.8125\n",
      "Training loss: 0.545762, accuracy: 0.765625\n",
      "Training loss: 0.428803, accuracy: 0.828125\n",
      "Training loss: 0.566029, accuracy: 0.765625\n",
      "Training loss: 0.55193, accuracy: 0.71875\n",
      "Training loss: 0.456927, accuracy: 0.84375\n",
      "Training loss: 0.465487, accuracy: 0.78125\n",
      "Training loss: 0.454084, accuracy: 0.796875\n",
      "Training loss: 0.66717, accuracy: 0.671875\n",
      "Training loss: 0.456853, accuracy: 0.796875\n",
      "Training loss: 0.415991, accuracy: 0.84375\n",
      "Training loss: 0.397208, accuracy: 0.8125\n",
      "Training loss: 0.395402, accuracy: 0.859375\n",
      "Training loss: 0.504811, accuracy: 0.796875\n",
      "Training loss: 0.437994, accuracy: 0.84375\n",
      "Training loss: 0.426205, accuracy: 0.8125\n",
      "Training loss: 0.548224, accuracy: 0.734375\n",
      "Training loss: 0.60754, accuracy: 0.71875\n",
      "Training loss: 0.383213, accuracy: 0.828125\n",
      "Training loss: 0.49884, accuracy: 0.75\n",
      "Training loss: 0.425757, accuracy: 0.796875\n",
      "Training loss: 0.412423, accuracy: 0.84375\n",
      "Training loss: 0.374158, accuracy: 0.84375\n",
      "Training loss: 0.432262, accuracy: 0.765625\n",
      "Training loss: 0.336047, accuracy: 0.890625\n",
      "Training loss: 0.356988, accuracy: 0.875\n",
      "Training loss: 0.306357, accuracy: 0.921875\n",
      "Training loss: 0.49544, accuracy: 0.765625\n",
      "Training loss: 0.292669, accuracy: 0.84375\n",
      "Training loss: 0.580395, accuracy: 0.78125\n",
      "Training loss: 0.413193, accuracy: 0.84375\n",
      "Training loss: 0.348654, accuracy: 0.828125\n",
      "Training loss: 0.254669, accuracy: 0.90625\n",
      "Training loss: 0.507493, accuracy: 0.828125\n",
      "Training loss: 0.570412, accuracy: 0.8125\n",
      "Training loss: 0.366504, accuracy: 0.921875\n",
      "Training loss: 0.451204, accuracy: 0.828125\n",
      "Training loss: 0.301034, accuracy: 0.859375\n",
      "Training loss: 0.47553, accuracy: 0.765625\n",
      "Training loss: 0.42478, accuracy: 0.828125\n",
      "Training loss: 0.462653, accuracy: 0.796875\n",
      "Training loss: 0.493778, accuracy: 0.796875\n",
      "Training loss: 0.420018, accuracy: 0.796875\n",
      "Training loss: 0.359612, accuracy: 0.828125\n",
      "Training loss: 0.331032, accuracy: 0.890625\n",
      "Training loss: 0.31461, accuracy: 0.90625\n",
      "Training loss: 0.451396, accuracy: 0.828125\n",
      "Training loss: 0.466686, accuracy: 0.75\n",
      "Training loss: 0.363433, accuracy: 0.8125\n",
      "Training loss: 0.464196, accuracy: 0.765625\n",
      "Training loss: 0.367148, accuracy: 0.84375\n",
      "Training loss: 0.329524, accuracy: 0.828125\n",
      "Training loss: 0.40042, accuracy: 0.859375\n",
      "Training loss: 0.39619, accuracy: 0.78125\n",
      "Training loss: 0.323369, accuracy: 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.42219, accuracy: 0.828125\n",
      "Training loss: 0.406066, accuracy: 0.796875\n",
      "Training loss: 0.36697, accuracy: 0.859375\n",
      "Training loss: 0.544508, accuracy: 0.78125\n",
      "Training loss: 0.472953, accuracy: 0.8125\n",
      "Training loss: 0.211684, accuracy: 0.953125\n",
      "Training loss: 0.368324, accuracy: 0.828125\n",
      "Training loss: 0.330749, accuracy: 0.875\n",
      "Training loss: 0.282374, accuracy: 0.90625\n",
      "Training loss: 0.513495, accuracy: 0.765625\n",
      "Training loss: 0.462114, accuracy: 0.828125\n",
      "Training loss: 0.315551, accuracy: 0.890625\n",
      "Training loss: 0.404075, accuracy: 0.84375\n",
      "Training loss: 0.48911, accuracy: 0.765625\n",
      "Training loss: 0.502505, accuracy: 0.796875\n",
      "Training loss: 0.374929, accuracy: 0.828125\n",
      "Training loss: 0.358091, accuracy: 0.859375\n",
      "Training loss: 0.283219, accuracy: 0.921875\n",
      "Training loss: 0.379041, accuracy: 0.890625\n",
      "Training loss: 0.371063, accuracy: 0.84375\n",
      "Training loss: 0.372571, accuracy: 0.828125\n",
      "Training loss: 0.339703, accuracy: 0.875\n",
      "Training loss: 0.568425, accuracy: 0.734375\n",
      "Training loss: 0.475806, accuracy: 0.796875\n",
      "Training loss: 0.398956, accuracy: 0.875\n",
      "Training loss: 0.384596, accuracy: 0.8125\n",
      "Training loss: 0.416379, accuracy: 0.828125\n",
      "Training loss: 0.434416, accuracy: 0.828125\n",
      "Training loss: 0.390514, accuracy: 0.8125\n",
      "Training loss: 0.294063, accuracy: 0.90625\n",
      "Training loss: 0.578393, accuracy: 0.734375\n",
      "Training loss: 0.350537, accuracy: 0.84375\n",
      "Training loss: 0.380278, accuracy: 0.84375\n",
      "Training loss: 0.399458, accuracy: 0.78125\n",
      "Training loss: 0.443548, accuracy: 0.8125\n",
      "Training loss: 0.310246, accuracy: 0.875\n",
      "Training loss: 0.392228, accuracy: 0.859375\n",
      "Training loss: 0.370944, accuracy: 0.828125\n",
      "Training loss: 0.503966, accuracy: 0.765625\n",
      "Training loss: 0.42436, accuracy: 0.828125\n",
      "Training loss: 0.429208, accuracy: 0.796875\n",
      "Training loss: 0.400571, accuracy: 0.84375\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 600: validation accuracy 0.79776 ----------------\n",
      "Training loss: 0.445801, accuracy: 0.8125\n",
      "Training loss: 0.38821, accuracy: 0.84375\n",
      "Training loss: 0.411323, accuracy: 0.859375\n",
      "Training loss: 0.403914, accuracy: 0.828125\n",
      "Training loss: 0.343347, accuracy: 0.875\n",
      "Training loss: 0.433215, accuracy: 0.78125\n",
      "Training loss: 0.406201, accuracy: 0.84375\n",
      "Training loss: 0.423726, accuracy: 0.828125\n",
      "Training loss: 0.244812, accuracy: 0.9375\n",
      "Training loss: 0.350146, accuracy: 0.859375\n",
      "Training loss: 0.478885, accuracy: 0.8125\n",
      "Training loss: 0.306992, accuracy: 0.875\n",
      "Training loss: 0.546589, accuracy: 0.734375\n",
      "Training loss: 0.383963, accuracy: 0.828125\n",
      "Training loss: 0.471704, accuracy: 0.78125\n",
      "Training loss: 0.44283, accuracy: 0.828125\n",
      "Training loss: 0.375109, accuracy: 0.859375\n",
      "Training loss: 0.415755, accuracy: 0.84375\n",
      "Training loss: 0.414385, accuracy: 0.84375\n",
      "Training loss: 0.584932, accuracy: 0.78125\n",
      "Training loss: 0.415269, accuracy: 0.796875\n",
      "Training loss: 0.444498, accuracy: 0.84375\n",
      "Training loss: 0.298269, accuracy: 0.90625\n",
      "Training loss: 0.456713, accuracy: 0.8125\n",
      "Training loss: 0.333973, accuracy: 0.890625\n",
      "Training loss: 0.346583, accuracy: 0.875\n",
      "Training loss: 0.441535, accuracy: 0.84375\n",
      "Training loss: 0.332623, accuracy: 0.9375\n",
      "Training loss: 0.34776, accuracy: 0.84375\n",
      "Training loss: 0.438364, accuracy: 0.828125\n",
      "Training loss: 0.317866, accuracy: 0.890625\n",
      "Training loss: 0.356228, accuracy: 0.859375\n",
      "Training loss: 0.337245, accuracy: 0.875\n",
      "Training loss: 0.358963, accuracy: 0.84375\n",
      "Training loss: 0.336387, accuracy: 0.875\n",
      "Training loss: 0.401279, accuracy: 0.796875\n",
      "Training loss: 0.257001, accuracy: 0.90625\n",
      "Training loss: 0.452198, accuracy: 0.859375\n",
      "Training loss: 0.262743, accuracy: 0.921875\n",
      "Training loss: 0.282723, accuracy: 0.90625\n",
      "Training loss: 0.381097, accuracy: 0.890625\n",
      "Training loss: 0.570576, accuracy: 0.765625\n",
      "Training loss: 0.344748, accuracy: 0.828125\n",
      "Training loss: 0.395059, accuracy: 0.84375\n",
      "Training loss: 0.430467, accuracy: 0.796875\n",
      "Training loss: 0.362481, accuracy: 0.84375\n",
      "Training loss: 0.415079, accuracy: 0.84375\n",
      "Training loss: 0.317562, accuracy: 0.859375\n",
      "Training loss: 0.570659, accuracy: 0.75\n",
      "Training loss: 0.366869, accuracy: 0.84375\n",
      "Training loss: 0.2417, accuracy: 0.921875\n",
      "Training loss: 0.425143, accuracy: 0.859375\n",
      "Training loss: 0.318473, accuracy: 0.890625\n",
      "Training loss: 0.364193, accuracy: 0.84375\n",
      "Training loss: 0.411179, accuracy: 0.859375\n",
      "Training loss: 0.345133, accuracy: 0.875\n",
      "Training loss: 0.214517, accuracy: 0.9375\n",
      "Training loss: 0.302054, accuracy: 0.890625\n",
      "Training loss: 0.313705, accuracy: 0.875\n",
      "Training loss: 0.400895, accuracy: 0.84375\n",
      "Training loss: 0.257482, accuracy: 0.921875\n",
      "Training loss: 0.276748, accuracy: 0.875\n",
      "Training loss: 0.456548, accuracy: 0.78125\n",
      "Training loss: 0.406189, accuracy: 0.84375\n",
      "Training loss: 0.412339, accuracy: 0.796875\n",
      "Training loss: 0.317072, accuracy: 0.890625\n",
      "Training loss: 0.280299, accuracy: 0.890625\n",
      "Training loss: 0.478886, accuracy: 0.8125\n",
      "Training loss: 0.392637, accuracy: 0.8125\n",
      "Training loss: 0.333432, accuracy: 0.875\n",
      "Training loss: 0.341722, accuracy: 0.859375\n",
      "Training loss: 0.340467, accuracy: 0.828125\n",
      "Training loss: 0.462584, accuracy: 0.796875\n",
      "Training loss: 0.356215, accuracy: 0.828125\n",
      "Training loss: 0.347412, accuracy: 0.859375\n",
      "Training loss: 0.281541, accuracy: 0.890625\n",
      "Training loss: 0.322152, accuracy: 0.859375\n",
      "Training loss: 0.338171, accuracy: 0.859375\n",
      "Training loss: 0.358569, accuracy: 0.859375\n",
      "Training loss: 0.372676, accuracy: 0.828125\n",
      "Training loss: 0.234062, accuracy: 0.90625\n",
      "Training loss: 0.390714, accuracy: 0.8125\n",
      "Training loss: 0.39707, accuracy: 0.84375\n",
      "Training loss: 0.363671, accuracy: 0.875\n",
      "Training loss: 0.450891, accuracy: 0.78125\n",
      "Training loss: 0.318538, accuracy: 0.890625\n",
      "Training loss: 0.454509, accuracy: 0.78125\n",
      "Training loss: 0.338751, accuracy: 0.84375\n",
      "Training loss: 0.519843, accuracy: 0.765625\n",
      "Training loss: 0.330618, accuracy: 0.859375\n",
      "Training loss: 0.400477, accuracy: 0.84375\n",
      "Training loss: 0.330182, accuracy: 0.890625\n",
      "Training loss: 0.303676, accuracy: 0.875\n",
      "Training loss: 0.557065, accuracy: 0.75\n",
      "Training loss: 0.433905, accuracy: 0.75\n",
      "Training loss: 0.468066, accuracy: 0.8125\n",
      "Training loss: 0.31902, accuracy: 0.890625\n",
      "Training loss: 0.43084, accuracy: 0.796875\n",
      "Training loss: 0.386768, accuracy: 0.859375\n",
      "Training loss: 0.31279, accuracy: 0.859375\n",
      "----------------- Step 700: validation accuracy 0.788 ----------------\n",
      "Training loss: 0.314915, accuracy: 0.875\n",
      "Training loss: 0.370375, accuracy: 0.875\n",
      "Training loss: 0.326222, accuracy: 0.828125\n",
      "Training loss: 0.331669, accuracy: 0.875\n",
      "Training loss: 0.190949, accuracy: 0.953125\n",
      "Training loss: 0.313339, accuracy: 0.859375\n",
      "Training loss: 0.272538, accuracy: 0.890625\n",
      "Training loss: 0.308446, accuracy: 0.875\n",
      "Training loss: 0.256504, accuracy: 0.890625\n",
      "Training loss: 0.372476, accuracy: 0.859375\n",
      "Training loss: 0.238973, accuracy: 0.921875\n",
      "Training loss: 0.388178, accuracy: 0.875\n",
      "Training loss: 0.326678, accuracy: 0.921875\n",
      "Training loss: 0.327494, accuracy: 0.890625\n",
      "Training loss: 0.370097, accuracy: 0.8125\n",
      "Training loss: 0.405378, accuracy: 0.828125\n",
      "Training loss: 0.338704, accuracy: 0.84375\n",
      "Training loss: 0.488384, accuracy: 0.796875\n",
      "Training loss: 0.317592, accuracy: 0.859375\n",
      "Training loss: 0.255002, accuracy: 0.90625\n",
      "Training loss: 0.25914, accuracy: 0.921875\n",
      "Training loss: 0.408131, accuracy: 0.84375\n",
      "Training loss: 0.372867, accuracy: 0.8125\n",
      "Training loss: 0.384302, accuracy: 0.890625\n",
      "Training loss: 0.436104, accuracy: 0.828125\n",
      "Training loss: 0.309215, accuracy: 0.859375\n",
      "Training loss: 0.285283, accuracy: 0.875\n",
      "Training loss: 0.401078, accuracy: 0.828125\n",
      "Training loss: 0.336639, accuracy: 0.84375\n",
      "Training loss: 0.29132, accuracy: 0.921875\n",
      "Training loss: 0.296213, accuracy: 0.875\n",
      "Training loss: 0.302782, accuracy: 0.890625\n",
      "Training loss: 0.370596, accuracy: 0.828125\n",
      "Training loss: 0.336606, accuracy: 0.859375\n",
      "Training loss: 0.383552, accuracy: 0.84375\n",
      "Training loss: 0.363505, accuracy: 0.84375\n",
      "Training loss: 0.332878, accuracy: 0.875\n",
      "Training loss: 0.425899, accuracy: 0.859375\n",
      "Training loss: 0.2249, accuracy: 0.90625\n",
      "Training loss: 0.398013, accuracy: 0.875\n",
      "Training loss: 0.374351, accuracy: 0.84375\n",
      "Training loss: 0.227697, accuracy: 0.9375\n",
      "Training loss: 0.382782, accuracy: 0.828125\n",
      "Training loss: 0.477442, accuracy: 0.859375\n",
      "Training loss: 0.302853, accuracy: 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.261173, accuracy: 0.890625\n",
      "Training loss: 0.333395, accuracy: 0.890625\n",
      "Training loss: 0.336609, accuracy: 0.890625\n",
      "Training loss: 0.317698, accuracy: 0.859375\n",
      "Training loss: 0.340766, accuracy: 0.890625\n",
      "Training loss: 0.282659, accuracy: 0.875\n",
      "Training loss: 0.275991, accuracy: 0.890625\n",
      "Training loss: 0.193476, accuracy: 0.9375\n",
      "Training loss: 0.399733, accuracy: 0.828125\n",
      "Training loss: 0.328709, accuracy: 0.890625\n",
      "Training loss: 0.374391, accuracy: 0.84375\n",
      "Training loss: 0.265118, accuracy: 0.90625\n",
      "Training loss: 0.245358, accuracy: 0.9375\n",
      "Training loss: 0.3329, accuracy: 0.875\n",
      "Training loss: 0.388867, accuracy: 0.84375\n",
      "Training loss: 0.378735, accuracy: 0.828125\n",
      "Training loss: 0.426134, accuracy: 0.859375\n",
      "Training loss: 0.195414, accuracy: 0.9375\n",
      "Training loss: 0.352516, accuracy: 0.890625\n",
      "Training loss: 0.16574, accuracy: 0.953125\n",
      "Training loss: 0.205717, accuracy: 0.953125\n",
      "Training loss: 0.270386, accuracy: 0.890625\n",
      "Training loss: 0.210267, accuracy: 0.921875\n",
      "Training loss: 0.31566, accuracy: 0.890625\n",
      "Training loss: 0.31376, accuracy: 0.859375\n",
      "Training loss: 0.314982, accuracy: 0.90625\n",
      "Training loss: 0.265524, accuracy: 0.921875\n",
      "Training loss: 0.548001, accuracy: 0.78125\n",
      "Training loss: 0.502366, accuracy: 0.828125\n",
      "Training loss: 0.334862, accuracy: 0.859375\n",
      "Training loss: 0.239611, accuracy: 0.921875\n",
      "Training loss: 0.211067, accuracy: 0.921875\n",
      "Training loss: 0.454558, accuracy: 0.828125\n",
      "Training loss: 0.352744, accuracy: 0.875\n",
      "Training loss: 0.326252, accuracy: 0.859375\n",
      "Training loss: 0.372996, accuracy: 0.796875\n",
      "Training loss: 0.304702, accuracy: 0.890625\n",
      "Training loss: 0.192371, accuracy: 0.96875\n",
      "Training loss: 0.254575, accuracy: 0.921875\n",
      "Training loss: 0.287847, accuracy: 0.875\n",
      "Training loss: 0.239776, accuracy: 0.921875\n",
      "Training loss: 0.361796, accuracy: 0.859375\n",
      "Training loss: 0.284511, accuracy: 0.890625\n",
      "Training loss: 0.260672, accuracy: 0.921875\n",
      "Training loss: 0.156333, accuracy: 0.953125\n",
      "Training loss: 0.439558, accuracy: 0.8125\n",
      "Training loss: 0.2196, accuracy: 0.953125\n",
      "Training loss: 0.400202, accuracy: 0.84375\n",
      "Training loss: 0.302319, accuracy: 0.921875\n",
      "Training loss: 0.224305, accuracy: 0.921875\n",
      "Training loss: 0.261602, accuracy: 0.921875\n",
      "Training loss: 0.380744, accuracy: 0.875\n",
      "Training loss: 0.494544, accuracy: 0.84375\n",
      "Training loss: 0.308605, accuracy: 0.875\n",
      "Training loss: 0.332124, accuracy: 0.890625\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 800: validation accuracy 0.83744 ----------------\n",
      "Training loss: 0.4501, accuracy: 0.859375\n",
      "Training loss: 0.196817, accuracy: 0.953125\n",
      "Training loss: 0.412243, accuracy: 0.828125\n",
      "Training loss: 0.28651, accuracy: 0.90625\n",
      "Training loss: 0.545436, accuracy: 0.78125\n",
      "Training loss: 0.421402, accuracy: 0.828125\n",
      "Training loss: 0.338118, accuracy: 0.890625\n",
      "Training loss: 0.329991, accuracy: 0.875\n",
      "Training loss: 0.273174, accuracy: 0.921875\n",
      "Training loss: 0.388955, accuracy: 0.890625\n",
      "Training loss: 0.333336, accuracy: 0.875\n",
      "Training loss: 0.330122, accuracy: 0.875\n",
      "Training loss: 0.355054, accuracy: 0.859375\n",
      "Training loss: 0.331326, accuracy: 0.84375\n",
      "Training loss: 0.300353, accuracy: 0.875\n",
      "Training loss: 0.325146, accuracy: 0.875\n",
      "Training loss: 0.30552, accuracy: 0.859375\n",
      "Training loss: 0.302958, accuracy: 0.890625\n",
      "Training loss: 0.29506, accuracy: 0.875\n",
      "Training loss: 0.241172, accuracy: 0.921875\n",
      "Training loss: 0.170534, accuracy: 0.953125\n",
      "Training loss: 0.255079, accuracy: 0.921875\n",
      "Training loss: 0.209256, accuracy: 0.9375\n",
      "Training loss: 0.296018, accuracy: 0.859375\n",
      "Training loss: 0.156595, accuracy: 0.90625\n",
      "Training loss: 0.309526, accuracy: 0.90625\n",
      "Training loss: 0.184936, accuracy: 0.953125\n",
      "Training loss: 0.187939, accuracy: 0.96875\n",
      "Training loss: 0.161103, accuracy: 0.953125\n",
      "Training loss: 0.374954, accuracy: 0.84375\n",
      "Training loss: 0.358194, accuracy: 0.890625\n",
      "Training loss: 0.314252, accuracy: 0.875\n",
      "Training loss: 0.205384, accuracy: 0.953125\n",
      "Training loss: 0.12564, accuracy: 0.9375\n",
      "Training loss: 0.526499, accuracy: 0.8125\n",
      "Training loss: 0.454201, accuracy: 0.875\n",
      "Training loss: 0.218565, accuracy: 0.921875\n",
      "Training loss: 0.409394, accuracy: 0.859375\n",
      "Training loss: 0.260929, accuracy: 0.859375\n",
      "Training loss: 0.258618, accuracy: 0.921875\n",
      "Training loss: 0.169435, accuracy: 0.96875\n",
      "Training loss: 0.205548, accuracy: 0.921875\n",
      "Training loss: 0.211801, accuracy: 0.9375\n",
      "Training loss: 0.3565, accuracy: 0.875\n",
      "Training loss: 0.25763, accuracy: 0.921875\n",
      "Training loss: 0.339849, accuracy: 0.875\n",
      "Training loss: 0.315411, accuracy: 0.875\n",
      "Training loss: 0.324902, accuracy: 0.875\n",
      "Training loss: 0.358642, accuracy: 0.875\n",
      "Training loss: 0.272986, accuracy: 0.90625\n",
      "Training loss: 0.247675, accuracy: 0.890625\n",
      "Training loss: 0.301765, accuracy: 0.890625\n",
      "Training loss: 0.28694, accuracy: 0.875\n",
      "Training loss: 0.307372, accuracy: 0.890625\n",
      "Training loss: 0.245897, accuracy: 0.90625\n",
      "Training loss: 0.364004, accuracy: 0.859375\n",
      "Training loss: 0.10308, accuracy: 0.984375\n",
      "Training loss: 0.286804, accuracy: 0.890625\n",
      "Training loss: 0.28525, accuracy: 0.84375\n",
      "Training loss: 0.266338, accuracy: 0.9375\n",
      "Training loss: 0.220136, accuracy: 0.90625\n",
      "Training loss: 0.255572, accuracy: 0.921875\n",
      "Training loss: 0.206508, accuracy: 0.921875\n",
      "Training loss: 0.223261, accuracy: 0.9375\n",
      "Training loss: 0.261749, accuracy: 0.875\n",
      "Training loss: 0.312528, accuracy: 0.890625\n",
      "Training loss: 0.136526, accuracy: 0.96875\n",
      "Training loss: 0.269094, accuracy: 0.875\n",
      "Training loss: 0.212712, accuracy: 0.921875\n",
      "Training loss: 0.49675, accuracy: 0.84375\n",
      "Training loss: 0.280235, accuracy: 0.90625\n",
      "Training loss: 0.227089, accuracy: 0.921875\n",
      "Training loss: 0.129403, accuracy: 0.9375\n",
      "Training loss: 0.433558, accuracy: 0.859375\n",
      "Training loss: 0.378787, accuracy: 0.890625\n",
      "Training loss: 0.282903, accuracy: 0.875\n",
      "Training loss: 0.23996, accuracy: 0.90625\n",
      "Training loss: 0.317046, accuracy: 0.890625\n",
      "Training loss: 0.305995, accuracy: 0.921875\n",
      "Training loss: 0.204878, accuracy: 0.9375\n",
      "Training loss: 0.185069, accuracy: 0.953125\n",
      "Training loss: 0.544901, accuracy: 0.8125\n",
      "Training loss: 0.166355, accuracy: 0.96875\n",
      "Training loss: 0.271607, accuracy: 0.921875\n",
      "Training loss: 0.212378, accuracy: 0.9375\n",
      "Training loss: 0.214759, accuracy: 0.9375\n",
      "Training loss: 0.1631, accuracy: 0.953125\n",
      "Training loss: 0.235943, accuracy: 0.921875\n",
      "Training loss: 0.209377, accuracy: 0.9375\n",
      "Training loss: 0.247832, accuracy: 0.90625\n",
      "Training loss: 0.238944, accuracy: 0.890625\n",
      "Training loss: 0.226404, accuracy: 0.921875\n",
      "Training loss: 0.218726, accuracy: 0.890625\n",
      "Training loss: 0.266894, accuracy: 0.90625\n",
      "Training loss: 0.225574, accuracy: 0.890625\n",
      "Training loss: 0.293828, accuracy: 0.90625\n",
      "Training loss: 0.184429, accuracy: 0.9375\n",
      "Training loss: 0.175037, accuracy: 0.9375\n",
      "Training loss: 0.397445, accuracy: 0.890625\n",
      "Training loss: 0.183208, accuracy: 0.953125\n",
      "----------------- Step 900: validation accuracy 0.83056 ----------------\n",
      "Training loss: 0.336657, accuracy: 0.875\n",
      "Training loss: 0.158098, accuracy: 0.96875\n",
      "Training loss: 0.213652, accuracy: 0.921875\n",
      "Training loss: 0.279834, accuracy: 0.890625\n",
      "Training loss: 0.172652, accuracy: 0.921875\n",
      "Training loss: 0.356586, accuracy: 0.859375\n",
      "Training loss: 0.246486, accuracy: 0.890625\n",
      "Training loss: 0.315496, accuracy: 0.859375\n",
      "Training loss: 0.326242, accuracy: 0.84375\n",
      "Training loss: 0.258305, accuracy: 0.90625\n",
      "Training loss: 0.460211, accuracy: 0.859375\n",
      "Training loss: 0.353371, accuracy: 0.859375\n",
      "Training loss: 0.401103, accuracy: 0.84375\n",
      "Training loss: 0.128868, accuracy: 0.984375\n",
      "Training loss: 0.367273, accuracy: 0.859375\n",
      "Training loss: 0.190606, accuracy: 0.921875\n",
      "Training loss: 0.32417, accuracy: 0.875\n",
      "Training loss: 0.224259, accuracy: 0.921875\n",
      "Training loss: 0.281843, accuracy: 0.875\n",
      "Training loss: 0.378582, accuracy: 0.875\n",
      "Training loss: 0.296061, accuracy: 0.890625\n",
      "Training loss: 0.2876, accuracy: 0.875\n",
      "Training loss: 0.389831, accuracy: 0.84375\n",
      "Training loss: 0.244829, accuracy: 0.90625\n",
      "Training loss: 0.227341, accuracy: 0.9375\n",
      "Training loss: 0.259982, accuracy: 0.90625\n",
      "Training loss: 0.183245, accuracy: 0.9375\n",
      "Training loss: 0.231303, accuracy: 0.953125\n",
      "Training loss: 0.213107, accuracy: 0.9375\n",
      "Training loss: 0.183954, accuracy: 0.9375\n",
      "Training loss: 0.366869, accuracy: 0.90625\n",
      "Training loss: 0.187359, accuracy: 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.150514, accuracy: 0.953125\n",
      "Training loss: 0.201078, accuracy: 0.953125\n",
      "Training loss: 0.405781, accuracy: 0.875\n",
      "Training loss: 0.202732, accuracy: 0.90625\n",
      "Training loss: 0.276117, accuracy: 0.90625\n",
      "Training loss: 0.291773, accuracy: 0.875\n",
      "Training loss: 0.191158, accuracy: 0.921875\n",
      "Training loss: 0.316553, accuracy: 0.890625\n",
      "Training loss: 0.222148, accuracy: 0.921875\n",
      "Training loss: 0.378765, accuracy: 0.875\n",
      "Training loss: 0.199402, accuracy: 0.921875\n",
      "Training loss: 0.215883, accuracy: 0.9375\n",
      "Training loss: 0.198521, accuracy: 0.921875\n",
      "Training loss: 0.317008, accuracy: 0.890625\n",
      "Training loss: 0.21672, accuracy: 0.9375\n",
      "Training loss: 0.378218, accuracy: 0.859375\n",
      "Training loss: 0.285682, accuracy: 0.90625\n",
      "Training loss: 0.132858, accuracy: 0.984375\n",
      "Training loss: 0.286478, accuracy: 0.90625\n",
      "Training loss: 0.164545, accuracy: 0.9375\n",
      "Training loss: 0.312223, accuracy: 0.875\n",
      "Training loss: 0.328904, accuracy: 0.921875\n",
      "Training loss: 0.217954, accuracy: 0.90625\n",
      "Training loss: 0.261446, accuracy: 0.9375\n",
      "Training loss: 0.314003, accuracy: 0.875\n",
      "Training loss: 0.250225, accuracy: 0.90625\n",
      "Training loss: 0.284185, accuracy: 0.90625\n",
      "Training loss: 0.227163, accuracy: 0.875\n",
      "Training loss: 0.435982, accuracy: 0.796875\n",
      "Training loss: 0.21562, accuracy: 0.890625\n",
      "Training loss: 0.214077, accuracy: 0.921875\n",
      "Training loss: 0.143365, accuracy: 0.953125\n",
      "Training loss: 0.163429, accuracy: 0.9375\n",
      "Training loss: 0.333141, accuracy: 0.890625\n",
      "Training loss: 0.212982, accuracy: 0.9375\n",
      "Training loss: 0.171783, accuracy: 0.953125\n",
      "Training loss: 0.188972, accuracy: 0.96875\n",
      "Training loss: 0.176873, accuracy: 0.9375\n",
      "Training loss: 0.285384, accuracy: 0.921875\n",
      "Training loss: 0.177359, accuracy: 0.9375\n",
      "Training loss: 0.262857, accuracy: 0.890625\n",
      "Training loss: 0.145237, accuracy: 0.953125\n",
      "Training loss: 0.260058, accuracy: 0.921875\n",
      "Training loss: 0.243402, accuracy: 0.90625\n",
      "Training loss: 0.182297, accuracy: 0.9375\n",
      "Training loss: 0.307377, accuracy: 0.859375\n",
      "Training loss: 0.138711, accuracy: 0.96875\n",
      "Training loss: 0.318499, accuracy: 0.859375\n",
      "Training loss: 0.234451, accuracy: 0.921875\n",
      "Training loss: 0.314405, accuracy: 0.875\n",
      "Training loss: 0.237739, accuracy: 0.9375\n",
      "Training loss: 0.235907, accuracy: 0.890625\n",
      "Training loss: 0.251925, accuracy: 0.921875\n",
      "Training loss: 0.158506, accuracy: 0.9375\n",
      "Training loss: 0.325632, accuracy: 0.859375\n",
      "Training loss: 0.264222, accuracy: 0.921875\n",
      "Training loss: 0.344383, accuracy: 0.859375\n",
      "Training loss: 0.242362, accuracy: 0.90625\n",
      "Training loss: 0.200641, accuracy: 0.90625\n",
      "Training loss: 0.324157, accuracy: 0.875\n",
      "Training loss: 0.282271, accuracy: 0.890625\n",
      "Training loss: 0.1427, accuracy: 0.9375\n",
      "Training loss: 0.248347, accuracy: 0.90625\n",
      "Training loss: 0.211925, accuracy: 0.921875\n",
      "Training loss: 0.265068, accuracy: 0.90625\n",
      "Training loss: 0.10203, accuracy: 0.984375\n",
      "Training loss: 0.14721, accuracy: 0.953125\n",
      "Training loss: 0.15584, accuracy: 0.953125\n",
      "----------------- Step 1000: validation accuracy 0.83472 ----------------\n",
      "Training loss: 0.179345, accuracy: 0.96875\n",
      "Training loss: 0.221564, accuracy: 0.9375\n",
      "Training loss: 0.201291, accuracy: 0.953125\n",
      "Training loss: 0.17811, accuracy: 0.890625\n",
      "Training loss: 0.260615, accuracy: 0.90625\n",
      "Training loss: 0.171997, accuracy: 0.9375\n",
      "Training loss: 0.156423, accuracy: 0.921875\n",
      "Training loss: 0.195868, accuracy: 0.921875\n",
      "Training loss: 0.281747, accuracy: 0.90625\n",
      "Training loss: 0.165266, accuracy: 0.9375\n",
      "Training loss: 0.251349, accuracy: 0.90625\n",
      "Training loss: 0.10654, accuracy: 0.9375\n",
      "Training loss: 0.177619, accuracy: 0.953125\n",
      "Training loss: 0.138285, accuracy: 0.96875\n",
      "Training loss: 0.39683, accuracy: 0.859375\n",
      "Training loss: 0.302545, accuracy: 0.890625\n",
      "Training loss: 0.359674, accuracy: 0.859375\n",
      "Training loss: 0.20555, accuracy: 0.921875\n",
      "Training loss: 0.108341, accuracy: 0.96875\n",
      "Training loss: 0.199488, accuracy: 0.9375\n",
      "Training loss: 0.251265, accuracy: 0.90625\n",
      "Training loss: 0.181358, accuracy: 0.921875\n",
      "Training loss: 0.113229, accuracy: 0.96875\n",
      "Training loss: 0.157809, accuracy: 0.953125\n",
      "Training loss: 0.200084, accuracy: 0.90625\n",
      "Training loss: 0.260791, accuracy: 0.921875\n",
      "Training loss: 0.206257, accuracy: 0.90625\n",
      "Training loss: 0.332431, accuracy: 0.84375\n",
      "Training loss: 0.235081, accuracy: 0.921875\n",
      "Training loss: 0.222652, accuracy: 0.9375\n",
      "Training loss: 0.328894, accuracy: 0.875\n",
      "Training loss: 0.161488, accuracy: 0.9375\n",
      "Training loss: 0.276097, accuracy: 0.921875\n",
      "Training loss: 0.199387, accuracy: 0.921875\n",
      "Training loss: 0.125983, accuracy: 0.96875\n",
      "Training loss: 0.243548, accuracy: 0.890625\n",
      "Training loss: 0.493909, accuracy: 0.78125\n",
      "Training loss: 0.227702, accuracy: 0.921875\n",
      "Training loss: 0.183437, accuracy: 0.921875\n",
      "Training loss: 0.258442, accuracy: 0.921875\n",
      "Training loss: 0.209494, accuracy: 0.890625\n",
      "Training loss: 0.262703, accuracy: 0.890625\n",
      "Training loss: 0.298091, accuracy: 0.90625\n",
      "Training loss: 0.188824, accuracy: 0.921875\n",
      "Training loss: 0.201347, accuracy: 0.953125\n",
      "Training loss: 0.156567, accuracy: 0.96875\n",
      "Training loss: 0.246428, accuracy: 0.90625\n",
      "Training loss: 0.211682, accuracy: 0.921875\n",
      "Training loss: 0.225699, accuracy: 0.90625\n",
      "Training loss: 0.251917, accuracy: 0.90625\n",
      "Training loss: 0.276104, accuracy: 0.921875\n",
      "Training loss: 0.23677, accuracy: 0.90625\n",
      "Training loss: 0.346282, accuracy: 0.890625\n",
      "Training loss: 0.205089, accuracy: 0.921875\n",
      "Training loss: 0.331637, accuracy: 0.859375\n",
      "Training loss: 0.159503, accuracy: 0.96875\n",
      "Training loss: 0.275967, accuracy: 0.921875\n",
      "Training loss: 0.198113, accuracy: 0.921875\n",
      "Training loss: 0.263798, accuracy: 0.921875\n",
      "Training loss: 0.157575, accuracy: 0.953125\n",
      "Training loss: 0.147934, accuracy: 0.953125\n",
      "Training loss: 0.245003, accuracy: 0.90625\n",
      "Training loss: 0.261147, accuracy: 0.921875\n",
      "Training loss: 0.263619, accuracy: 0.90625\n",
      "Training loss: 0.196335, accuracy: 0.9375\n",
      "Training loss: 0.261851, accuracy: 0.921875\n",
      "Training loss: 0.428962, accuracy: 0.84375\n",
      "Training loss: 0.198463, accuracy: 0.90625\n",
      "Training loss: 0.228225, accuracy: 0.9375\n",
      "Training loss: 0.183886, accuracy: 0.921875\n",
      "Training loss: 0.234567, accuracy: 0.921875\n",
      "Training loss: 0.273021, accuracy: 0.9375\n",
      "Training loss: 0.194917, accuracy: 0.921875\n",
      "Training loss: 0.296423, accuracy: 0.875\n",
      "Training loss: 0.203717, accuracy: 0.9375\n",
      "Training loss: 0.0931189, accuracy: 0.984375\n",
      "Training loss: 0.11527, accuracy: 0.96875\n",
      "Training loss: 0.124582, accuracy: 0.96875\n",
      "Training loss: 0.12064, accuracy: 0.984375\n",
      "Training loss: 0.309385, accuracy: 0.890625\n",
      "Training loss: 0.134826, accuracy: 0.9375\n",
      "Training loss: 0.143391, accuracy: 0.953125\n",
      "Training loss: 0.0847471, accuracy: 0.984375\n",
      "Training loss: 0.23313, accuracy: 0.9375\n",
      "Training loss: 0.125527, accuracy: 0.9375\n",
      "Training loss: 0.313647, accuracy: 0.90625\n",
      "Training loss: 0.146849, accuracy: 0.96875\n",
      "Training loss: 0.165335, accuracy: 0.9375\n",
      "Training loss: 0.110162, accuracy: 0.953125\n",
      "Training loss: 0.187907, accuracy: 0.921875\n",
      "Training loss: 0.382367, accuracy: 0.875\n",
      "Training loss: 0.210191, accuracy: 0.9375\n",
      "Training loss: 0.319496, accuracy: 0.875\n",
      "Training loss: 0.33341, accuracy: 0.921875\n",
      "Training loss: 0.14061, accuracy: 0.96875\n",
      "Training loss: 0.268592, accuracy: 0.890625\n",
      "Training loss: 0.152139, accuracy: 0.96875\n",
      "Training loss: 0.421848, accuracy: 0.859375\n",
      "Training loss: 0.402045, accuracy: 0.859375\n",
      "Training loss: 0.335538, accuracy: 0.90625\n",
      "----------------- Step 1100: validation accuracy 0.82448 ----------------\n",
      "Training loss: 0.250006, accuracy: 0.90625\n",
      "Training loss: 0.299332, accuracy: 0.90625\n",
      "Training loss: 0.313344, accuracy: 0.875\n",
      "Training loss: 0.193026, accuracy: 0.953125\n",
      "Training loss: 0.274111, accuracy: 0.890625\n",
      "Training loss: 0.293653, accuracy: 0.921875\n",
      "Training loss: 0.244823, accuracy: 0.875\n",
      "Training loss: 0.237627, accuracy: 0.90625\n",
      "Training loss: 0.272057, accuracy: 0.875\n",
      "Training loss: 0.17366, accuracy: 0.921875\n",
      "Training loss: 0.175898, accuracy: 0.953125\n",
      "Training loss: 0.22867, accuracy: 0.921875\n",
      "Training loss: 0.175714, accuracy: 0.953125\n",
      "Training loss: 0.185497, accuracy: 0.96875\n",
      "Training loss: 0.170326, accuracy: 0.96875\n",
      "Training loss: 0.140363, accuracy: 0.9375\n",
      "Training loss: 0.281564, accuracy: 0.90625\n",
      "Training loss: 0.105461, accuracy: 0.953125\n",
      "Training loss: 0.213906, accuracy: 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.234856, accuracy: 0.921875\n",
      "Training loss: 0.158198, accuracy: 0.953125\n",
      "Training loss: 0.107602, accuracy: 0.96875\n",
      "Training loss: 0.246698, accuracy: 0.9375\n",
      "Training loss: 0.27203, accuracy: 0.921875\n",
      "Training loss: 0.0760961, accuracy: 0.96875\n",
      "Training loss: 0.140376, accuracy: 0.9375\n",
      "Training loss: 0.0972924, accuracy: 0.96875\n",
      "Training loss: 0.258874, accuracy: 0.921875\n",
      "Training loss: 0.196657, accuracy: 0.9375\n",
      "Training loss: 0.1877, accuracy: 0.9375\n",
      "Training loss: 0.376996, accuracy: 0.875\n",
      "Training loss: 0.155171, accuracy: 0.953125\n",
      "Training loss: 0.125424, accuracy: 0.953125\n",
      "Training loss: 0.136587, accuracy: 0.96875\n",
      "Training loss: 0.135973, accuracy: 0.9375\n",
      "Training loss: 0.130842, accuracy: 0.953125\n",
      "Training loss: 0.239935, accuracy: 0.921875\n",
      "Training loss: 0.306048, accuracy: 0.890625\n",
      "Training loss: 0.279612, accuracy: 0.90625\n",
      "Training loss: 0.125133, accuracy: 0.96875\n",
      "Training loss: 0.21689, accuracy: 0.921875\n",
      "Training loss: 0.147414, accuracy: 0.9375\n",
      "Training loss: 0.157715, accuracy: 0.921875\n",
      "Training loss: 0.232063, accuracy: 0.921875\n",
      "Training loss: 0.19592, accuracy: 0.921875\n",
      "Training loss: 0.175734, accuracy: 0.921875\n",
      "Training loss: 0.202939, accuracy: 0.90625\n",
      "Training loss: 0.111891, accuracy: 0.96875\n",
      "Training loss: 0.418082, accuracy: 0.859375\n",
      "Training loss: 0.050802, accuracy: 1.0\n",
      "Training loss: 0.196383, accuracy: 0.9375\n",
      "Training loss: 0.1723, accuracy: 0.921875\n",
      "Training loss: 0.179244, accuracy: 0.921875\n",
      "Training loss: 0.105166, accuracy: 0.96875\n",
      "Training loss: 0.14192, accuracy: 0.9375\n",
      "Training loss: 0.150845, accuracy: 0.96875\n",
      "Training loss: 0.194571, accuracy: 0.953125\n",
      "Training loss: 0.161129, accuracy: 0.96875\n",
      "Training loss: 0.1918, accuracy: 0.953125\n",
      "Training loss: 0.14816, accuracy: 0.9375\n",
      "Training loss: 0.164922, accuracy: 0.9375\n",
      "Training loss: 0.173761, accuracy: 0.921875\n",
      "Training loss: 0.317971, accuracy: 0.875\n",
      "Training loss: 0.210146, accuracy: 0.921875\n",
      "Training loss: 0.104508, accuracy: 0.96875\n",
      "Training loss: 0.203075, accuracy: 0.90625\n",
      "Training loss: 0.314597, accuracy: 0.90625\n",
      "Training loss: 0.192394, accuracy: 0.953125\n",
      "Training loss: 0.290909, accuracy: 0.859375\n",
      "Training loss: 0.182463, accuracy: 0.921875\n",
      "Training loss: 0.198222, accuracy: 0.96875\n",
      "Training loss: 0.217405, accuracy: 0.953125\n",
      "Training loss: 0.194976, accuracy: 0.953125\n",
      "Training loss: 0.105721, accuracy: 0.984375\n",
      "Training loss: 0.465214, accuracy: 0.859375\n",
      "Training loss: 0.0947791, accuracy: 0.984375\n",
      "Training loss: 0.259154, accuracy: 0.921875\n",
      "Training loss: 0.1633, accuracy: 0.9375\n",
      "Training loss: 0.0939627, accuracy: 0.984375\n",
      "Training loss: 0.0987317, accuracy: 0.984375\n",
      "Training loss: 0.177959, accuracy: 0.921875\n",
      "Training loss: 0.199107, accuracy: 0.921875\n",
      "Training loss: 0.218536, accuracy: 0.890625\n",
      "Training loss: 0.19949, accuracy: 0.9375\n",
      "Training loss: 0.123877, accuracy: 0.96875\n",
      "Training loss: 0.229806, accuracy: 0.890625\n",
      "Training loss: 0.123016, accuracy: 0.953125\n",
      "Training loss: 0.264358, accuracy: 0.921875\n",
      "Training loss: 0.119097, accuracy: 0.984375\n",
      "Training loss: 0.110912, accuracy: 0.953125\n",
      "Training loss: 0.125831, accuracy: 0.96875\n",
      "Training loss: 0.249556, accuracy: 0.9375\n",
      "Training loss: 0.204634, accuracy: 0.953125\n",
      "Training loss: 0.130469, accuracy: 0.921875\n",
      "Training loss: 0.0454916, accuracy: 1.0\n",
      "Training loss: 0.119951, accuracy: 0.984375\n",
      "Training loss: 0.191216, accuracy: 0.90625\n",
      "Training loss: 0.135032, accuracy: 0.96875\n",
      "Training loss: 0.27748, accuracy: 0.890625\n",
      "Training loss: 0.0779511, accuracy: 0.984375\n",
      "----------------- Step 1200: validation accuracy 0.8224 ----------------\n",
      "Training loss: 0.169504, accuracy: 0.953125\n",
      "Training loss: 0.245622, accuracy: 0.90625\n",
      "Training loss: 0.181516, accuracy: 0.9375\n",
      "Training loss: 0.287128, accuracy: 0.921875\n",
      "Training loss: 0.256221, accuracy: 0.921875\n",
      "Training loss: 0.347966, accuracy: 0.859375\n",
      "Training loss: 0.157721, accuracy: 0.96875\n",
      "Training loss: 0.194963, accuracy: 0.890625\n",
      "Training loss: 0.166673, accuracy: 0.90625\n",
      "Training loss: 0.184215, accuracy: 0.953125\n",
      "Training loss: 0.276548, accuracy: 0.890625\n",
      "Training loss: 0.229824, accuracy: 0.90625\n",
      "Training loss: 0.331298, accuracy: 0.890625\n",
      "Training loss: 0.246242, accuracy: 0.921875\n",
      "Training loss: 0.173102, accuracy: 0.921875\n",
      "Training loss: 0.262225, accuracy: 0.90625\n",
      "Training loss: 0.217217, accuracy: 0.90625\n",
      "Training loss: 0.18253, accuracy: 0.9375\n",
      "Training loss: 0.103534, accuracy: 0.984375\n",
      "Training loss: 0.259689, accuracy: 0.921875\n",
      "Training loss: 0.322114, accuracy: 0.90625\n",
      "Training loss: 0.160635, accuracy: 0.953125\n",
      "Training loss: 0.152509, accuracy: 0.953125\n",
      "Training loss: 0.346082, accuracy: 0.890625\n",
      "Training loss: 0.213201, accuracy: 0.90625\n",
      "Training loss: 0.177501, accuracy: 0.953125\n",
      "Training loss: 0.154803, accuracy: 0.953125\n",
      "Training loss: 0.227425, accuracy: 0.90625\n",
      "Training loss: 0.165092, accuracy: 0.953125\n",
      "Training loss: 0.217636, accuracy: 0.90625\n",
      "Training loss: 0.206038, accuracy: 0.921875\n",
      "Training loss: 0.298869, accuracy: 0.859375\n",
      "Training loss: 0.127579, accuracy: 0.984375\n",
      "Training loss: 0.149959, accuracy: 0.953125\n",
      "Training loss: 0.30643, accuracy: 0.90625\n",
      "Training loss: 0.168594, accuracy: 0.921875\n",
      "Training loss: 0.167056, accuracy: 0.953125\n",
      "Training loss: 0.145017, accuracy: 0.953125\n",
      "Training loss: 0.237509, accuracy: 0.9375\n",
      "Training loss: 0.123339, accuracy: 0.953125\n",
      "Training loss: 0.221938, accuracy: 0.890625\n",
      "Training loss: 0.239158, accuracy: 0.9375\n",
      "Training loss: 0.072139, accuracy: 0.984375\n",
      "Training loss: 0.133391, accuracy: 0.953125\n",
      "Training loss: 0.109432, accuracy: 0.96875\n",
      "Training loss: 0.208096, accuracy: 0.921875\n",
      "Training loss: 0.177453, accuracy: 0.953125\n",
      "Training loss: 0.22736, accuracy: 0.90625\n",
      "Training loss: 0.202943, accuracy: 0.9375\n",
      "Training loss: 0.194617, accuracy: 0.9375\n",
      "Training loss: 0.15651, accuracy: 0.953125\n",
      "Training loss: 0.245142, accuracy: 0.921875\n",
      "Training loss: 0.134523, accuracy: 0.96875\n",
      "Training loss: 0.328779, accuracy: 0.890625\n",
      "Training loss: 0.166104, accuracy: 0.953125\n",
      "Training loss: 0.142826, accuracy: 0.9375\n",
      "Training loss: 0.139347, accuracy: 0.953125\n",
      "Training loss: 0.127915, accuracy: 0.9375\n",
      "Training loss: 0.181622, accuracy: 0.921875\n",
      "Training loss: 0.195473, accuracy: 0.9375\n",
      "Training loss: 0.160226, accuracy: 0.96875\n",
      "Training loss: 0.0699444, accuracy: 0.984375\n",
      "Training loss: 0.150133, accuracy: 0.9375\n",
      "Training loss: 0.106949, accuracy: 0.953125\n",
      "Training loss: 0.220904, accuracy: 0.921875\n",
      "Training loss: 0.101572, accuracy: 0.96875\n",
      "Training loss: 0.047973, accuracy: 0.984375\n",
      "Training loss: 0.150071, accuracy: 0.96875\n",
      "Training loss: 0.125219, accuracy: 0.953125\n",
      "Training loss: 0.106182, accuracy: 0.953125\n",
      "Training loss: 0.154731, accuracy: 0.9375\n",
      "Training loss: 0.156932, accuracy: 0.9375\n",
      "Training loss: 0.0659821, accuracy: 0.984375\n",
      "Training loss: 0.192905, accuracy: 0.921875\n",
      "Training loss: 0.261359, accuracy: 0.921875\n",
      "Training loss: 0.127444, accuracy: 0.953125\n",
      "Training loss: 0.079103, accuracy: 0.953125\n",
      "Training loss: 0.134177, accuracy: 0.953125\n",
      "Training loss: 0.172428, accuracy: 0.9375\n",
      "Training loss: 0.129362, accuracy: 0.921875\n",
      "Training loss: 0.152982, accuracy: 0.953125\n",
      "Training loss: 0.147769, accuracy: 0.953125\n",
      "Training loss: 0.113158, accuracy: 0.953125\n",
      "Training loss: 0.140679, accuracy: 0.9375\n",
      "Training loss: 0.163844, accuracy: 0.953125\n",
      "Training loss: 0.172885, accuracy: 0.9375\n",
      "Training loss: 0.0594384, accuracy: 0.984375\n",
      "Training loss: 0.183421, accuracy: 0.9375\n",
      "Training loss: 0.125226, accuracy: 0.953125\n",
      "Training loss: 0.148844, accuracy: 0.953125\n",
      "Training loss: 0.0424455, accuracy: 1.0\n",
      "Training loss: 0.0949389, accuracy: 0.953125\n",
      "Training loss: 0.121415, accuracy: 0.96875\n",
      "Training loss: 0.180268, accuracy: 0.96875\n",
      "Training loss: 0.127155, accuracy: 0.953125\n",
      "Training loss: 0.166006, accuracy: 0.9375\n",
      "Training loss: 0.0785298, accuracy: 0.984375\n",
      "Training loss: 0.128624, accuracy: 0.96875\n",
      "Training loss: 0.173023, accuracy: 0.96875\n",
      "Training loss: 0.137676, accuracy: 0.96875\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 1300: validation accuracy 0.84112 ----------------\n",
      "Training loss: 0.0918055, accuracy: 0.96875\n",
      "Training loss: 0.163775, accuracy: 0.921875\n",
      "Training loss: 0.0451903, accuracy: 0.96875\n",
      "Training loss: 0.0913204, accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.111858, accuracy: 0.953125\n",
      "Training loss: 0.183573, accuracy: 0.953125\n",
      "Training loss: 0.205127, accuracy: 0.9375\n",
      "Training loss: 0.27829, accuracy: 0.921875\n",
      "Training loss: 0.148887, accuracy: 0.953125\n",
      "Training loss: 0.218371, accuracy: 0.90625\n",
      "Training loss: 0.168415, accuracy: 0.953125\n",
      "Training loss: 0.0681603, accuracy: 0.984375\n",
      "Training loss: 0.164589, accuracy: 0.9375\n",
      "Training loss: 0.121871, accuracy: 0.96875\n",
      "Training loss: 0.152084, accuracy: 0.9375\n",
      "Training loss: 0.047361, accuracy: 1.0\n",
      "Training loss: 0.232823, accuracy: 0.9375\n",
      "Training loss: 0.131743, accuracy: 0.921875\n",
      "Training loss: 0.313787, accuracy: 0.875\n",
      "Training loss: 0.164689, accuracy: 0.953125\n",
      "Training loss: 0.142013, accuracy: 0.921875\n",
      "Training loss: 0.207355, accuracy: 0.921875\n",
      "Training loss: 0.196487, accuracy: 0.9375\n",
      "Training loss: 0.248578, accuracy: 0.921875\n",
      "Training loss: 0.114737, accuracy: 0.96875\n",
      "Training loss: 0.202792, accuracy: 0.921875\n",
      "Training loss: 0.0791928, accuracy: 0.984375\n",
      "Training loss: 0.0869751, accuracy: 0.984375\n",
      "Training loss: 0.212618, accuracy: 0.921875\n",
      "Training loss: 0.344979, accuracy: 0.875\n",
      "Training loss: 0.0665782, accuracy: 0.984375\n",
      "Training loss: 0.0891629, accuracy: 0.984375\n",
      "Training loss: 0.121483, accuracy: 0.953125\n",
      "Training loss: 0.238895, accuracy: 0.921875\n",
      "Training loss: 0.172814, accuracy: 0.921875\n",
      "Training loss: 0.190962, accuracy: 0.953125\n",
      "Training loss: 0.209298, accuracy: 0.921875\n",
      "Training loss: 0.0818698, accuracy: 0.96875\n",
      "Training loss: 0.0782343, accuracy: 0.96875\n",
      "Training loss: 0.12246, accuracy: 0.953125\n",
      "Training loss: 0.179899, accuracy: 0.9375\n",
      "Training loss: 0.0882075, accuracy: 0.96875\n",
      "Training loss: 0.11689, accuracy: 0.953125\n",
      "Training loss: 0.0927569, accuracy: 0.96875\n",
      "Training loss: 0.237667, accuracy: 0.90625\n",
      "Training loss: 0.342562, accuracy: 0.90625\n",
      "Training loss: 0.196905, accuracy: 0.921875\n",
      "Training loss: 0.218042, accuracy: 0.953125\n",
      "Training loss: 0.152423, accuracy: 0.96875\n",
      "Training loss: 0.237756, accuracy: 0.921875\n",
      "Training loss: 0.183536, accuracy: 0.9375\n",
      "Training loss: 0.116054, accuracy: 0.953125\n",
      "Training loss: 0.126471, accuracy: 0.9375\n",
      "Training loss: 0.124024, accuracy: 0.953125\n",
      "Training loss: 0.159622, accuracy: 0.9375\n",
      "Training loss: 0.142476, accuracy: 0.9375\n",
      "Training loss: 0.171019, accuracy: 0.96875\n",
      "Training loss: 0.175133, accuracy: 0.953125\n",
      "Training loss: 0.177213, accuracy: 0.9375\n",
      "Training loss: 0.255491, accuracy: 0.921875\n",
      "Training loss: 0.116723, accuracy: 0.953125\n",
      "Training loss: 0.134192, accuracy: 0.953125\n",
      "Training loss: 0.0838162, accuracy: 0.984375\n",
      "Training loss: 0.199326, accuracy: 0.953125\n",
      "Training loss: 0.213803, accuracy: 0.921875\n",
      "Training loss: 0.161999, accuracy: 0.953125\n",
      "Training loss: 0.301169, accuracy: 0.890625\n",
      "Training loss: 0.0912238, accuracy: 0.984375\n",
      "Training loss: 0.0594859, accuracy: 1.0\n",
      "Training loss: 0.0941106, accuracy: 0.984375\n",
      "Training loss: 0.0816984, accuracy: 0.96875\n",
      "Training loss: 0.167535, accuracy: 0.9375\n",
      "Training loss: 0.223522, accuracy: 0.921875\n",
      "Training loss: 0.158689, accuracy: 0.953125\n",
      "Training loss: 0.0887413, accuracy: 0.984375\n",
      "Training loss: 0.0946392, accuracy: 0.953125\n",
      "Training loss: 0.226035, accuracy: 0.90625\n",
      "Training loss: 0.201816, accuracy: 0.921875\n",
      "Training loss: 0.236622, accuracy: 0.90625\n",
      "Training loss: 0.110364, accuracy: 0.984375\n",
      "Training loss: 0.188389, accuracy: 0.9375\n",
      "Training loss: 0.162692, accuracy: 0.953125\n",
      "Training loss: 0.165187, accuracy: 0.96875\n",
      "Training loss: 0.234388, accuracy: 0.921875\n",
      "Training loss: 0.287467, accuracy: 0.90625\n",
      "Training loss: 0.20065, accuracy: 0.9375\n",
      "Training loss: 0.280512, accuracy: 0.90625\n",
      "Training loss: 0.12804, accuracy: 0.953125\n",
      "Training loss: 0.280489, accuracy: 0.875\n",
      "Training loss: 0.126803, accuracy: 0.953125\n",
      "Training loss: 0.255815, accuracy: 0.890625\n",
      "Training loss: 0.308493, accuracy: 0.90625\n",
      "Training loss: 0.191705, accuracy: 0.9375\n",
      "Training loss: 0.187872, accuracy: 0.9375\n",
      "Training loss: 0.238827, accuracy: 0.890625\n",
      "Training loss: 0.246077, accuracy: 0.9375\n",
      "Training loss: 0.194508, accuracy: 0.921875\n",
      "Training loss: 0.186451, accuracy: 0.9375\n",
      "Training loss: 0.264531, accuracy: 0.90625\n",
      "Training loss: 0.151401, accuracy: 0.90625\n",
      "----------------- Step 1400: validation accuracy 0.83312 ----------------\n",
      "Training loss: 0.173831, accuracy: 0.9375\n",
      "Training loss: 0.125254, accuracy: 0.96875\n",
      "Training loss: 0.151122, accuracy: 0.9375\n",
      "Training loss: 0.106399, accuracy: 0.96875\n",
      "Training loss: 0.125498, accuracy: 0.953125\n",
      "Training loss: 0.118678, accuracy: 0.96875\n",
      "Training loss: 0.154663, accuracy: 0.953125\n",
      "Training loss: 0.136185, accuracy: 0.96875\n",
      "Training loss: 0.083874, accuracy: 0.96875\n",
      "Training loss: 0.175119, accuracy: 0.9375\n",
      "Training loss: 0.0857633, accuracy: 0.96875\n",
      "Training loss: 0.148009, accuracy: 0.953125\n",
      "Training loss: 0.127562, accuracy: 0.984375\n",
      "Training loss: 0.136457, accuracy: 0.96875\n",
      "Training loss: 0.178368, accuracy: 0.9375\n",
      "Training loss: 0.0966654, accuracy: 0.953125\n",
      "Training loss: 0.244473, accuracy: 0.9375\n",
      "Training loss: 0.0714382, accuracy: 0.953125\n",
      "Training loss: 0.0279421, accuracy: 1.0\n",
      "Training loss: 0.0385921, accuracy: 1.0\n",
      "Training loss: 0.258387, accuracy: 0.9375\n",
      "Training loss: 0.165308, accuracy: 0.9375\n",
      "Training loss: 0.0236739, accuracy: 1.0\n",
      "Training loss: 0.302981, accuracy: 0.921875\n",
      "Training loss: 0.0269684, accuracy: 1.0\n",
      "Training loss: 0.110296, accuracy: 0.96875\n",
      "Training loss: 0.131593, accuracy: 0.96875\n",
      "Training loss: 0.0565842, accuracy: 0.984375\n",
      "Training loss: 0.0878048, accuracy: 0.96875\n",
      "Training loss: 0.109418, accuracy: 0.96875\n",
      "Training loss: 0.18223, accuracy: 0.9375\n",
      "Training loss: 0.280237, accuracy: 0.921875\n",
      "Training loss: 0.0928132, accuracy: 0.96875\n",
      "Training loss: 0.113224, accuracy: 0.96875\n",
      "Training loss: 0.170177, accuracy: 0.953125\n",
      "Training loss: 0.137794, accuracy: 0.96875\n",
      "Training loss: 0.118307, accuracy: 0.953125\n",
      "Training loss: 0.174139, accuracy: 0.9375\n",
      "Training loss: 0.190683, accuracy: 0.9375\n",
      "Training loss: 0.14245, accuracy: 0.953125\n",
      "Training loss: 0.0497725, accuracy: 1.0\n",
      "Training loss: 0.365553, accuracy: 0.890625\n",
      "Training loss: 0.0599708, accuracy: 0.984375\n",
      "Training loss: 0.0466395, accuracy: 0.984375\n",
      "Training loss: 0.129794, accuracy: 0.9375\n",
      "Training loss: 0.124473, accuracy: 0.9375\n",
      "Training loss: 0.0817852, accuracy: 0.96875\n",
      "Training loss: 0.108676, accuracy: 0.96875\n",
      "Training loss: 0.055124, accuracy: 1.0\n",
      "Training loss: 0.146497, accuracy: 0.96875\n",
      "Training loss: 0.120481, accuracy: 0.984375\n",
      "Training loss: 0.185403, accuracy: 0.921875\n",
      "Training loss: 0.0932755, accuracy: 0.984375\n",
      "Training loss: 0.149937, accuracy: 0.953125\n",
      "Training loss: 0.109067, accuracy: 0.953125\n",
      "Training loss: 0.118971, accuracy: 0.984375\n",
      "Training loss: 0.197616, accuracy: 0.921875\n",
      "Training loss: 0.0773809, accuracy: 0.984375\n",
      "Training loss: 0.0624517, accuracy: 0.96875\n",
      "Training loss: 0.290598, accuracy: 0.90625\n",
      "Training loss: 0.141935, accuracy: 0.96875\n",
      "Training loss: 0.285609, accuracy: 0.890625\n",
      "Training loss: 0.146907, accuracy: 0.9375\n",
      "Training loss: 0.19111, accuracy: 0.9375\n",
      "Training loss: 0.175718, accuracy: 0.9375\n",
      "Training loss: 0.0672831, accuracy: 0.984375\n",
      "Training loss: 0.0784902, accuracy: 0.96875\n",
      "Training loss: 0.29728, accuracy: 0.90625\n",
      "Training loss: 0.0889448, accuracy: 0.984375\n",
      "Training loss: 0.280766, accuracy: 0.90625\n",
      "Training loss: 0.0752329, accuracy: 0.96875\n",
      "Training loss: 0.120106, accuracy: 0.96875\n",
      "Training loss: 0.160223, accuracy: 0.953125\n",
      "Training loss: 0.0628965, accuracy: 1.0\n",
      "Training loss: 0.171313, accuracy: 0.9375\n",
      "Training loss: 0.0776718, accuracy: 0.96875\n",
      "Training loss: 0.114425, accuracy: 0.984375\n",
      "Training loss: 0.0942746, accuracy: 0.96875\n",
      "Training loss: 0.0780569, accuracy: 0.96875\n",
      "Training loss: 0.137672, accuracy: 0.984375\n",
      "Training loss: 0.225353, accuracy: 0.9375\n",
      "Training loss: 0.146787, accuracy: 0.96875\n",
      "Training loss: 0.0378362, accuracy: 1.0\n",
      "Training loss: 0.0895381, accuracy: 0.96875\n",
      "Training loss: 0.171778, accuracy: 0.9375\n",
      "Training loss: 0.156582, accuracy: 0.96875\n",
      "Training loss: 0.0637769, accuracy: 0.984375\n",
      "Training loss: 0.0552591, accuracy: 0.984375\n",
      "Training loss: 0.105247, accuracy: 0.96875\n",
      "Training loss: 0.0859842, accuracy: 0.9375\n",
      "Training loss: 0.0661233, accuracy: 0.96875\n",
      "Training loss: 0.130865, accuracy: 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.067058, accuracy: 0.96875\n",
      "Training loss: 0.0864547, accuracy: 0.984375\n",
      "Training loss: 0.191015, accuracy: 0.96875\n",
      "Training loss: 0.157078, accuracy: 0.953125\n",
      "Training loss: 0.233333, accuracy: 0.9375\n",
      "Training loss: 0.195381, accuracy: 0.953125\n",
      "Training loss: 0.179292, accuracy: 0.953125\n",
      "Training loss: 0.115575, accuracy: 0.9375\n",
      "----------------- Step 1500: validation accuracy 0.84 ----------------\n",
      "Training loss: 0.0432654, accuracy: 1.0\n",
      "Training loss: 0.0819222, accuracy: 0.984375\n",
      "Training loss: 0.151645, accuracy: 0.953125\n",
      "Training loss: 0.0349077, accuracy: 0.984375\n",
      "Training loss: 0.117458, accuracy: 0.96875\n",
      "Training loss: 0.209155, accuracy: 0.9375\n",
      "Training loss: 0.0503842, accuracy: 1.0\n",
      "Training loss: 0.0956899, accuracy: 0.96875\n",
      "Training loss: 0.239771, accuracy: 0.9375\n",
      "Training loss: 0.0726943, accuracy: 0.984375\n",
      "Training loss: 0.136448, accuracy: 0.96875\n",
      "Training loss: 0.100797, accuracy: 0.96875\n",
      "Training loss: 0.169425, accuracy: 0.953125\n",
      "Training loss: 0.190718, accuracy: 0.953125\n",
      "Training loss: 0.0957984, accuracy: 0.984375\n",
      "Training loss: 0.134286, accuracy: 0.96875\n",
      "Training loss: 0.340784, accuracy: 0.90625\n",
      "Training loss: 0.0811631, accuracy: 0.96875\n",
      "Training loss: 0.0520119, accuracy: 0.984375\n",
      "Training loss: 0.0663905, accuracy: 0.984375\n",
      "Training loss: 0.21532, accuracy: 0.9375\n",
      "Training loss: 0.094907, accuracy: 0.96875\n",
      "Training loss: 0.127914, accuracy: 0.96875\n",
      "Training loss: 0.116304, accuracy: 0.96875\n",
      "Training loss: 0.157064, accuracy: 0.96875\n",
      "Training loss: 0.105178, accuracy: 0.984375\n",
      "Training loss: 0.129375, accuracy: 0.9375\n",
      "Training loss: 0.443003, accuracy: 0.875\n",
      "Training loss: 0.121404, accuracy: 0.953125\n",
      "Training loss: 0.14056, accuracy: 0.96875\n",
      "Training loss: 0.0787486, accuracy: 0.984375\n",
      "Training loss: 0.143787, accuracy: 0.953125\n",
      "Training loss: 0.083534, accuracy: 0.96875\n",
      "Training loss: 0.0950257, accuracy: 0.9375\n",
      "Training loss: 0.257874, accuracy: 0.90625\n",
      "Training loss: 0.0743741, accuracy: 0.984375\n",
      "Training loss: 0.0695175, accuracy: 0.984375\n",
      "Training loss: 0.0507559, accuracy: 0.984375\n",
      "Training loss: 0.170798, accuracy: 0.953125\n",
      "Training loss: 0.174172, accuracy: 0.90625\n",
      "Training loss: 0.107626, accuracy: 0.984375\n",
      "Training loss: 0.101501, accuracy: 0.984375\n",
      "Training loss: 0.186427, accuracy: 0.9375\n",
      "Training loss: 0.111334, accuracy: 0.96875\n",
      "Training loss: 0.141157, accuracy: 0.953125\n",
      "Training loss: 0.0717276, accuracy: 0.96875\n",
      "Training loss: 0.245293, accuracy: 0.921875\n",
      "Training loss: 0.0505031, accuracy: 0.984375\n",
      "Training loss: 0.0628491, accuracy: 0.984375\n",
      "Training loss: 0.0694478, accuracy: 0.96875\n",
      "Training loss: 0.180164, accuracy: 0.96875\n",
      "Training loss: 0.107605, accuracy: 0.984375\n",
      "Training loss: 0.345346, accuracy: 0.921875\n",
      "Training loss: 0.083406, accuracy: 0.96875\n",
      "Training loss: 0.0935362, accuracy: 0.96875\n",
      "Training loss: 0.0681117, accuracy: 0.984375\n",
      "Training loss: 0.0605724, accuracy: 0.984375\n",
      "Training loss: 0.0961189, accuracy: 0.984375\n",
      "Training loss: 0.0331445, accuracy: 1.0\n",
      "Training loss: 0.0452645, accuracy: 1.0\n",
      "Training loss: 0.117439, accuracy: 0.984375\n",
      "Training loss: 0.0387111, accuracy: 0.984375\n",
      "Training loss: 0.0497372, accuracy: 0.984375\n",
      "Training loss: 0.046681, accuracy: 0.984375\n",
      "Training loss: 0.0827205, accuracy: 0.96875\n",
      "Training loss: 0.0785561, accuracy: 0.953125\n",
      "Training loss: 0.0759942, accuracy: 0.96875\n",
      "Training loss: 0.167163, accuracy: 0.96875\n",
      "Training loss: 0.15563, accuracy: 0.9375\n",
      "Training loss: 0.0287575, accuracy: 1.0\n",
      "Training loss: 0.0752217, accuracy: 0.96875\n",
      "Training loss: 0.0391856, accuracy: 0.984375\n",
      "Training loss: 0.06099, accuracy: 0.984375\n",
      "Training loss: 0.105624, accuracy: 0.984375\n",
      "Training loss: 0.135912, accuracy: 0.953125\n",
      "Training loss: 0.0958577, accuracy: 0.984375\n",
      "Training loss: 0.0176171, accuracy: 1.0\n",
      "Training loss: 0.0678637, accuracy: 0.984375\n",
      "Training loss: 0.130913, accuracy: 0.96875\n",
      "Training loss: 0.0458935, accuracy: 0.984375\n",
      "Training loss: 0.0774903, accuracy: 0.953125\n",
      "Training loss: 0.19544, accuracy: 0.953125\n",
      "Training loss: 0.0304355, accuracy: 0.984375\n",
      "Training loss: 0.0159258, accuracy: 1.0\n",
      "Training loss: 0.0918923, accuracy: 0.96875\n",
      "Training loss: 0.100008, accuracy: 0.984375\n",
      "Training loss: 0.129773, accuracy: 0.984375\n",
      "Training loss: 0.0969004, accuracy: 0.96875\n",
      "Training loss: 0.0746693, accuracy: 0.984375\n",
      "Training loss: 0.036597, accuracy: 0.984375\n",
      "Training loss: 0.0946351, accuracy: 0.984375\n",
      "Training loss: 0.194205, accuracy: 0.96875\n",
      "Training loss: 0.10635, accuracy: 0.96875\n",
      "Training loss: 0.0396308, accuracy: 1.0\n",
      "Training loss: 0.0758412, accuracy: 0.953125\n",
      "Training loss: 0.0275282, accuracy: 1.0\n",
      "Training loss: 0.112009, accuracy: 0.953125\n",
      "Training loss: 0.0539231, accuracy: 0.984375\n",
      "Training loss: 0.0375997, accuracy: 0.984375\n",
      "Training loss: 0.12138, accuracy: 0.9375\n",
      "----------------- Step 1600: validation accuracy 0.8408 ----------------\n",
      "Training loss: 0.201901, accuracy: 0.9375\n",
      "Training loss: 0.0704907, accuracy: 0.96875\n",
      "Training loss: 0.245735, accuracy: 0.953125\n",
      "Training loss: 0.153946, accuracy: 0.921875\n",
      "Training loss: 0.0594527, accuracy: 0.96875\n",
      "Training loss: 0.119536, accuracy: 0.96875\n",
      "Training loss: 0.109009, accuracy: 0.96875\n",
      "Training loss: 0.111455, accuracy: 0.953125\n",
      "Training loss: 0.0691331, accuracy: 0.96875\n",
      "Training loss: 0.0847328, accuracy: 0.984375\n",
      "Training loss: 0.0625289, accuracy: 0.953125\n",
      "Training loss: 0.156434, accuracy: 0.9375\n",
      "Training loss: 0.109719, accuracy: 0.984375\n",
      "Training loss: 0.103465, accuracy: 0.953125\n",
      "Training loss: 0.129133, accuracy: 0.96875\n",
      "Training loss: 0.122738, accuracy: 0.96875\n",
      "Training loss: 0.189742, accuracy: 0.9375\n",
      "Training loss: 0.126577, accuracy: 0.9375\n",
      "Training loss: 0.194925, accuracy: 0.953125\n",
      "Training loss: 0.0311455, accuracy: 0.984375\n",
      "Training loss: 0.0433867, accuracy: 0.984375\n",
      "Training loss: 0.10184, accuracy: 0.96875\n",
      "Training loss: 0.295588, accuracy: 0.90625\n",
      "Training loss: 0.0758253, accuracy: 0.984375\n",
      "Training loss: 0.11453, accuracy: 0.953125\n",
      "Training loss: 0.0929837, accuracy: 0.984375\n",
      "Training loss: 0.124143, accuracy: 0.953125\n",
      "Training loss: 0.251, accuracy: 0.921875\n",
      "Training loss: 0.121392, accuracy: 0.96875\n",
      "Training loss: 0.161508, accuracy: 0.953125\n",
      "Training loss: 0.0278868, accuracy: 1.0\n",
      "Training loss: 0.0573054, accuracy: 0.984375\n",
      "Training loss: 0.0443715, accuracy: 0.984375\n",
      "Training loss: 0.15564, accuracy: 0.96875\n",
      "Training loss: 0.0642001, accuracy: 0.984375\n",
      "Training loss: 0.0575455, accuracy: 1.0\n",
      "Training loss: 0.0965527, accuracy: 0.96875\n",
      "Training loss: 0.195281, accuracy: 0.96875\n",
      "Training loss: 0.244153, accuracy: 0.9375\n",
      "Training loss: 0.111006, accuracy: 0.953125\n",
      "Training loss: 0.176123, accuracy: 0.953125\n",
      "Training loss: 0.106114, accuracy: 0.953125\n",
      "Training loss: 0.145866, accuracy: 0.9375\n",
      "Training loss: 0.0700398, accuracy: 0.96875\n",
      "Training loss: 0.123239, accuracy: 0.953125\n",
      "Training loss: 0.0280733, accuracy: 1.0\n",
      "Training loss: 0.0596001, accuracy: 0.96875\n",
      "Training loss: 0.0791856, accuracy: 0.953125\n",
      "Training loss: 0.137681, accuracy: 0.9375\n",
      "Training loss: 0.14006, accuracy: 0.953125\n",
      "Training loss: 0.222496, accuracy: 0.9375\n",
      "Training loss: 0.216794, accuracy: 0.90625\n",
      "Training loss: 0.0988015, accuracy: 0.984375\n",
      "Training loss: 0.0702814, accuracy: 0.984375\n",
      "Training loss: 0.470721, accuracy: 0.890625\n",
      "Training loss: 0.141223, accuracy: 0.953125\n",
      "Training loss: 0.33749, accuracy: 0.84375\n",
      "Training loss: 0.225317, accuracy: 0.9375\n",
      "Training loss: 0.282372, accuracy: 0.90625\n",
      "Training loss: 0.169483, accuracy: 0.96875\n",
      "Training loss: 0.124558, accuracy: 0.96875\n",
      "Training loss: 0.0531957, accuracy: 0.984375\n",
      "Training loss: 0.0739281, accuracy: 0.984375\n",
      "Training loss: 0.0751363, accuracy: 1.0\n",
      "Training loss: 0.0823414, accuracy: 0.984375\n",
      "Training loss: 0.174988, accuracy: 0.9375\n",
      "Training loss: 0.110715, accuracy: 0.96875\n",
      "Training loss: 0.0903574, accuracy: 0.984375\n",
      "Training loss: 0.191967, accuracy: 0.9375\n",
      "Training loss: 0.208162, accuracy: 0.921875\n",
      "Training loss: 0.0821193, accuracy: 0.984375\n",
      "Training loss: 0.184796, accuracy: 0.921875\n",
      "Training loss: 0.109155, accuracy: 0.96875\n",
      "Training loss: 0.0799376, accuracy: 0.984375\n",
      "Training loss: 0.0811732, accuracy: 0.96875\n",
      "Training loss: 0.120734, accuracy: 0.96875\n",
      "Training loss: 0.177084, accuracy: 0.953125\n",
      "Training loss: 0.215848, accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.148382, accuracy: 0.96875\n",
      "Training loss: 0.214785, accuracy: 0.9375\n",
      "Training loss: 0.100876, accuracy: 0.953125\n",
      "Training loss: 0.0817711, accuracy: 0.984375\n",
      "Training loss: 0.106876, accuracy: 0.96875\n",
      "Training loss: 0.194636, accuracy: 0.9375\n",
      "Training loss: 0.253508, accuracy: 0.921875\n",
      "Training loss: 0.113568, accuracy: 0.96875\n",
      "Training loss: 0.069887, accuracy: 0.96875\n",
      "Training loss: 0.192005, accuracy: 0.953125\n",
      "Training loss: 0.137106, accuracy: 0.96875\n",
      "Training loss: 0.0782728, accuracy: 0.984375\n",
      "Training loss: 0.158458, accuracy: 0.953125\n",
      "Training loss: 0.148833, accuracy: 0.9375\n",
      "Training loss: 0.0468441, accuracy: 0.984375\n",
      "Training loss: 0.0982963, accuracy: 0.96875\n",
      "Training loss: 0.0623678, accuracy: 0.984375\n",
      "Training loss: 0.0741168, accuracy: 0.953125\n",
      "Training loss: 0.136047, accuracy: 0.953125\n",
      "Training loss: 0.0597897, accuracy: 0.984375\n",
      "Training loss: 0.126732, accuracy: 0.9375\n",
      "Training loss: 0.109527, accuracy: 0.96875\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 1700: validation accuracy 0.844 ----------------\n",
      "Training loss: 0.0557717, accuracy: 0.96875\n",
      "Training loss: 0.0506228, accuracy: 0.984375\n",
      "Training loss: 0.0943495, accuracy: 0.953125\n",
      "Training loss: 0.0280391, accuracy: 1.0\n",
      "Training loss: 0.133455, accuracy: 0.953125\n",
      "Training loss: 0.130566, accuracy: 0.984375\n",
      "Training loss: 0.0533257, accuracy: 0.984375\n",
      "Training loss: 0.110808, accuracy: 0.96875\n",
      "Training loss: 0.0328064, accuracy: 1.0\n",
      "Training loss: 0.084429, accuracy: 0.96875\n",
      "Training loss: 0.0556563, accuracy: 0.984375\n",
      "Training loss: 0.0387245, accuracy: 1.0\n",
      "Training loss: 0.0578133, accuracy: 0.96875\n",
      "Training loss: 0.321319, accuracy: 0.921875\n",
      "Training loss: 0.0320411, accuracy: 0.984375\n",
      "Training loss: 0.020724, accuracy: 1.0\n",
      "Training loss: 0.163845, accuracy: 0.96875\n",
      "Training loss: 0.028621, accuracy: 0.984375\n",
      "Training loss: 0.0734746, accuracy: 0.953125\n",
      "Training loss: 0.0238379, accuracy: 1.0\n",
      "Training loss: 0.0367563, accuracy: 0.984375\n",
      "Training loss: 0.0526337, accuracy: 0.984375\n",
      "Training loss: 0.0554972, accuracy: 0.96875\n",
      "Training loss: 0.0834637, accuracy: 0.96875\n",
      "Training loss: 0.135806, accuracy: 0.96875\n",
      "Training loss: 0.0664135, accuracy: 0.984375\n",
      "Training loss: 0.139995, accuracy: 0.96875\n",
      "Training loss: 0.094486, accuracy: 0.984375\n",
      "Training loss: 0.0606954, accuracy: 0.96875\n",
      "Training loss: 0.0654865, accuracy: 0.96875\n",
      "Training loss: 0.0428275, accuracy: 0.984375\n",
      "Training loss: 0.0249123, accuracy: 1.0\n",
      "Training loss: 0.0729753, accuracy: 0.984375\n",
      "Training loss: 0.0267047, accuracy: 1.0\n",
      "Training loss: 0.356831, accuracy: 0.90625\n",
      "Training loss: 0.0189457, accuracy: 1.0\n",
      "Training loss: 0.00666747, accuracy: 1.0\n",
      "Training loss: 0.0951245, accuracy: 0.984375\n",
      "Training loss: 0.0132584, accuracy: 1.0\n",
      "Training loss: 0.0541476, accuracy: 0.984375\n",
      "Training loss: 0.0762481, accuracy: 0.96875\n",
      "Training loss: 0.0924948, accuracy: 0.96875\n",
      "Training loss: 0.136892, accuracy: 0.9375\n",
      "Training loss: 0.125843, accuracy: 0.96875\n",
      "Training loss: 0.0903609, accuracy: 0.96875\n",
      "Training loss: 0.117085, accuracy: 0.96875\n",
      "Training loss: 0.086875, accuracy: 0.984375\n",
      "Training loss: 0.0441489, accuracy: 0.96875\n",
      "Training loss: 0.072317, accuracy: 0.984375\n",
      "Training loss: 0.152594, accuracy: 0.953125\n",
      "Training loss: 0.115169, accuracy: 0.984375\n",
      "Training loss: 0.0242556, accuracy: 1.0\n",
      "Training loss: 0.291408, accuracy: 0.890625\n",
      "Training loss: 0.0454065, accuracy: 0.984375\n",
      "Training loss: 0.0973789, accuracy: 0.9375\n",
      "Training loss: 0.107433, accuracy: 0.96875\n",
      "Training loss: 0.166802, accuracy: 0.953125\n",
      "Training loss: 0.149308, accuracy: 0.96875\n",
      "Training loss: 0.0517393, accuracy: 0.96875\n",
      "Training loss: 0.0478762, accuracy: 0.984375\n",
      "Training loss: 0.233661, accuracy: 0.953125\n",
      "Training loss: 0.0651383, accuracy: 0.96875\n",
      "Training loss: 0.156892, accuracy: 0.96875\n",
      "Training loss: 0.027327, accuracy: 0.984375\n",
      "Training loss: 0.024982, accuracy: 1.0\n",
      "Training loss: 0.0222229, accuracy: 1.0\n",
      "Training loss: 0.0516, accuracy: 0.96875\n",
      "Training loss: 0.050015, accuracy: 0.984375\n",
      "Training loss: 0.0501007, accuracy: 0.984375\n",
      "Training loss: 0.0625491, accuracy: 0.984375\n",
      "Training loss: 0.0337112, accuracy: 0.984375\n",
      "Training loss: 0.0654166, accuracy: 0.984375\n",
      "Training loss: 0.077069, accuracy: 0.96875\n",
      "Training loss: 0.120505, accuracy: 0.96875\n",
      "Training loss: 0.162485, accuracy: 0.96875\n",
      "Training loss: 0.0816152, accuracy: 0.96875\n",
      "Training loss: 0.0528743, accuracy: 0.953125\n",
      "Training loss: 0.122653, accuracy: 0.96875\n",
      "Training loss: 0.163927, accuracy: 0.96875\n",
      "Training loss: 0.115122, accuracy: 0.953125\n",
      "Training loss: 0.0258836, accuracy: 1.0\n",
      "Training loss: 0.0843321, accuracy: 0.984375\n",
      "Training loss: 0.0675388, accuracy: 0.984375\n",
      "Training loss: 0.0818318, accuracy: 0.984375\n",
      "Training loss: 0.126802, accuracy: 0.953125\n",
      "Training loss: 0.0325273, accuracy: 1.0\n",
      "Training loss: 0.0343013, accuracy: 0.984375\n",
      "Training loss: 0.190901, accuracy: 0.953125\n",
      "Training loss: 0.0838123, accuracy: 0.984375\n",
      "Training loss: 0.138528, accuracy: 0.96875\n",
      "Training loss: 0.182127, accuracy: 0.953125\n",
      "Training loss: 0.0765155, accuracy: 0.96875\n",
      "Training loss: 0.0966513, accuracy: 0.984375\n",
      "Training loss: 0.0441516, accuracy: 0.984375\n",
      "Training loss: 0.0429744, accuracy: 0.984375\n",
      "Training loss: 0.1419, accuracy: 0.9375\n",
      "Training loss: 0.0759399, accuracy: 0.96875\n",
      "Training loss: 0.0203137, accuracy: 1.0\n",
      "Training loss: 0.164058, accuracy: 0.9375\n",
      "Training loss: 0.0823932, accuracy: 0.984375\n",
      "----------------- Step 1800: validation accuracy 0.8304 ----------------\n",
      "Training loss: 0.0568416, accuracy: 0.984375\n",
      "Training loss: 0.210148, accuracy: 0.96875\n",
      "Training loss: 0.120025, accuracy: 0.9375\n",
      "Training loss: 0.163285, accuracy: 0.953125\n",
      "Training loss: 0.030332, accuracy: 1.0\n",
      "Training loss: 0.162481, accuracy: 0.953125\n",
      "Training loss: 0.105307, accuracy: 0.984375\n",
      "Training loss: 0.150855, accuracy: 0.90625\n",
      "Training loss: 0.266898, accuracy: 0.921875\n",
      "Training loss: 0.27309, accuracy: 0.90625\n",
      "Training loss: 0.0694169, accuracy: 0.96875\n",
      "Training loss: 0.048037, accuracy: 0.984375\n",
      "Training loss: 0.0333651, accuracy: 1.0\n",
      "Training loss: 0.218942, accuracy: 0.953125\n",
      "Training loss: 0.112416, accuracy: 0.96875\n",
      "Training loss: 0.132602, accuracy: 0.96875\n",
      "Training loss: 0.106899, accuracy: 0.984375\n",
      "Training loss: 0.119067, accuracy: 0.984375\n",
      "Training loss: 0.0942637, accuracy: 0.96875\n",
      "Training loss: 0.139676, accuracy: 0.96875\n",
      "Training loss: 0.424802, accuracy: 0.875\n",
      "Training loss: 0.0665855, accuracy: 0.984375\n",
      "Training loss: 0.1986, accuracy: 0.921875\n",
      "Training loss: 0.111143, accuracy: 0.96875\n",
      "Training loss: 0.105162, accuracy: 0.984375\n",
      "Training loss: 0.0847904, accuracy: 0.984375\n",
      "Training loss: 0.137353, accuracy: 0.96875\n",
      "Training loss: 0.0956801, accuracy: 0.984375\n",
      "Training loss: 0.0356366, accuracy: 0.984375\n",
      "Training loss: 0.0773429, accuracy: 0.984375\n",
      "Training loss: 0.126041, accuracy: 0.953125\n",
      "Training loss: 0.0923287, accuracy: 0.984375\n",
      "Training loss: 0.115968, accuracy: 0.96875\n",
      "Training loss: 0.0522456, accuracy: 1.0\n",
      "Training loss: 0.151461, accuracy: 0.96875\n",
      "Training loss: 0.204942, accuracy: 0.90625\n",
      "Training loss: 0.0892329, accuracy: 0.984375\n",
      "Training loss: 0.121246, accuracy: 0.96875\n",
      "Training loss: 0.132033, accuracy: 0.96875\n",
      "Training loss: 0.386609, accuracy: 0.875\n",
      "Training loss: 0.0350324, accuracy: 1.0\n",
      "Training loss: 0.0529179, accuracy: 0.984375\n",
      "Training loss: 0.0573757, accuracy: 0.984375\n",
      "Training loss: 0.0590403, accuracy: 0.96875\n",
      "Training loss: 0.0526544, accuracy: 1.0\n",
      "Training loss: 0.205449, accuracy: 0.953125\n",
      "Training loss: 0.0398705, accuracy: 0.984375\n",
      "Training loss: 0.0192186, accuracy: 1.0\n",
      "Training loss: 0.0632726, accuracy: 0.96875\n",
      "Training loss: 0.0461414, accuracy: 0.984375\n",
      "Training loss: 0.0421373, accuracy: 0.984375\n",
      "Training loss: 0.0241056, accuracy: 1.0\n",
      "Training loss: 0.0248538, accuracy: 1.0\n",
      "Training loss: 0.0857213, accuracy: 0.984375\n",
      "Training loss: 0.0304898, accuracy: 1.0\n",
      "Training loss: 0.0423444, accuracy: 0.984375\n",
      "Training loss: 0.0602677, accuracy: 0.984375\n",
      "Training loss: 0.0817514, accuracy: 0.953125\n",
      "Training loss: 0.0807579, accuracy: 0.953125\n",
      "Training loss: 0.0395675, accuracy: 0.984375\n",
      "Training loss: 0.196726, accuracy: 0.921875\n",
      "Training loss: 0.134188, accuracy: 0.953125\n",
      "Training loss: 0.0189974, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0548815, accuracy: 0.96875\n",
      "Training loss: 0.0396417, accuracy: 0.984375\n",
      "Training loss: 0.0363721, accuracy: 0.984375\n",
      "Training loss: 0.100433, accuracy: 0.984375\n",
      "Training loss: 0.0184883, accuracy: 1.0\n",
      "Training loss: 0.0810714, accuracy: 0.984375\n",
      "Training loss: 0.103483, accuracy: 0.953125\n",
      "Training loss: 0.101414, accuracy: 0.96875\n",
      "Training loss: 0.197008, accuracy: 0.953125\n",
      "Training loss: 0.00622717, accuracy: 1.0\n",
      "Training loss: 0.0465845, accuracy: 0.984375\n",
      "Training loss: 0.125437, accuracy: 0.96875\n",
      "Training loss: 0.0203203, accuracy: 1.0\n",
      "Training loss: 0.0230628, accuracy: 1.0\n",
      "Training loss: 0.0483305, accuracy: 0.96875\n",
      "Training loss: 0.10672, accuracy: 0.953125\n",
      "Training loss: 0.24902, accuracy: 0.90625\n",
      "Training loss: 0.0360937, accuracy: 0.984375\n",
      "Training loss: 0.140988, accuracy: 0.96875\n",
      "Training loss: 0.0110982, accuracy: 1.0\n",
      "Training loss: 0.0260522, accuracy: 0.984375\n",
      "Training loss: 0.0954209, accuracy: 0.984375\n",
      "Training loss: 0.0578074, accuracy: 0.984375\n",
      "Training loss: 0.0731206, accuracy: 0.96875\n",
      "Training loss: 0.0173563, accuracy: 1.0\n",
      "Training loss: 0.0213454, accuracy: 1.0\n",
      "Training loss: 0.0327186, accuracy: 0.984375\n",
      "Training loss: 0.0113813, accuracy: 1.0\n",
      "Training loss: 0.0216996, accuracy: 0.984375\n",
      "Training loss: 0.0834218, accuracy: 0.984375\n",
      "Training loss: 0.134431, accuracy: 0.96875\n",
      "Training loss: 0.0105755, accuracy: 1.0\n",
      "Training loss: 0.117037, accuracy: 0.953125\n",
      "Training loss: 0.0086378, accuracy: 1.0\n",
      "Training loss: 0.141424, accuracy: 0.96875\n",
      "Training loss: 0.119606, accuracy: 0.96875\n",
      "Training loss: 0.0699261, accuracy: 0.96875\n",
      "----------------- Step 1900: validation accuracy 0.84304 ----------------\n",
      "Training loss: 0.0989969, accuracy: 0.96875\n",
      "Training loss: 0.00660105, accuracy: 1.0\n",
      "Training loss: 0.052967, accuracy: 0.984375\n",
      "Training loss: 0.0141881, accuracy: 1.0\n",
      "Training loss: 0.134552, accuracy: 0.96875\n",
      "Training loss: 0.212927, accuracy: 0.953125\n",
      "Training loss: 0.0850819, accuracy: 0.96875\n",
      "Training loss: 0.0842872, accuracy: 0.984375\n",
      "Training loss: 0.0444765, accuracy: 0.984375\n",
      "Training loss: 0.101456, accuracy: 0.953125\n",
      "Training loss: 0.0358553, accuracy: 0.984375\n",
      "Training loss: 0.0385734, accuracy: 1.0\n",
      "Training loss: 0.0587363, accuracy: 0.984375\n",
      "Training loss: 0.008981, accuracy: 1.0\n",
      "Training loss: 0.0995804, accuracy: 0.984375\n",
      "Training loss: 0.207258, accuracy: 0.9375\n",
      "Training loss: 0.0613428, accuracy: 0.96875\n",
      "Training loss: 0.0748078, accuracy: 0.953125\n",
      "Training loss: 0.0402763, accuracy: 0.984375\n",
      "Training loss: 0.0202367, accuracy: 1.0\n",
      "Training loss: 0.138612, accuracy: 0.96875\n",
      "Training loss: 0.092596, accuracy: 0.984375\n",
      "Training loss: 0.157519, accuracy: 0.9375\n",
      "Training loss: 0.109831, accuracy: 0.953125\n",
      "Training loss: 0.0902152, accuracy: 0.96875\n",
      "Training loss: 0.0711013, accuracy: 0.96875\n",
      "Training loss: 0.107681, accuracy: 0.96875\n",
      "Training loss: 0.0326614, accuracy: 1.0\n",
      "Training loss: 0.0702268, accuracy: 0.953125\n",
      "Training loss: 0.0755175, accuracy: 0.96875\n",
      "Training loss: 0.150473, accuracy: 0.953125\n",
      "Training loss: 0.133617, accuracy: 0.984375\n",
      "Training loss: 0.0831347, accuracy: 0.96875\n",
      "Training loss: 0.101311, accuracy: 0.984375\n",
      "Training loss: 0.0750475, accuracy: 0.96875\n",
      "Training loss: 0.040351, accuracy: 1.0\n",
      "Training loss: 0.119572, accuracy: 0.96875\n",
      "Training loss: 0.0893088, accuracy: 0.96875\n",
      "Training loss: 0.0251386, accuracy: 1.0\n",
      "Training loss: 0.053494, accuracy: 0.984375\n",
      "Training loss: 0.0854244, accuracy: 0.96875\n",
      "Training loss: 0.0863345, accuracy: 0.984375\n",
      "Training loss: 0.0650386, accuracy: 0.984375\n",
      "Training loss: 0.219329, accuracy: 0.9375\n",
      "Training loss: 0.017292, accuracy: 1.0\n",
      "Training loss: 0.138915, accuracy: 0.9375\n",
      "Training loss: 0.028635, accuracy: 1.0\n",
      "Training loss: 0.0633622, accuracy: 0.984375\n",
      "Training loss: 0.0844111, accuracy: 0.984375\n",
      "Training loss: 0.169827, accuracy: 0.953125\n",
      "Training loss: 0.0756686, accuracy: 0.953125\n",
      "Training loss: 0.122378, accuracy: 0.96875\n",
      "Training loss: 0.10574, accuracy: 0.96875\n",
      "Training loss: 0.0233728, accuracy: 0.984375\n",
      "Training loss: 0.0226699, accuracy: 1.0\n",
      "Training loss: 0.0241599, accuracy: 1.0\n",
      "Training loss: 0.116948, accuracy: 0.96875\n",
      "Training loss: 0.0715726, accuracy: 0.96875\n",
      "Training loss: 0.0595263, accuracy: 0.96875\n",
      "Training loss: 0.0697909, accuracy: 0.984375\n",
      "Training loss: 0.0828337, accuracy: 0.984375\n",
      "Training loss: 0.042209, accuracy: 0.984375\n",
      "Training loss: 0.146825, accuracy: 0.953125\n",
      "Training loss: 0.101581, accuracy: 0.96875\n",
      "Training loss: 0.128731, accuracy: 0.953125\n",
      "Training loss: 0.016682, accuracy: 1.0\n",
      "Training loss: 0.0158808, accuracy: 1.0\n",
      "Training loss: 0.056542, accuracy: 0.984375\n",
      "Training loss: 0.114461, accuracy: 0.96875\n",
      "Training loss: 0.015495, accuracy: 1.0\n",
      "Training loss: 0.160891, accuracy: 0.96875\n",
      "Training loss: 0.220171, accuracy: 0.953125\n",
      "Training loss: 0.113969, accuracy: 0.96875\n",
      "Training loss: 0.0391798, accuracy: 0.984375\n",
      "Training loss: 0.132827, accuracy: 0.96875\n",
      "Training loss: 0.123995, accuracy: 0.96875\n",
      "Training loss: 0.271029, accuracy: 0.9375\n",
      "Training loss: 0.217668, accuracy: 0.9375\n",
      "Training loss: 0.0860093, accuracy: 0.96875\n",
      "Training loss: 0.0619205, accuracy: 0.96875\n",
      "Training loss: 0.138111, accuracy: 0.96875\n",
      "Training loss: 0.109441, accuracy: 0.953125\n",
      "Training loss: 0.0419067, accuracy: 0.984375\n",
      "Training loss: 0.101765, accuracy: 0.96875\n",
      "Training loss: 0.196032, accuracy: 0.9375\n",
      "Training loss: 0.0238235, accuracy: 1.0\n",
      "Training loss: 0.162044, accuracy: 0.953125\n",
      "Training loss: 0.0451893, accuracy: 1.0\n",
      "Training loss: 0.0573028, accuracy: 0.984375\n",
      "Training loss: 0.0460796, accuracy: 0.984375\n",
      "Training loss: 0.0191771, accuracy: 1.0\n",
      "Training loss: 0.082935, accuracy: 0.984375\n",
      "Training loss: 0.0344011, accuracy: 1.0\n",
      "Training loss: 0.0436214, accuracy: 0.984375\n",
      "Training loss: 0.0259893, accuracy: 1.0\n",
      "Training loss: 0.035061, accuracy: 0.984375\n",
      "Training loss: 0.0739261, accuracy: 0.984375\n",
      "Training loss: 0.0777505, accuracy: 0.984375\n",
      "Training loss: 0.0353347, accuracy: 0.984375\n",
      "Training loss: 0.0182123, accuracy: 1.0\n",
      "----------------- Step 2000: validation accuracy 0.83728 ----------------\n",
      "Training loss: 0.198162, accuracy: 0.9375\n",
      "Training loss: 0.0867562, accuracy: 0.953125\n",
      "Training loss: 0.0494816, accuracy: 0.984375\n",
      "Training loss: 0.0717266, accuracy: 0.96875\n",
      "Training loss: 0.0209439, accuracy: 1.0\n",
      "Training loss: 0.0289527, accuracy: 0.984375\n",
      "Training loss: 0.203825, accuracy: 0.9375\n",
      "Training loss: 0.021183, accuracy: 1.0\n",
      "Training loss: 0.0128243, accuracy: 1.0\n",
      "Training loss: 0.275657, accuracy: 0.953125\n",
      "Training loss: 0.0124143, accuracy: 1.0\n",
      "Training loss: 0.0401511, accuracy: 0.96875\n",
      "Training loss: 0.0827995, accuracy: 0.96875\n",
      "Training loss: 0.0232509, accuracy: 1.0\n",
      "Training loss: 0.0100457, accuracy: 1.0\n",
      "Training loss: 0.00958635, accuracy: 1.0\n",
      "Training loss: 0.0416835, accuracy: 0.984375\n",
      "Training loss: 0.0377849, accuracy: 0.984375\n",
      "Training loss: 0.0488584, accuracy: 0.984375\n",
      "Training loss: 0.166989, accuracy: 0.96875\n",
      "Training loss: 0.017704, accuracy: 1.0\n",
      "Training loss: 0.0110111, accuracy: 1.0\n",
      "Training loss: 0.0167353, accuracy: 1.0\n",
      "Training loss: 0.116147, accuracy: 0.96875\n",
      "Training loss: 0.025722, accuracy: 1.0\n",
      "Training loss: 0.088347, accuracy: 0.984375\n",
      "Training loss: 0.0139357, accuracy: 1.0\n",
      "Training loss: 0.28183, accuracy: 0.921875\n",
      "Training loss: 0.00579164, accuracy: 1.0\n",
      "Training loss: 0.010581, accuracy: 1.0\n",
      "Training loss: 0.00979936, accuracy: 1.0\n",
      "Training loss: 0.00892266, accuracy: 1.0\n",
      "Training loss: 0.100285, accuracy: 0.984375\n",
      "Training loss: 0.0301987, accuracy: 1.0\n",
      "Training loss: 0.0133879, accuracy: 1.0\n",
      "Training loss: 0.0922924, accuracy: 0.984375\n",
      "Training loss: 0.115465, accuracy: 0.96875\n",
      "Training loss: 0.0167628, accuracy: 1.0\n",
      "Training loss: 0.100939, accuracy: 0.96875\n",
      "Training loss: 0.0589942, accuracy: 0.984375\n",
      "Training loss: 0.0834719, accuracy: 0.984375\n",
      "Training loss: 0.0350154, accuracy: 0.984375\n",
      "Training loss: 0.183245, accuracy: 0.953125\n",
      "Training loss: 0.105707, accuracy: 0.984375\n",
      "Training loss: 0.00746942, accuracy: 1.0\n",
      "Training loss: 0.30971, accuracy: 0.921875\n",
      "Training loss: 0.147462, accuracy: 0.984375\n",
      "Training loss: 0.0269224, accuracy: 1.0\n",
      "Training loss: 0.0128202, accuracy: 1.0\n",
      "Training loss: 0.140521, accuracy: 0.96875\n",
      "Training loss: 0.163023, accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0652676, accuracy: 0.96875\n",
      "Training loss: 0.0365265, accuracy: 0.984375\n",
      "Training loss: 0.227183, accuracy: 0.953125\n",
      "Training loss: 0.0236744, accuracy: 1.0\n",
      "Training loss: 0.16151, accuracy: 0.9375\n",
      "Training loss: 0.0136344, accuracy: 1.0\n",
      "Training loss: 0.103506, accuracy: 0.96875\n",
      "Training loss: 0.0188843, accuracy: 1.0\n",
      "Training loss: 0.0292239, accuracy: 1.0\n",
      "Training loss: 0.043277, accuracy: 0.984375\n",
      "Training loss: 0.104084, accuracy: 0.953125\n",
      "Training loss: 0.0563433, accuracy: 0.984375\n",
      "Training loss: 0.0469383, accuracy: 0.984375\n",
      "Training loss: 0.10326, accuracy: 0.96875\n",
      "Training loss: 0.0398159, accuracy: 0.984375\n",
      "Training loss: 0.0543891, accuracy: 0.984375\n",
      "Training loss: 0.087815, accuracy: 0.984375\n",
      "Training loss: 0.0169461, accuracy: 1.0\n",
      "Training loss: 0.016747, accuracy: 1.0\n",
      "Training loss: 0.0975059, accuracy: 0.96875\n",
      "Training loss: 0.158907, accuracy: 0.96875\n",
      "Training loss: 0.0624446, accuracy: 0.96875\n",
      "Training loss: 0.0134142, accuracy: 1.0\n",
      "Training loss: 0.0988198, accuracy: 0.984375\n",
      "Training loss: 0.061081, accuracy: 0.96875\n",
      "Training loss: 0.0141833, accuracy: 1.0\n",
      "Training loss: 0.0274563, accuracy: 1.0\n",
      "Training loss: 0.062428, accuracy: 0.96875\n",
      "Training loss: 0.0538655, accuracy: 0.984375\n",
      "Training loss: 0.164934, accuracy: 0.96875\n",
      "Training loss: 0.0449618, accuracy: 0.984375\n",
      "Training loss: 0.096401, accuracy: 0.984375\n",
      "Training loss: 0.0816371, accuracy: 0.984375\n",
      "Training loss: 0.0621821, accuracy: 0.96875\n",
      "Training loss: 0.0167463, accuracy: 1.0\n",
      "Training loss: 0.0125418, accuracy: 1.0\n",
      "Training loss: 0.0309671, accuracy: 0.984375\n",
      "Training loss: 0.0378557, accuracy: 0.984375\n",
      "Training loss: 0.0178905, accuracy: 1.0\n",
      "Training loss: 0.0106427, accuracy: 1.0\n",
      "Training loss: 0.0916, accuracy: 0.984375\n",
      "Training loss: 0.0473093, accuracy: 1.0\n",
      "Training loss: 0.0308143, accuracy: 0.984375\n",
      "Training loss: 0.195784, accuracy: 0.921875\n",
      "Training loss: 0.0734081, accuracy: 0.96875\n",
      "Training loss: 0.148949, accuracy: 0.953125\n",
      "Training loss: 0.0283844, accuracy: 0.984375\n",
      "Training loss: 0.107834, accuracy: 0.96875\n",
      "Training loss: 0.145266, accuracy: 0.96875\n",
      "----------------- Step 2100: validation accuracy 0.82624 ----------------\n",
      "Training loss: 0.137556, accuracy: 0.953125\n",
      "Training loss: 0.187944, accuracy: 0.96875\n",
      "Training loss: 0.294468, accuracy: 0.90625\n",
      "Training loss: 0.0174332, accuracy: 1.0\n",
      "Training loss: 0.0153668, accuracy: 1.0\n",
      "Training loss: 0.00964567, accuracy: 1.0\n",
      "Training loss: 0.230212, accuracy: 0.953125\n",
      "Training loss: 0.02886, accuracy: 1.0\n",
      "Training loss: 0.13231, accuracy: 0.953125\n",
      "Training loss: 0.0987304, accuracy: 0.984375\n",
      "Training loss: 0.127606, accuracy: 0.953125\n",
      "Training loss: 0.0853987, accuracy: 0.984375\n",
      "Training loss: 0.0749794, accuracy: 0.984375\n",
      "Training loss: 0.366461, accuracy: 0.90625\n",
      "Training loss: 0.071177, accuracy: 0.984375\n",
      "Training loss: 0.325013, accuracy: 0.890625\n",
      "Training loss: 0.0779078, accuracy: 0.96875\n",
      "Training loss: 0.16894, accuracy: 0.96875\n",
      "Training loss: 0.0391478, accuracy: 1.0\n",
      "Training loss: 0.0915717, accuracy: 0.984375\n",
      "Training loss: 0.104549, accuracy: 0.96875\n",
      "Training loss: 0.0291788, accuracy: 1.0\n",
      "Training loss: 0.0480961, accuracy: 1.0\n",
      "Training loss: 0.0508874, accuracy: 0.984375\n",
      "Training loss: 0.0789317, accuracy: 0.984375\n",
      "Training loss: 0.0995189, accuracy: 0.96875\n",
      "Training loss: 0.0303795, accuracy: 1.0\n",
      "Training loss: 0.152525, accuracy: 0.953125\n",
      "Training loss: 0.141112, accuracy: 0.96875\n",
      "Training loss: 0.0840233, accuracy: 0.984375\n",
      "Training loss: 0.109635, accuracy: 0.96875\n",
      "Training loss: 0.07477, accuracy: 0.96875\n",
      "Training loss: 0.216062, accuracy: 0.953125\n",
      "Training loss: 0.0314063, accuracy: 1.0\n",
      "Training loss: 0.0251338, accuracy: 1.0\n",
      "Training loss: 0.0475343, accuracy: 0.984375\n",
      "Training loss: 0.0523626, accuracy: 0.984375\n",
      "Training loss: 0.0444448, accuracy: 1.0\n",
      "Training loss: 0.191614, accuracy: 0.953125\n",
      "Training loss: 0.0325991, accuracy: 0.984375\n",
      "Training loss: 0.0478364, accuracy: 0.984375\n",
      "Training loss: 0.0394888, accuracy: 0.984375\n",
      "Training loss: 0.156777, accuracy: 0.96875\n",
      "Training loss: 0.053552, accuracy: 0.96875\n",
      "Training loss: 0.0489722, accuracy: 0.984375\n",
      "Training loss: 0.0169377, accuracy: 1.0\n",
      "Training loss: 0.156461, accuracy: 0.953125\n",
      "Training loss: 0.0413244, accuracy: 0.96875\n",
      "Training loss: 0.025691, accuracy: 1.0\n",
      "Training loss: 0.0192956, accuracy: 1.0\n",
      "Training loss: 0.0265637, accuracy: 0.984375\n",
      "Training loss: 0.0771839, accuracy: 0.96875\n",
      "Training loss: 0.0187918, accuracy: 1.0\n",
      "Training loss: 0.152162, accuracy: 0.953125\n",
      "Training loss: 0.107822, accuracy: 0.984375\n",
      "Training loss: 0.029153, accuracy: 0.984375\n",
      "Training loss: 0.0180556, accuracy: 1.0\n",
      "Training loss: 0.0358697, accuracy: 0.984375\n",
      "Training loss: 0.0194849, accuracy: 1.0\n",
      "Training loss: 0.122432, accuracy: 0.984375\n",
      "Training loss: 0.00653302, accuracy: 1.0\n",
      "Training loss: 0.0429318, accuracy: 0.984375\n",
      "Training loss: 0.0195193, accuracy: 1.0\n",
      "Training loss: 0.0578855, accuracy: 0.984375\n",
      "Training loss: 0.102207, accuracy: 0.984375\n",
      "Training loss: 0.10493, accuracy: 0.984375\n",
      "Training loss: 0.123693, accuracy: 0.96875\n",
      "Training loss: 0.0840528, accuracy: 0.984375\n",
      "Training loss: 0.076812, accuracy: 0.984375\n",
      "Training loss: 0.0132513, accuracy: 1.0\n",
      "Training loss: 0.00565006, accuracy: 1.0\n",
      "Training loss: 0.0840365, accuracy: 0.96875\n",
      "Training loss: 0.157085, accuracy: 0.953125\n",
      "Training loss: 0.0156099, accuracy: 1.0\n",
      "Training loss: 0.14064, accuracy: 0.953125\n",
      "Training loss: 0.00687929, accuracy: 1.0\n",
      "Training loss: 0.0533261, accuracy: 0.984375\n",
      "Training loss: 0.109381, accuracy: 0.984375\n",
      "Training loss: 0.0402512, accuracy: 0.984375\n",
      "Training loss: 0.0400923, accuracy: 0.984375\n",
      "Training loss: 0.0946217, accuracy: 0.96875\n",
      "Training loss: 0.00923542, accuracy: 1.0\n",
      "Training loss: 0.0496374, accuracy: 0.984375\n",
      "Training loss: 0.0148907, accuracy: 1.0\n",
      "Training loss: 0.0277432, accuracy: 1.0\n",
      "Training loss: 0.0762884, accuracy: 0.984375\n",
      "Training loss: 0.060215, accuracy: 0.984375\n",
      "Training loss: 0.0250726, accuracy: 1.0\n",
      "Training loss: 0.0661104, accuracy: 0.96875\n",
      "Training loss: 0.0168917, accuracy: 1.0\n",
      "Training loss: 0.028936, accuracy: 0.984375\n",
      "Training loss: 0.0466927, accuracy: 0.984375\n",
      "Training loss: 0.0168188, accuracy: 1.0\n",
      "Training loss: 0.10385, accuracy: 0.984375\n",
      "Training loss: 0.0275966, accuracy: 1.0\n",
      "Training loss: 0.192021, accuracy: 0.9375\n",
      "Training loss: 0.0809897, accuracy: 0.984375\n",
      "Training loss: 0.0659357, accuracy: 0.96875\n",
      "Training loss: 0.101665, accuracy: 0.984375\n",
      "Training loss: 0.0413465, accuracy: 0.984375\n",
      "----------------- Step 2200: validation accuracy 0.83456 ----------------\n",
      "Training loss: 0.149034, accuracy: 0.953125\n",
      "Training loss: 0.0140328, accuracy: 1.0\n",
      "Training loss: 0.112084, accuracy: 0.96875\n",
      "Training loss: 0.00884881, accuracy: 1.0\n",
      "Training loss: 0.0342995, accuracy: 1.0\n",
      "Training loss: 0.0171967, accuracy: 1.0\n",
      "Training loss: 0.010621, accuracy: 1.0\n",
      "Training loss: 0.00805485, accuracy: 1.0\n",
      "Training loss: 0.145962, accuracy: 0.96875\n",
      "Training loss: 0.0204312, accuracy: 1.0\n",
      "Training loss: 0.0339743, accuracy: 0.984375\n",
      "Training loss: 0.0665114, accuracy: 0.984375\n",
      "Training loss: 0.0280568, accuracy: 0.984375\n",
      "Training loss: 0.141084, accuracy: 0.96875\n",
      "Training loss: 0.0884153, accuracy: 0.984375\n",
      "Training loss: 0.0507366, accuracy: 0.984375\n",
      "Training loss: 0.0504481, accuracy: 0.96875\n",
      "Training loss: 0.0108506, accuracy: 1.0\n",
      "Training loss: 0.0447503, accuracy: 0.984375\n",
      "Training loss: 0.125377, accuracy: 0.953125\n",
      "Training loss: 0.0745724, accuracy: 0.984375\n",
      "Training loss: 0.0612758, accuracy: 0.96875\n",
      "Training loss: 0.0551257, accuracy: 0.96875\n",
      "Training loss: 0.0203904, accuracy: 1.0\n",
      "Training loss: 0.11204, accuracy: 0.984375\n",
      "Training loss: 0.0692926, accuracy: 0.984375\n",
      "Training loss: 0.0963388, accuracy: 0.984375\n",
      "Training loss: 0.0420625, accuracy: 0.984375\n",
      "Training loss: 0.0925896, accuracy: 0.96875\n",
      "Training loss: 0.0091969, accuracy: 1.0\n",
      "Training loss: 0.10161, accuracy: 0.96875\n",
      "Training loss: 0.0470618, accuracy: 0.984375\n",
      "Training loss: 0.0109091, accuracy: 1.0\n",
      "Training loss: 0.0248145, accuracy: 0.984375\n",
      "Training loss: 0.0782769, accuracy: 0.984375\n",
      "Training loss: 0.0655749, accuracy: 0.984375\n",
      "Training loss: 0.189594, accuracy: 0.96875\n",
      "Training loss: 0.0316646, accuracy: 0.984375\n",
      "Training loss: 0.0548099, accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0134934, accuracy: 1.0\n",
      "Training loss: 0.0992913, accuracy: 0.984375\n",
      "Training loss: 0.0677993, accuracy: 0.984375\n",
      "Training loss: 0.0265921, accuracy: 1.0\n",
      "Training loss: 0.0635932, accuracy: 0.984375\n",
      "Training loss: 0.100325, accuracy: 0.984375\n",
      "Training loss: 0.0244081, accuracy: 1.0\n",
      "Training loss: 0.00603471, accuracy: 1.0\n",
      "Training loss: 0.00934772, accuracy: 1.0\n",
      "Training loss: 0.018811, accuracy: 0.984375\n",
      "Training loss: 0.0113918, accuracy: 1.0\n",
      "Training loss: 0.0522434, accuracy: 0.96875\n",
      "Training loss: 0.0397025, accuracy: 0.984375\n",
      "Training loss: 0.066626, accuracy: 0.984375\n",
      "Training loss: 0.10177, accuracy: 0.96875\n",
      "Training loss: 0.01844, accuracy: 1.0\n",
      "Training loss: 0.105178, accuracy: 0.984375\n",
      "Training loss: 0.0548624, accuracy: 0.953125\n",
      "Training loss: 0.147987, accuracy: 0.953125\n",
      "Training loss: 0.0572593, accuracy: 0.984375\n",
      "Training loss: 0.0109132, accuracy: 1.0\n",
      "Training loss: 0.0490329, accuracy: 0.96875\n",
      "Training loss: 0.111286, accuracy: 0.984375\n",
      "Training loss: 0.0143873, accuracy: 1.0\n",
      "Training loss: 0.195577, accuracy: 0.953125\n",
      "Training loss: 0.187516, accuracy: 0.96875\n",
      "Training loss: 0.142634, accuracy: 0.953125\n",
      "Training loss: 0.0636469, accuracy: 0.984375\n",
      "Training loss: 0.0763917, accuracy: 0.96875\n",
      "Training loss: 0.229026, accuracy: 0.921875\n",
      "Training loss: 0.227257, accuracy: 0.953125\n",
      "Training loss: 0.19198, accuracy: 0.9375\n",
      "Training loss: 0.0854977, accuracy: 0.984375\n",
      "Training loss: 0.0591148, accuracy: 0.984375\n",
      "Training loss: 0.0392254, accuracy: 0.984375\n",
      "Training loss: 0.126891, accuracy: 0.953125\n",
      "Training loss: 0.0338743, accuracy: 0.984375\n",
      "Training loss: 0.0609042, accuracy: 0.984375\n",
      "Training loss: 0.128197, accuracy: 0.96875\n",
      "Training loss: 0.0477889, accuracy: 1.0\n",
      "Training loss: 0.127086, accuracy: 0.96875\n",
      "Training loss: 0.0636779, accuracy: 0.96875\n",
      "Training loss: 0.0603485, accuracy: 0.984375\n",
      "Training loss: 0.0392362, accuracy: 1.0\n",
      "Training loss: 0.0460216, accuracy: 0.984375\n",
      "Training loss: 0.119916, accuracy: 0.953125\n",
      "Training loss: 0.0183931, accuracy: 1.0\n",
      "Training loss: 0.0182638, accuracy: 1.0\n",
      "Training loss: 0.0164488, accuracy: 1.0\n",
      "Training loss: 0.0392924, accuracy: 0.984375\n",
      "Training loss: 0.015287, accuracy: 1.0\n",
      "Training loss: 0.0242631, accuracy: 1.0\n",
      "Training loss: 0.0174051, accuracy: 1.0\n",
      "Training loss: 0.0315394, accuracy: 0.984375\n",
      "Training loss: 0.112317, accuracy: 0.984375\n",
      "Training loss: 0.137989, accuracy: 0.96875\n",
      "Training loss: 0.0477504, accuracy: 0.96875\n",
      "Training loss: 0.0681653, accuracy: 0.984375\n",
      "Training loss: 0.0218987, accuracy: 1.0\n",
      "Training loss: 0.0148329, accuracy: 1.0\n",
      "Training loss: 0.17708, accuracy: 0.96875\n",
      "----------------- Step 2300: validation accuracy 0.84192 ----------------\n",
      "Training loss: 0.00928405, accuracy: 1.0\n",
      "Training loss: 0.0175553, accuracy: 1.0\n",
      "Training loss: 0.270752, accuracy: 0.953125\n",
      "Training loss: 0.121818, accuracy: 0.96875\n",
      "Training loss: 0.0341307, accuracy: 0.984375\n",
      "Training loss: 0.0254063, accuracy: 0.984375\n",
      "Training loss: 0.0529176, accuracy: 0.96875\n",
      "Training loss: 0.00763476, accuracy: 1.0\n",
      "Training loss: 0.00868038, accuracy: 1.0\n",
      "Training loss: 0.0258834, accuracy: 0.984375\n",
      "Training loss: 0.0108954, accuracy: 1.0\n",
      "Training loss: 0.00513395, accuracy: 1.0\n",
      "Training loss: 0.0929149, accuracy: 0.984375\n",
      "Training loss: 0.0609781, accuracy: 0.96875\n",
      "Training loss: 0.0261706, accuracy: 0.984375\n",
      "Training loss: 0.0138946, accuracy: 1.0\n",
      "Training loss: 0.126063, accuracy: 0.96875\n",
      "Training loss: 0.0166594, accuracy: 0.984375\n",
      "Training loss: 0.0597869, accuracy: 0.984375\n",
      "Training loss: 0.076593, accuracy: 0.953125\n",
      "Training loss: 0.186671, accuracy: 0.96875\n",
      "Training loss: 0.00492028, accuracy: 1.0\n",
      "Training loss: 0.0196443, accuracy: 0.984375\n",
      "Training loss: 0.022667, accuracy: 0.984375\n",
      "Training loss: 0.0179456, accuracy: 0.984375\n",
      "Training loss: 0.0418194, accuracy: 0.984375\n",
      "Training loss: 0.0281693, accuracy: 1.0\n",
      "Training loss: 0.0155468, accuracy: 1.0\n",
      "Training loss: 0.0687719, accuracy: 0.96875\n",
      "Training loss: 0.109549, accuracy: 0.984375\n",
      "Training loss: 0.0537047, accuracy: 0.984375\n",
      "Training loss: 0.0365507, accuracy: 0.984375\n",
      "Training loss: 0.0185185, accuracy: 0.984375\n",
      "Training loss: 0.0366716, accuracy: 0.984375\n",
      "Training loss: 0.0164114, accuracy: 1.0\n",
      "Training loss: 0.121867, accuracy: 0.984375\n",
      "Training loss: 0.069436, accuracy: 0.984375\n",
      "Training loss: 0.00570919, accuracy: 1.0\n",
      "Training loss: 0.148157, accuracy: 0.96875\n",
      "Training loss: 0.122655, accuracy: 0.984375\n",
      "Training loss: 0.01842, accuracy: 1.0\n",
      "Training loss: 0.0144973, accuracy: 1.0\n",
      "Training loss: 0.114602, accuracy: 0.984375\n",
      "Training loss: 0.107037, accuracy: 0.96875\n",
      "Training loss: 0.045259, accuracy: 0.96875\n",
      "Training loss: 0.00835699, accuracy: 1.0\n",
      "Training loss: 0.240421, accuracy: 0.9375\n",
      "Training loss: 0.0222416, accuracy: 0.984375\n",
      "Training loss: 0.0644847, accuracy: 0.984375\n",
      "Training loss: 0.00644198, accuracy: 1.0\n",
      "Training loss: 0.0606267, accuracy: 0.984375\n",
      "Training loss: 0.00943219, accuracy: 1.0\n",
      "Training loss: 0.0112826, accuracy: 1.0\n",
      "Training loss: 0.0549786, accuracy: 0.984375\n",
      "Training loss: 0.106338, accuracy: 0.96875\n",
      "Training loss: 0.0167573, accuracy: 1.0\n",
      "Training loss: 0.016508, accuracy: 1.0\n",
      "Training loss: 0.0351839, accuracy: 0.984375\n",
      "Training loss: 0.0103786, accuracy: 1.0\n",
      "Training loss: 0.286869, accuracy: 0.921875\n",
      "Training loss: 0.102294, accuracy: 0.96875\n",
      "Training loss: 0.016816, accuracy: 1.0\n",
      "Training loss: 0.0263244, accuracy: 1.0\n",
      "Training loss: 0.121291, accuracy: 0.953125\n",
      "Training loss: 0.110054, accuracy: 0.96875\n",
      "Training loss: 0.0462388, accuracy: 0.984375\n",
      "Training loss: 0.0873276, accuracy: 0.984375\n",
      "Training loss: 0.0725415, accuracy: 0.984375\n",
      "Training loss: 0.0305241, accuracy: 0.984375\n",
      "Training loss: 0.0713086, accuracy: 0.984375\n",
      "Training loss: 0.0282511, accuracy: 0.984375\n",
      "Training loss: 0.0208865, accuracy: 1.0\n",
      "Training loss: 0.054011, accuracy: 0.984375\n",
      "Training loss: 0.136047, accuracy: 0.96875\n",
      "Training loss: 0.0136296, accuracy: 1.0\n",
      "Training loss: 0.0970709, accuracy: 0.984375\n",
      "Training loss: 0.0607178, accuracy: 0.984375\n",
      "Training loss: 0.0493501, accuracy: 0.984375\n",
      "Training loss: 0.0174895, accuracy: 1.0\n",
      "Training loss: 0.00651463, accuracy: 1.0\n",
      "Training loss: 0.0179816, accuracy: 1.0\n",
      "Training loss: 0.0307369, accuracy: 0.984375\n",
      "Training loss: 0.0230369, accuracy: 0.984375\n",
      "Training loss: 0.0526549, accuracy: 0.96875\n",
      "Training loss: 0.117434, accuracy: 0.96875\n",
      "Training loss: 0.117763, accuracy: 0.984375\n",
      "Training loss: 0.0198247, accuracy: 1.0\n",
      "Training loss: 0.147144, accuracy: 0.984375\n",
      "Training loss: 0.0574057, accuracy: 0.96875\n",
      "Training loss: 0.0500785, accuracy: 0.984375\n",
      "Training loss: 0.0132977, accuracy: 1.0\n",
      "Training loss: 0.0827009, accuracy: 0.984375\n",
      "Training loss: 0.120956, accuracy: 0.96875\n",
      "Training loss: 0.0785035, accuracy: 0.984375\n",
      "Training loss: 0.0720212, accuracy: 0.953125\n",
      "Training loss: 0.166503, accuracy: 0.96875\n",
      "Training loss: 0.00823623, accuracy: 1.0\n",
      "Training loss: 0.0142359, accuracy: 1.0\n",
      "Training loss: 0.0282955, accuracy: 0.984375\n",
      "Training loss: 0.204473, accuracy: 0.953125\n",
      "----------------- Step 2400: validation accuracy 0.83712 ----------------\n",
      "Training loss: 0.0249582, accuracy: 1.0\n",
      "Training loss: 0.184042, accuracy: 0.96875\n",
      "Training loss: 0.0073375, accuracy: 1.0\n",
      "Training loss: 0.201436, accuracy: 0.953125\n",
      "Training loss: 0.0888956, accuracy: 0.984375\n",
      "Training loss: 0.0716356, accuracy: 0.984375\n",
      "Training loss: 0.240307, accuracy: 0.953125\n",
      "Training loss: 0.0568869, accuracy: 0.984375\n",
      "Training loss: 0.165657, accuracy: 0.96875\n",
      "Training loss: 0.0287806, accuracy: 0.984375\n",
      "Training loss: 0.117331, accuracy: 0.96875\n",
      "Training loss: 0.076832, accuracy: 0.984375\n",
      "Training loss: 0.0912243, accuracy: 0.984375\n",
      "Training loss: 0.0612067, accuracy: 0.984375\n",
      "Training loss: 0.0231304, accuracy: 1.0\n",
      "Training loss: 0.0543884, accuracy: 0.984375\n",
      "Training loss: 0.0906729, accuracy: 0.96875\n",
      "Training loss: 0.157592, accuracy: 0.953125\n",
      "Training loss: 0.196187, accuracy: 0.9375\n",
      "Training loss: 0.0839205, accuracy: 0.984375\n",
      "Training loss: 0.0889078, accuracy: 0.984375\n",
      "Training loss: 0.161646, accuracy: 0.96875\n",
      "Training loss: 0.115641, accuracy: 0.96875\n",
      "Training loss: 0.119034, accuracy: 0.96875\n",
      "Training loss: 0.0536558, accuracy: 0.984375\n",
      "Training loss: 0.280505, accuracy: 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.203993, accuracy: 0.9375\n",
      "Training loss: 0.0300753, accuracy: 1.0\n",
      "Training loss: 0.0287427, accuracy: 1.0\n",
      "Training loss: 0.0254767, accuracy: 1.0\n",
      "Training loss: 0.046626, accuracy: 1.0\n",
      "Training loss: 0.17085, accuracy: 0.953125\n",
      "Training loss: 0.019648, accuracy: 1.0\n",
      "Training loss: 0.0565728, accuracy: 0.984375\n",
      "Training loss: 0.0578145, accuracy: 0.984375\n",
      "Training loss: 0.0643665, accuracy: 0.984375\n",
      "Training loss: 0.0250919, accuracy: 1.0\n",
      "Training loss: 0.19185, accuracy: 0.96875\n",
      "Training loss: 0.0176504, accuracy: 1.0\n",
      "Training loss: 0.0415388, accuracy: 0.984375\n",
      "Training loss: 0.0719822, accuracy: 0.984375\n",
      "Training loss: 0.033604, accuracy: 0.984375\n",
      "Training loss: 0.138282, accuracy: 0.96875\n",
      "Training loss: 0.0198183, accuracy: 1.0\n",
      "Training loss: 0.0281711, accuracy: 1.0\n",
      "Training loss: 0.082809, accuracy: 0.96875\n",
      "Training loss: 0.134533, accuracy: 0.984375\n",
      "Training loss: 0.0733915, accuracy: 0.984375\n",
      "Training loss: 0.0767985, accuracy: 0.984375\n",
      "Training loss: 0.065818, accuracy: 0.96875\n",
      "Training loss: 0.0177026, accuracy: 1.0\n",
      "Training loss: 0.0295319, accuracy: 0.984375\n",
      "Training loss: 0.122987, accuracy: 0.984375\n",
      "Training loss: 0.0134448, accuracy: 1.0\n",
      "Training loss: 0.0456528, accuracy: 0.96875\n",
      "Training loss: 0.0751713, accuracy: 0.984375\n",
      "Training loss: 0.202092, accuracy: 0.953125\n",
      "Training loss: 0.102959, accuracy: 0.953125\n",
      "Training loss: 0.0671185, accuracy: 0.984375\n",
      "Training loss: 0.0506858, accuracy: 0.984375\n",
      "Training loss: 0.0744818, accuracy: 0.984375\n",
      "Training loss: 0.106087, accuracy: 0.96875\n",
      "Training loss: 0.0158607, accuracy: 1.0\n",
      "Training loss: 0.0344774, accuracy: 0.984375\n",
      "Training loss: 0.0284929, accuracy: 0.984375\n",
      "Training loss: 0.098423, accuracy: 0.984375\n",
      "Training loss: 0.103941, accuracy: 0.953125\n",
      "Training loss: 0.060306, accuracy: 0.96875\n",
      "Training loss: 0.0215221, accuracy: 0.984375\n",
      "Training loss: 0.0398997, accuracy: 0.984375\n",
      "Training loss: 0.184981, accuracy: 0.953125\n",
      "Training loss: 0.0923005, accuracy: 0.984375\n",
      "Training loss: 0.0149387, accuracy: 1.0\n",
      "Training loss: 0.0211208, accuracy: 1.0\n",
      "Training loss: 0.144602, accuracy: 0.9375\n",
      "Training loss: 0.03096, accuracy: 1.0\n",
      "Training loss: 0.123781, accuracy: 0.96875\n",
      "Training loss: 0.184504, accuracy: 0.9375\n",
      "Training loss: 0.330361, accuracy: 0.921875\n",
      "Training loss: 0.25351, accuracy: 0.921875\n",
      "Training loss: 0.173191, accuracy: 0.90625\n",
      "Training loss: 0.097314, accuracy: 0.96875\n",
      "Training loss: 0.0627461, accuracy: 0.984375\n",
      "Training loss: 0.073304, accuracy: 0.984375\n",
      "Training loss: 0.0293194, accuracy: 1.0\n",
      "Training loss: 0.057541, accuracy: 0.984375\n",
      "Training loss: 0.0421906, accuracy: 1.0\n",
      "Training loss: 0.0554009, accuracy: 1.0\n",
      "Training loss: 0.126725, accuracy: 0.96875\n",
      "Training loss: 0.0287811, accuracy: 1.0\n",
      "Training loss: 0.10117, accuracy: 0.96875\n",
      "Training loss: 0.125972, accuracy: 0.96875\n",
      "Training loss: 0.0435277, accuracy: 0.984375\n",
      "Training loss: 0.106475, accuracy: 0.96875\n",
      "Training loss: 0.0669467, accuracy: 0.984375\n",
      "Training loss: 0.0673221, accuracy: 0.96875\n",
      "Training loss: 0.0468857, accuracy: 0.984375\n",
      "Training loss: 0.163787, accuracy: 0.9375\n",
      "Training loss: 0.0651041, accuracy: 0.984375\n",
      "Training loss: 0.0979205, accuracy: 0.984375\n",
      "----------------- Step 2500: validation accuracy 0.81104 ----------------\n",
      "Training loss: 0.0493011, accuracy: 0.984375\n",
      "Training loss: 0.168097, accuracy: 0.953125\n",
      "Training loss: 0.021226, accuracy: 1.0\n",
      "Training loss: 0.0420048, accuracy: 0.984375\n",
      "Training loss: 0.0307479, accuracy: 1.0\n",
      "Training loss: 0.010161, accuracy: 1.0\n",
      "Training loss: 0.0823268, accuracy: 0.953125\n",
      "Training loss: 0.0562424, accuracy: 0.984375\n",
      "Training loss: 0.0807529, accuracy: 0.96875\n",
      "Training loss: 0.0827865, accuracy: 0.96875\n",
      "Training loss: 0.0183701, accuracy: 1.0\n",
      "Training loss: 0.0144439, accuracy: 1.0\n",
      "Training loss: 0.165515, accuracy: 0.953125\n",
      "Training loss: 0.0152445, accuracy: 1.0\n",
      "Training loss: 0.134268, accuracy: 0.96875\n",
      "Training loss: 0.0394459, accuracy: 0.984375\n",
      "Training loss: 0.0149405, accuracy: 1.0\n",
      "Training loss: 0.149556, accuracy: 0.984375\n",
      "Training loss: 0.0697142, accuracy: 0.96875\n",
      "Training loss: 0.0884316, accuracy: 0.984375\n",
      "Training loss: 0.116472, accuracy: 0.96875\n",
      "Training loss: 0.062321, accuracy: 0.96875\n",
      "Training loss: 0.0651866, accuracy: 0.984375\n",
      "Training loss: 0.0373289, accuracy: 0.984375\n",
      "Training loss: 0.0282526, accuracy: 0.984375\n",
      "Training loss: 0.00861382, accuracy: 1.0\n",
      "Training loss: 0.0196887, accuracy: 1.0\n",
      "Training loss: 0.123545, accuracy: 0.96875\n",
      "Training loss: 0.0119783, accuracy: 1.0\n",
      "Training loss: 0.180952, accuracy: 0.953125\n",
      "Training loss: 0.0105127, accuracy: 1.0\n",
      "Training loss: 0.0310809, accuracy: 0.984375\n",
      "Training loss: 0.0678668, accuracy: 0.96875\n",
      "Training loss: 0.100632, accuracy: 0.984375\n",
      "Training loss: 0.0477288, accuracy: 0.984375\n",
      "Training loss: 0.0264013, accuracy: 1.0\n",
      "Training loss: 0.0220528, accuracy: 1.0\n",
      "Training loss: 0.0846367, accuracy: 0.984375\n",
      "Training loss: 0.0995805, accuracy: 0.96875\n",
      "Training loss: 0.00607789, accuracy: 1.0\n",
      "Training loss: 0.010298, accuracy: 1.0\n",
      "Training loss: 0.0705756, accuracy: 0.984375\n",
      "Training loss: 0.0105063, accuracy: 1.0\n",
      "Training loss: 0.0133433, accuracy: 1.0\n",
      "Training loss: 0.030121, accuracy: 1.0\n",
      "Training loss: 0.0259214, accuracy: 0.984375\n",
      "Training loss: 0.161656, accuracy: 0.96875\n",
      "Training loss: 0.0287566, accuracy: 1.0\n",
      "Training loss: 0.105109, accuracy: 0.984375\n",
      "Training loss: 0.0153588, accuracy: 1.0\n",
      "Training loss: 0.12025, accuracy: 0.96875\n",
      "Training loss: 0.0201794, accuracy: 1.0\n",
      "Training loss: 0.0730106, accuracy: 0.953125\n",
      "Training loss: 0.0159744, accuracy: 1.0\n",
      "Training loss: 0.102253, accuracy: 0.96875\n",
      "Training loss: 0.0165852, accuracy: 1.0\n",
      "Training loss: 0.285253, accuracy: 0.953125\n",
      "Training loss: 0.209067, accuracy: 0.953125\n",
      "Training loss: 0.0225843, accuracy: 0.984375\n",
      "Training loss: 0.0773406, accuracy: 0.984375\n",
      "Training loss: 0.0918438, accuracy: 0.984375\n",
      "Training loss: 0.130754, accuracy: 0.96875\n",
      "Training loss: 0.163756, accuracy: 0.953125\n",
      "Training loss: 0.213826, accuracy: 0.953125\n",
      "Training loss: 0.0229676, accuracy: 1.0\n",
      "Training loss: 0.019696, accuracy: 1.0\n",
      "Training loss: 0.0244696, accuracy: 0.984375\n",
      "Training loss: 0.0937166, accuracy: 0.96875\n",
      "Training loss: 0.0372773, accuracy: 0.984375\n",
      "Training loss: 0.0729742, accuracy: 0.96875\n",
      "Training loss: 0.109102, accuracy: 0.96875\n",
      "Training loss: 0.0385243, accuracy: 0.984375\n",
      "Training loss: 0.0836792, accuracy: 0.984375\n",
      "Training loss: 0.0200913, accuracy: 1.0\n",
      "Training loss: 0.0233897, accuracy: 1.0\n",
      "Training loss: 0.033757, accuracy: 0.984375\n",
      "Training loss: 0.0126844, accuracy: 1.0\n",
      "Training loss: 0.0626323, accuracy: 0.984375\n",
      "Training loss: 0.0711106, accuracy: 0.96875\n",
      "Training loss: 0.0263928, accuracy: 1.0\n",
      "Training loss: 0.0207208, accuracy: 1.0\n",
      "Training loss: 0.124571, accuracy: 0.96875\n",
      "Training loss: 0.0253151, accuracy: 0.984375\n",
      "Training loss: 0.0155776, accuracy: 1.0\n",
      "Training loss: 0.0368366, accuracy: 1.0\n",
      "Training loss: 0.0321248, accuracy: 0.984375\n",
      "Training loss: 0.167492, accuracy: 0.9375\n",
      "Training loss: 0.0114172, accuracy: 1.0\n",
      "Training loss: 0.0335396, accuracy: 1.0\n",
      "Training loss: 0.0133676, accuracy: 1.0\n",
      "Training loss: 0.0933387, accuracy: 0.96875\n",
      "Training loss: 0.145991, accuracy: 0.9375\n",
      "Training loss: 0.207186, accuracy: 0.953125\n",
      "Training loss: 0.0573537, accuracy: 0.96875\n",
      "Training loss: 0.0667153, accuracy: 0.984375\n",
      "Training loss: 0.195637, accuracy: 0.96875\n",
      "Training loss: 0.0738609, accuracy: 0.96875\n",
      "Training loss: 0.0560415, accuracy: 0.984375\n",
      "Training loss: 0.0278221, accuracy: 1.0\n",
      "Training loss: 0.0145428, accuracy: 1.0\n",
      "----------------- Step 2600: validation accuracy 0.81904 ----------------\n",
      "Training loss: 0.0252047, accuracy: 0.984375\n",
      "Training loss: 0.0790729, accuracy: 0.984375\n",
      "Training loss: 0.0451555, accuracy: 0.96875\n",
      "Training loss: 0.0457002, accuracy: 1.0\n",
      "Training loss: 0.0239714, accuracy: 0.984375\n",
      "Training loss: 0.0960505, accuracy: 0.984375\n",
      "Training loss: 0.128269, accuracy: 0.953125\n",
      "Training loss: 0.0557227, accuracy: 0.984375\n",
      "Training loss: 0.0440231, accuracy: 0.984375\n",
      "Training loss: 0.0266696, accuracy: 0.984375\n",
      "Training loss: 0.00910155, accuracy: 1.0\n",
      "Training loss: 0.0186579, accuracy: 1.0\n",
      "Training loss: 0.0208179, accuracy: 0.984375\n",
      "Training loss: 0.161776, accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0325629, accuracy: 0.984375\n",
      "Training loss: 0.00703875, accuracy: 1.0\n",
      "Training loss: 0.00468951, accuracy: 1.0\n",
      "Training loss: 0.0114325, accuracy: 1.0\n",
      "Training loss: 0.0307266, accuracy: 0.984375\n",
      "Training loss: 0.123169, accuracy: 0.953125\n",
      "Training loss: 0.00942139, accuracy: 1.0\n",
      "Training loss: 0.00493224, accuracy: 1.0\n",
      "Training loss: 0.0754893, accuracy: 0.984375\n",
      "Training loss: 0.0142843, accuracy: 1.0\n",
      "Training loss: 0.120907, accuracy: 0.96875\n",
      "Training loss: 0.00885126, accuracy: 1.0\n",
      "Training loss: 0.0646895, accuracy: 0.984375\n",
      "Training loss: 0.00927762, accuracy: 1.0\n",
      "Training loss: 0.103588, accuracy: 0.984375\n",
      "Training loss: 0.00738846, accuracy: 1.0\n",
      "Training loss: 0.00479009, accuracy: 1.0\n",
      "Training loss: 0.124303, accuracy: 0.96875\n",
      "Training loss: 0.112396, accuracy: 0.984375\n",
      "Training loss: 0.0108885, accuracy: 1.0\n",
      "Training loss: 0.0193091, accuracy: 0.984375\n",
      "Training loss: 0.127467, accuracy: 0.96875\n",
      "Training loss: 0.175572, accuracy: 0.96875\n",
      "Training loss: 0.0115097, accuracy: 1.0\n",
      "Training loss: 0.0104168, accuracy: 1.0\n",
      "Training loss: 0.199823, accuracy: 0.96875\n",
      "Training loss: 0.00892644, accuracy: 1.0\n",
      "Training loss: 0.0140584, accuracy: 1.0\n",
      "Training loss: 0.0088085, accuracy: 1.0\n",
      "Training loss: 0.0217757, accuracy: 0.984375\n",
      "Training loss: 0.00701083, accuracy: 1.0\n",
      "Training loss: 0.00627456, accuracy: 1.0\n",
      "Training loss: 0.0514188, accuracy: 0.96875\n",
      "Training loss: 0.0707324, accuracy: 0.984375\n",
      "Training loss: 0.0109582, accuracy: 1.0\n",
      "Training loss: 0.0162164, accuracy: 1.0\n",
      "Training loss: 0.0401489, accuracy: 0.984375\n",
      "Training loss: 0.0127324, accuracy: 1.0\n",
      "Training loss: 0.0436231, accuracy: 0.96875\n",
      "Training loss: 0.144035, accuracy: 0.96875\n",
      "Training loss: 0.0357123, accuracy: 0.984375\n",
      "Training loss: 0.0149673, accuracy: 1.0\n",
      "Training loss: 0.149062, accuracy: 0.96875\n",
      "Training loss: 0.134766, accuracy: 0.96875\n",
      "Training loss: 0.0134824, accuracy: 1.0\n",
      "Training loss: 0.0259504, accuracy: 0.984375\n",
      "Training loss: 0.0808553, accuracy: 0.984375\n",
      "Training loss: 0.00812212, accuracy: 1.0\n",
      "Training loss: 0.0859979, accuracy: 0.96875\n",
      "Training loss: 0.019154, accuracy: 1.0\n",
      "Training loss: 0.0330873, accuracy: 0.984375\n",
      "Training loss: 0.186123, accuracy: 0.96875\n",
      "Training loss: 0.0814011, accuracy: 0.96875\n",
      "Training loss: 0.024669, accuracy: 1.0\n",
      "Training loss: 0.0890139, accuracy: 0.984375\n",
      "Training loss: 0.0629801, accuracy: 0.984375\n",
      "Training loss: 0.0244976, accuracy: 1.0\n",
      "Training loss: 0.0218992, accuracy: 0.984375\n",
      "Training loss: 0.034355, accuracy: 0.984375\n",
      "Training loss: 0.0343403, accuracy: 0.984375\n",
      "Training loss: 0.0182494, accuracy: 1.0\n",
      "Training loss: 0.00846505, accuracy: 1.0\n",
      "Training loss: 0.00873141, accuracy: 1.0\n",
      "Training loss: 0.0103723, accuracy: 1.0\n",
      "Training loss: 0.0841016, accuracy: 0.984375\n",
      "Training loss: 0.0139044, accuracy: 1.0\n",
      "Training loss: 0.181172, accuracy: 0.953125\n",
      "Training loss: 0.0284576, accuracy: 0.984375\n",
      "Training loss: 0.0131602, accuracy: 1.0\n",
      "Training loss: 0.0453457, accuracy: 0.984375\n",
      "Training loss: 0.118475, accuracy: 0.984375\n",
      "Training loss: 0.103414, accuracy: 0.984375\n",
      "Training loss: 0.0138463, accuracy: 1.0\n",
      "Training loss: 0.0181129, accuracy: 1.0\n",
      "Training loss: 0.145885, accuracy: 0.953125\n",
      "Training loss: 0.0504018, accuracy: 0.984375\n",
      "Training loss: 0.00884733, accuracy: 1.0\n",
      "Training loss: 0.0611662, accuracy: 0.984375\n",
      "Training loss: 0.121702, accuracy: 0.984375\n",
      "Training loss: 0.0287427, accuracy: 1.0\n",
      "Training loss: 0.196024, accuracy: 0.96875\n",
      "Training loss: 0.00535579, accuracy: 1.0\n",
      "Training loss: 0.111172, accuracy: 0.984375\n",
      "Training loss: 0.0988667, accuracy: 0.984375\n",
      "Training loss: 0.143162, accuracy: 0.96875\n",
      "Training loss: 0.205476, accuracy: 0.953125\n",
      "----------------- Step 2700: validation accuracy 0.83456 ----------------\n",
      "Training loss: 0.0936705, accuracy: 0.96875\n",
      "Training loss: 0.139243, accuracy: 0.96875\n",
      "Training loss: 0.0392442, accuracy: 0.984375\n",
      "Training loss: 0.155196, accuracy: 0.953125\n",
      "Training loss: 0.0155004, accuracy: 1.0\n",
      "Training loss: 0.112174, accuracy: 0.96875\n",
      "Training loss: 0.0533727, accuracy: 0.984375\n",
      "Training loss: 0.0342766, accuracy: 0.984375\n",
      "Training loss: 0.021209, accuracy: 1.0\n",
      "Training loss: 0.0391247, accuracy: 1.0\n",
      "Training loss: 0.10483, accuracy: 0.96875\n",
      "Training loss: 0.0867731, accuracy: 0.953125\n",
      "Training loss: 0.0260617, accuracy: 1.0\n",
      "Training loss: 0.0863324, accuracy: 0.984375\n",
      "Training loss: 0.219249, accuracy: 0.953125\n",
      "Training loss: 0.0225864, accuracy: 1.0\n",
      "Training loss: 0.117662, accuracy: 0.96875\n",
      "Training loss: 0.0184912, accuracy: 1.0\n",
      "Training loss: 0.188099, accuracy: 0.9375\n",
      "Training loss: 0.0268754, accuracy: 1.0\n",
      "Training loss: 0.0344774, accuracy: 1.0\n",
      "Training loss: 0.101225, accuracy: 0.984375\n",
      "Training loss: 0.0663898, accuracy: 0.984375\n",
      "Training loss: 0.158234, accuracy: 0.953125\n",
      "Training loss: 0.254163, accuracy: 0.9375\n",
      "Training loss: 0.0195845, accuracy: 1.0\n",
      "Training loss: 0.0734302, accuracy: 0.984375\n",
      "Training loss: 0.0720258, accuracy: 0.96875\n",
      "Training loss: 0.170484, accuracy: 0.9375\n",
      "Training loss: 0.109906, accuracy: 0.953125\n",
      "Training loss: 0.032447, accuracy: 1.0\n",
      "Training loss: 0.0495286, accuracy: 0.984375\n",
      "Training loss: 0.0928139, accuracy: 0.96875\n",
      "Training loss: 0.0532007, accuracy: 0.984375\n",
      "Training loss: 0.0194992, accuracy: 1.0\n",
      "Training loss: 0.0841339, accuracy: 0.96875\n",
      "Training loss: 0.0307385, accuracy: 1.0\n",
      "Training loss: 0.104934, accuracy: 0.953125\n",
      "Training loss: 0.0832865, accuracy: 0.953125\n",
      "Training loss: 0.206795, accuracy: 0.921875\n",
      "Training loss: 0.0602999, accuracy: 0.984375\n",
      "Training loss: 0.0245759, accuracy: 1.0\n",
      "Training loss: 0.0427399, accuracy: 0.96875\n",
      "Training loss: 0.0286366, accuracy: 1.0\n",
      "Training loss: 0.0590855, accuracy: 0.984375\n",
      "Training loss: 0.168146, accuracy: 0.953125\n",
      "Training loss: 0.044867, accuracy: 0.984375\n",
      "Training loss: 0.0184501, accuracy: 1.0\n",
      "Training loss: 0.0243249, accuracy: 1.0\n",
      "Training loss: 0.106651, accuracy: 0.96875\n",
      "Training loss: 0.0442105, accuracy: 0.984375\n",
      "Training loss: 0.0460369, accuracy: 0.96875\n",
      "Training loss: 0.0657996, accuracy: 0.953125\n",
      "Training loss: 0.0258209, accuracy: 1.0\n",
      "Training loss: 0.0175308, accuracy: 1.0\n",
      "Training loss: 0.0146336, accuracy: 1.0\n",
      "Training loss: 0.0165747, accuracy: 1.0\n",
      "Training loss: 0.016102, accuracy: 1.0\n",
      "Training loss: 0.100372, accuracy: 0.984375\n",
      "Training loss: 0.0202408, accuracy: 1.0\n",
      "Training loss: 0.0678906, accuracy: 0.984375\n",
      "Training loss: 0.034081, accuracy: 0.984375\n",
      "Training loss: 0.00822437, accuracy: 1.0\n",
      "Training loss: 0.117802, accuracy: 0.96875\n",
      "Training loss: 0.00524913, accuracy: 1.0\n",
      "Training loss: 0.0512, accuracy: 0.984375\n",
      "Training loss: 0.00427102, accuracy: 1.0\n",
      "Training loss: 0.00567585, accuracy: 1.0\n",
      "Training loss: 0.0215093, accuracy: 1.0\n",
      "Training loss: 0.00317331, accuracy: 1.0\n",
      "Training loss: 0.00267688, accuracy: 1.0\n",
      "Training loss: 0.12386, accuracy: 0.984375\n",
      "Training loss: 0.046763, accuracy: 0.984375\n",
      "Training loss: 0.00258178, accuracy: 1.0\n",
      "Training loss: 0.0102948, accuracy: 1.0\n",
      "Training loss: 0.0126237, accuracy: 1.0\n",
      "Training loss: 0.0766167, accuracy: 0.96875\n",
      "Training loss: 0.00650794, accuracy: 1.0\n",
      "Training loss: 0.0033249, accuracy: 1.0\n",
      "Training loss: 0.00362263, accuracy: 1.0\n",
      "Training loss: 0.0102284, accuracy: 1.0\n",
      "Training loss: 0.0136623, accuracy: 1.0\n",
      "Training loss: 0.00355672, accuracy: 1.0\n",
      "Training loss: 0.0189073, accuracy: 1.0\n",
      "Training loss: 0.0102092, accuracy: 1.0\n",
      "Training loss: 0.00396698, accuracy: 1.0\n",
      "Training loss: 0.00434628, accuracy: 1.0\n",
      "Training loss: 0.010594, accuracy: 1.0\n",
      "Training loss: 0.0403621, accuracy: 0.96875\n",
      "Training loss: 0.00726493, accuracy: 1.0\n",
      "Training loss: 0.0104406, accuracy: 1.0\n",
      "Training loss: 0.00593825, accuracy: 1.0\n",
      "Training loss: 0.034965, accuracy: 0.984375\n",
      "Training loss: 0.00560305, accuracy: 1.0\n",
      "Training loss: 0.187411, accuracy: 0.96875\n",
      "Training loss: 0.00797343, accuracy: 1.0\n",
      "Training loss: 0.012124, accuracy: 1.0\n",
      "Training loss: 0.0173004, accuracy: 0.984375\n",
      "Training loss: 0.00170598, accuracy: 1.0\n",
      "Training loss: 0.113288, accuracy: 0.953125\n",
      "----------------- Step 2800: validation accuracy 0.80208 ----------------\n",
      "Training loss: 0.059299, accuracy: 0.984375\n",
      "Training loss: 0.0296839, accuracy: 0.984375\n",
      "Training loss: 0.00568474, accuracy: 1.0\n",
      "Training loss: 0.0133097, accuracy: 1.0\n",
      "Training loss: 0.0120164, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.144562, accuracy: 0.96875\n",
      "Training loss: 0.00232765, accuracy: 1.0\n",
      "Training loss: 0.0105619, accuracy: 1.0\n",
      "Training loss: 0.00494102, accuracy: 1.0\n",
      "Training loss: 0.0612438, accuracy: 0.96875\n",
      "Training loss: 0.205858, accuracy: 0.953125\n",
      "Training loss: 0.0753361, accuracy: 0.984375\n",
      "Training loss: 0.0493096, accuracy: 0.984375\n",
      "Training loss: 0.089149, accuracy: 0.984375\n",
      "Training loss: 0.0439961, accuracy: 0.984375\n",
      "Training loss: 0.191104, accuracy: 0.9375\n",
      "Training loss: 0.0527923, accuracy: 0.984375\n",
      "Training loss: 0.159295, accuracy: 0.953125\n",
      "Training loss: 0.0654832, accuracy: 0.984375\n",
      "Training loss: 0.0359975, accuracy: 0.984375\n",
      "Training loss: 0.0630717, accuracy: 0.984375\n",
      "Training loss: 0.0107649, accuracy: 1.0\n",
      "Training loss: 0.0902274, accuracy: 0.96875\n",
      "Training loss: 0.0114415, accuracy: 1.0\n",
      "Training loss: 0.0323628, accuracy: 0.984375\n",
      "Training loss: 0.0228841, accuracy: 1.0\n",
      "Training loss: 0.12039, accuracy: 0.96875\n",
      "Training loss: 0.0697678, accuracy: 0.984375\n",
      "Training loss: 0.0253386, accuracy: 0.984375\n",
      "Training loss: 0.0153493, accuracy: 1.0\n",
      "Training loss: 0.127209, accuracy: 0.953125\n",
      "Training loss: 0.013933, accuracy: 1.0\n",
      "Training loss: 0.00449817, accuracy: 1.0\n",
      "Training loss: 0.0774912, accuracy: 0.984375\n",
      "Training loss: 0.00956904, accuracy: 1.0\n",
      "Training loss: 0.0991765, accuracy: 0.96875\n",
      "Training loss: 0.0193772, accuracy: 0.984375\n",
      "Training loss: 0.0137343, accuracy: 1.0\n",
      "Training loss: 0.0588079, accuracy: 0.984375\n",
      "Training loss: 0.0540418, accuracy: 0.984375\n",
      "Training loss: 0.0330617, accuracy: 0.984375\n",
      "Training loss: 0.224958, accuracy: 0.953125\n",
      "Training loss: 0.0468786, accuracy: 0.984375\n",
      "Training loss: 0.0998906, accuracy: 0.96875\n",
      "Training loss: 0.0169798, accuracy: 1.0\n",
      "Training loss: 0.00565011, accuracy: 1.0\n",
      "Training loss: 0.0542498, accuracy: 0.984375\n",
      "Training loss: 0.13174, accuracy: 0.96875\n",
      "Training loss: 0.0478878, accuracy: 0.984375\n",
      "Training loss: 0.266578, accuracy: 0.9375\n",
      "Training loss: 0.082358, accuracy: 0.984375\n",
      "Training loss: 0.0149913, accuracy: 1.0\n",
      "Training loss: 0.0215637, accuracy: 1.0\n",
      "Training loss: 0.056764, accuracy: 0.984375\n",
      "Training loss: 0.0693316, accuracy: 0.984375\n",
      "Training loss: 0.193509, accuracy: 0.96875\n",
      "Training loss: 0.206685, accuracy: 0.9375\n",
      "Training loss: 0.0266067, accuracy: 1.0\n",
      "Training loss: 0.0515133, accuracy: 0.984375\n",
      "Training loss: 0.0777419, accuracy: 0.96875\n",
      "Training loss: 0.0715475, accuracy: 0.984375\n",
      "Training loss: 0.0812366, accuracy: 0.96875\n",
      "Training loss: 0.0831975, accuracy: 0.984375\n",
      "Training loss: 0.0709367, accuracy: 0.96875\n",
      "Training loss: 0.0409222, accuracy: 0.984375\n",
      "Training loss: 0.0937679, accuracy: 0.96875\n",
      "Training loss: 0.0316567, accuracy: 1.0\n",
      "Training loss: 0.0215363, accuracy: 1.0\n",
      "Training loss: 0.0618296, accuracy: 0.984375\n",
      "Training loss: 0.0187627, accuracy: 1.0\n",
      "Training loss: 0.0674759, accuracy: 0.984375\n",
      "Training loss: 0.0343184, accuracy: 0.984375\n",
      "Training loss: 0.0319593, accuracy: 0.984375\n",
      "Training loss: 0.0141179, accuracy: 1.0\n",
      "Training loss: 0.0708048, accuracy: 0.984375\n",
      "Training loss: 0.0320773, accuracy: 0.984375\n",
      "Training loss: 0.0100004, accuracy: 1.0\n",
      "Training loss: 0.0135867, accuracy: 1.0\n",
      "Training loss: 0.0129129, accuracy: 1.0\n",
      "Training loss: 0.154288, accuracy: 0.953125\n",
      "Training loss: 0.0500144, accuracy: 0.984375\n",
      "Training loss: 0.0185349, accuracy: 1.0\n",
      "Training loss: 0.0782345, accuracy: 0.984375\n",
      "Training loss: 0.021435, accuracy: 0.984375\n",
      "Training loss: 0.0112232, accuracy: 1.0\n",
      "Training loss: 0.183863, accuracy: 0.953125\n",
      "Training loss: 0.0213377, accuracy: 0.984375\n",
      "Training loss: 0.0334142, accuracy: 0.984375\n",
      "Training loss: 0.150661, accuracy: 0.96875\n",
      "Training loss: 0.0148354, accuracy: 1.0\n",
      "Training loss: 0.0199794, accuracy: 1.0\n",
      "Training loss: 0.0946556, accuracy: 0.984375\n",
      "Training loss: 0.10532, accuracy: 0.984375\n",
      "Training loss: 0.00376698, accuracy: 1.0\n",
      "Training loss: 0.00522595, accuracy: 1.0\n",
      "Training loss: 0.0368585, accuracy: 0.984375\n",
      "Training loss: 0.0101049, accuracy: 1.0\n",
      "Training loss: 0.00680271, accuracy: 1.0\n",
      "Training loss: 0.0838658, accuracy: 0.984375\n",
      "Training loss: 0.00401413, accuracy: 1.0\n",
      "----------------- Step 2900: validation accuracy 0.83072 ----------------\n",
      "Training loss: 0.00816851, accuracy: 1.0\n",
      "Training loss: 0.0432533, accuracy: 0.984375\n",
      "Training loss: 0.0440213, accuracy: 0.984375\n",
      "Training loss: 0.0311322, accuracy: 1.0\n",
      "Training loss: 0.0325823, accuracy: 0.984375\n",
      "Training loss: 0.0145006, accuracy: 1.0\n",
      "Training loss: 0.137299, accuracy: 0.96875\n",
      "Training loss: 0.0586699, accuracy: 0.96875\n",
      "Training loss: 0.0330545, accuracy: 0.984375\n",
      "Training loss: 0.0222981, accuracy: 0.984375\n",
      "Training loss: 0.00727524, accuracy: 1.0\n",
      "Training loss: 0.00702655, accuracy: 1.0\n",
      "Training loss: 0.0532838, accuracy: 0.96875\n",
      "Training loss: 0.00969891, accuracy: 1.0\n",
      "Training loss: 0.10927, accuracy: 0.96875\n",
      "Training loss: 0.0210424, accuracy: 1.0\n",
      "Training loss: 0.0217085, accuracy: 1.0\n",
      "Training loss: 0.0716159, accuracy: 0.984375\n",
      "Training loss: 0.0117726, accuracy: 1.0\n",
      "Training loss: 0.00460046, accuracy: 1.0\n",
      "Training loss: 0.0919851, accuracy: 0.96875\n",
      "Training loss: 0.0262711, accuracy: 1.0\n",
      "Training loss: 0.0142743, accuracy: 1.0\n",
      "Training loss: 0.0308044, accuracy: 0.984375\n",
      "Training loss: 0.0231832, accuracy: 0.984375\n",
      "Training loss: 0.0147308, accuracy: 1.0\n",
      "Training loss: 0.0606491, accuracy: 0.984375\n",
      "Training loss: 0.0218256, accuracy: 0.984375\n",
      "Training loss: 0.160403, accuracy: 0.96875\n",
      "Training loss: 0.116751, accuracy: 0.984375\n",
      "Training loss: 0.00807024, accuracy: 1.0\n",
      "Training loss: 0.00493762, accuracy: 1.0\n",
      "Training loss: 0.217297, accuracy: 0.96875\n",
      "Training loss: 0.00639944, accuracy: 1.0\n",
      "Training loss: 0.0215296, accuracy: 1.0\n",
      "Training loss: 0.0494365, accuracy: 0.984375\n",
      "Training loss: 0.00699149, accuracy: 1.0\n",
      "Training loss: 0.00582186, accuracy: 1.0\n",
      "Training loss: 0.0129658, accuracy: 1.0\n",
      "Training loss: 0.0236661, accuracy: 0.984375\n",
      "Training loss: 0.0625516, accuracy: 0.96875\n",
      "Training loss: 0.0114211, accuracy: 1.0\n",
      "Training loss: 0.109204, accuracy: 0.984375\n",
      "Training loss: 0.015192, accuracy: 1.0\n",
      "Training loss: 0.00599006, accuracy: 1.0\n",
      "Training loss: 0.023858, accuracy: 1.0\n",
      "Training loss: 0.0467604, accuracy: 0.984375\n",
      "Training loss: 0.00629268, accuracy: 1.0\n",
      "Training loss: 0.0400133, accuracy: 0.984375\n",
      "Training loss: 0.0109704, accuracy: 1.0\n",
      "Training loss: 0.0439809, accuracy: 0.984375\n",
      "Training loss: 0.0179291, accuracy: 0.984375\n",
      "Training loss: 0.0105055, accuracy: 1.0\n",
      "Training loss: 0.0802365, accuracy: 0.984375\n",
      "Training loss: 0.0225723, accuracy: 0.984375\n",
      "Training loss: 0.00797242, accuracy: 1.0\n",
      "Training loss: 0.0332204, accuracy: 0.984375\n",
      "Training loss: 0.00548971, accuracy: 1.0\n",
      "Training loss: 0.0976176, accuracy: 0.984375\n",
      "Training loss: 0.0549996, accuracy: 0.96875\n",
      "Training loss: 0.027818, accuracy: 0.984375\n",
      "Training loss: 0.0821692, accuracy: 0.984375\n",
      "Training loss: 0.0238382, accuracy: 1.0\n",
      "Training loss: 0.0235956, accuracy: 1.0\n",
      "Training loss: 0.00773556, accuracy: 1.0\n",
      "Training loss: 0.0753132, accuracy: 0.96875\n",
      "Training loss: 0.00548315, accuracy: 1.0\n",
      "Training loss: 0.0138949, accuracy: 1.0\n",
      "Training loss: 0.0538183, accuracy: 0.96875\n",
      "Training loss: 0.00972392, accuracy: 1.0\n",
      "Training loss: 0.0291977, accuracy: 0.984375\n",
      "Training loss: 0.0338645, accuracy: 1.0\n",
      "Training loss: 0.0154118, accuracy: 1.0\n",
      "Training loss: 0.229511, accuracy: 0.96875\n",
      "Training loss: 0.0469769, accuracy: 0.984375\n",
      "Training loss: 0.0146067, accuracy: 1.0\n",
      "Training loss: 0.00702838, accuracy: 1.0\n",
      "Training loss: 0.0629839, accuracy: 0.984375\n",
      "Training loss: 0.0874197, accuracy: 0.984375\n",
      "Training loss: 0.024304, accuracy: 0.984375\n",
      "Training loss: 0.0106857, accuracy: 1.0\n",
      "Training loss: 0.126451, accuracy: 0.96875\n",
      "Training loss: 0.0050169, accuracy: 1.0\n",
      "Training loss: 0.00957887, accuracy: 1.0\n",
      "Training loss: 0.0271995, accuracy: 0.984375\n",
      "Training loss: 0.152004, accuracy: 0.96875\n",
      "Training loss: 0.0320978, accuracy: 0.984375\n",
      "Training loss: 0.158028, accuracy: 0.96875\n",
      "Training loss: 0.00856058, accuracy: 1.0\n",
      "Training loss: 0.151973, accuracy: 0.953125\n",
      "Training loss: 0.14437, accuracy: 0.96875\n",
      "Training loss: 0.034719, accuracy: 0.984375\n",
      "Training loss: 0.115971, accuracy: 0.96875\n",
      "Training loss: 0.0848555, accuracy: 0.984375\n",
      "Training loss: 0.00753677, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0415136, accuracy: 0.984375\n",
      "Training loss: 0.124718, accuracy: 0.9375\n",
      "Training loss: 0.00771718, accuracy: 1.0\n",
      "Training loss: 0.105167, accuracy: 0.984375\n",
      "Training loss: 0.038545, accuracy: 0.984375\n",
      "----------------- Step 3000: validation accuracy 0.828 ----------------\n",
      "Training loss: 0.0361813, accuracy: 0.984375\n",
      "Training loss: 0.0336925, accuracy: 0.984375\n",
      "Training loss: 0.0757634, accuracy: 0.984375\n",
      "Training loss: 0.0643787, accuracy: 0.984375\n",
      "Training loss: 0.103072, accuracy: 0.984375\n",
      "Training loss: 0.0101914, accuracy: 1.0\n",
      "Training loss: 0.163814, accuracy: 0.953125\n",
      "Training loss: 0.0445277, accuracy: 0.984375\n",
      "Training loss: 0.122119, accuracy: 0.96875\n",
      "Training loss: 0.174295, accuracy: 0.953125\n",
      "Training loss: 0.0133802, accuracy: 1.0\n",
      "Training loss: 0.15715, accuracy: 0.984375\n",
      "Training loss: 0.157614, accuracy: 0.96875\n",
      "Training loss: 0.0994804, accuracy: 0.984375\n",
      "Training loss: 0.0145148, accuracy: 1.0\n",
      "Training loss: 0.0122136, accuracy: 1.0\n",
      "Training loss: 0.0269954, accuracy: 1.0\n",
      "Training loss: 0.155073, accuracy: 0.96875\n",
      "Training loss: 0.0325469, accuracy: 0.984375\n",
      "Training loss: 0.0126699, accuracy: 1.0\n",
      "Training loss: 0.0604133, accuracy: 0.984375\n",
      "Training loss: 0.0536579, accuracy: 0.984375\n",
      "Training loss: 0.134013, accuracy: 0.9375\n",
      "Training loss: 0.0275207, accuracy: 1.0\n",
      "Training loss: 0.0569153, accuracy: 0.96875\n",
      "Training loss: 0.0413409, accuracy: 0.984375\n",
      "Training loss: 0.0359441, accuracy: 0.984375\n",
      "Training loss: 0.0885435, accuracy: 0.96875\n",
      "Training loss: 0.014041, accuracy: 1.0\n",
      "Training loss: 0.0310867, accuracy: 0.984375\n",
      "Training loss: 0.0258375, accuracy: 1.0\n",
      "Training loss: 0.0269445, accuracy: 1.0\n",
      "Training loss: 0.200418, accuracy: 0.96875\n",
      "Training loss: 0.00869132, accuracy: 1.0\n",
      "Training loss: 0.0147638, accuracy: 1.0\n",
      "Training loss: 0.113768, accuracy: 0.953125\n",
      "Training loss: 0.0111608, accuracy: 1.0\n",
      "Training loss: 0.0156636, accuracy: 1.0\n",
      "Training loss: 0.227636, accuracy: 0.953125\n",
      "Training loss: 0.10647, accuracy: 0.953125\n",
      "Training loss: 0.0691138, accuracy: 0.984375\n",
      "Training loss: 0.0162326, accuracy: 1.0\n",
      "Training loss: 0.0322628, accuracy: 0.984375\n",
      "Training loss: 0.187417, accuracy: 0.953125\n",
      "Training loss: 0.0125995, accuracy: 1.0\n",
      "Training loss: 0.134496, accuracy: 0.953125\n",
      "Training loss: 0.143634, accuracy: 0.984375\n",
      "Training loss: 0.0414706, accuracy: 0.96875\n",
      "Training loss: 0.0103931, accuracy: 1.0\n",
      "Training loss: 0.163411, accuracy: 0.96875\n",
      "Training loss: 0.128656, accuracy: 0.953125\n",
      "Training loss: 0.117068, accuracy: 0.96875\n",
      "Training loss: 0.0170627, accuracy: 1.0\n",
      "Training loss: 0.0103881, accuracy: 1.0\n",
      "Training loss: 0.0372325, accuracy: 0.984375\n",
      "Training loss: 0.0130954, accuracy: 1.0\n",
      "Training loss: 0.0997751, accuracy: 0.96875\n",
      "Training loss: 0.0100089, accuracy: 1.0\n",
      "Training loss: 0.047588, accuracy: 0.984375\n",
      "Training loss: 0.0127171, accuracy: 1.0\n",
      "Training loss: 0.00930319, accuracy: 1.0\n",
      "Training loss: 0.0292945, accuracy: 0.984375\n",
      "Training loss: 0.0147067, accuracy: 1.0\n",
      "Training loss: 0.00741276, accuracy: 1.0\n",
      "Training loss: 0.0938932, accuracy: 0.984375\n",
      "Training loss: 0.0665273, accuracy: 0.96875\n",
      "Training loss: 0.0663246, accuracy: 0.984375\n",
      "Training loss: 0.0126532, accuracy: 1.0\n",
      "Training loss: 0.0246617, accuracy: 0.984375\n",
      "Training loss: 0.0155007, accuracy: 1.0\n",
      "Training loss: 0.0642584, accuracy: 0.984375\n",
      "Training loss: 0.00938595, accuracy: 1.0\n",
      "Training loss: 0.0153887, accuracy: 1.0\n",
      "Training loss: 0.0110975, accuracy: 1.0\n",
      "Training loss: 0.0449026, accuracy: 0.984375\n",
      "Training loss: 0.0200367, accuracy: 0.984375\n",
      "Training loss: 0.0690215, accuracy: 0.984375\n",
      "Training loss: 0.0596963, accuracy: 0.984375\n",
      "Training loss: 0.0196524, accuracy: 0.984375\n",
      "Training loss: 0.0223103, accuracy: 0.984375\n",
      "Training loss: 0.050031, accuracy: 0.984375\n",
      "Training loss: 0.0202364, accuracy: 0.984375\n",
      "Training loss: 0.0111255, accuracy: 1.0\n",
      "Training loss: 0.0191651, accuracy: 1.0\n",
      "Training loss: 0.0189904, accuracy: 0.984375\n",
      "Training loss: 0.00947615, accuracy: 1.0\n",
      "Training loss: 0.0457269, accuracy: 0.984375\n",
      "Training loss: 0.116879, accuracy: 0.984375\n",
      "Training loss: 0.00694486, accuracy: 1.0\n",
      "Training loss: 0.0110208, accuracy: 1.0\n",
      "Training loss: 0.0120361, accuracy: 1.0\n",
      "Training loss: 0.00657057, accuracy: 1.0\n",
      "Training loss: 0.0523982, accuracy: 0.984375\n",
      "Training loss: 0.032939, accuracy: 0.984375\n",
      "Training loss: 0.0171001, accuracy: 1.0\n",
      "Training loss: 0.00290807, accuracy: 1.0\n",
      "Training loss: 0.0584797, accuracy: 0.96875\n",
      "Training loss: 0.0253428, accuracy: 0.984375\n",
      "Training loss: 0.0806698, accuracy: 0.984375\n",
      "Training loss: 0.00603823, accuracy: 1.0\n",
      "----------------- Step 3100: validation accuracy 0.8312 ----------------\n",
      "Training loss: 0.005595, accuracy: 1.0\n",
      "Training loss: 0.162564, accuracy: 0.953125\n",
      "Training loss: 0.0802594, accuracy: 0.984375\n",
      "Training loss: 0.0629881, accuracy: 0.984375\n",
      "Training loss: 0.00726317, accuracy: 1.0\n",
      "Training loss: 0.0494099, accuracy: 0.96875\n",
      "Training loss: 0.0194553, accuracy: 1.0\n",
      "Training loss: 0.0110729, accuracy: 1.0\n",
      "Training loss: 0.0775983, accuracy: 0.984375\n",
      "Training loss: 0.0133271, accuracy: 1.0\n",
      "Training loss: 0.00413238, accuracy: 1.0\n",
      "Training loss: 0.00475851, accuracy: 1.0\n",
      "Training loss: 0.0706863, accuracy: 0.984375\n",
      "Training loss: 0.00638029, accuracy: 1.0\n",
      "Training loss: 0.0114195, accuracy: 1.0\n",
      "Training loss: 0.00579835, accuracy: 1.0\n",
      "Training loss: 0.034121, accuracy: 0.984375\n",
      "Training loss: 0.0391678, accuracy: 0.984375\n",
      "Training loss: 0.00281952, accuracy: 1.0\n",
      "Training loss: 0.019338, accuracy: 0.984375\n",
      "Training loss: 0.0736485, accuracy: 0.96875\n",
      "Training loss: 0.018243, accuracy: 1.0\n",
      "Training loss: 0.0297379, accuracy: 0.984375\n",
      "Training loss: 0.0769096, accuracy: 0.96875\n",
      "Training loss: 0.0908338, accuracy: 0.96875\n",
      "Training loss: 0.00426277, accuracy: 1.0\n",
      "Training loss: 0.0137008, accuracy: 1.0\n",
      "Training loss: 0.00394552, accuracy: 1.0\n",
      "Training loss: 0.129529, accuracy: 0.953125\n",
      "Training loss: 0.0262182, accuracy: 0.984375\n",
      "Training loss: 0.0154901, accuracy: 1.0\n",
      "Training loss: 0.0693348, accuracy: 0.984375\n",
      "Training loss: 0.103621, accuracy: 0.96875\n",
      "Training loss: 0.0216274, accuracy: 1.0\n",
      "Training loss: 0.0671979, accuracy: 0.984375\n",
      "Training loss: 0.0128323, accuracy: 1.0\n",
      "Training loss: 0.0275124, accuracy: 0.984375\n",
      "Training loss: 0.0764811, accuracy: 0.984375\n",
      "Training loss: 0.00561516, accuracy: 1.0\n",
      "Training loss: 0.00411967, accuracy: 1.0\n",
      "Training loss: 0.165054, accuracy: 0.96875\n",
      "Training loss: 0.165918, accuracy: 0.953125\n",
      "Training loss: 0.266744, accuracy: 0.953125\n",
      "Training loss: 0.0961482, accuracy: 0.984375\n",
      "Training loss: 0.0394073, accuracy: 0.984375\n",
      "Training loss: 0.0134127, accuracy: 1.0\n",
      "Training loss: 0.0783339, accuracy: 0.984375\n",
      "Training loss: 0.0810183, accuracy: 0.984375\n",
      "Training loss: 0.137348, accuracy: 0.96875\n",
      "Training loss: 0.218792, accuracy: 0.953125\n",
      "Training loss: 0.0836526, accuracy: 0.96875\n",
      "Training loss: 0.0133815, accuracy: 1.0\n",
      "Training loss: 0.0459038, accuracy: 0.984375\n",
      "Training loss: 0.020656, accuracy: 1.0\n",
      "Training loss: 0.0273412, accuracy: 1.0\n",
      "Training loss: 0.0182087, accuracy: 1.0\n",
      "Training loss: 0.0187474, accuracy: 1.0\n",
      "Training loss: 0.0163306, accuracy: 1.0\n",
      "Training loss: 0.0921198, accuracy: 0.984375\n",
      "Training loss: 0.0219869, accuracy: 1.0\n",
      "Training loss: 0.0261743, accuracy: 1.0\n",
      "Training loss: 0.0863983, accuracy: 0.984375\n",
      "Training loss: 0.133302, accuracy: 0.984375\n",
      "Training loss: 0.127843, accuracy: 0.96875\n",
      "Training loss: 0.0567878, accuracy: 0.984375\n",
      "Training loss: 0.0375559, accuracy: 0.984375\n",
      "Training loss: 0.0169018, accuracy: 1.0\n",
      "Training loss: 0.0142175, accuracy: 1.0\n",
      "Training loss: 0.160785, accuracy: 0.953125\n",
      "Training loss: 0.0165067, accuracy: 1.0\n",
      "Training loss: 0.0112217, accuracy: 1.0\n",
      "Training loss: 0.0125636, accuracy: 1.0\n",
      "Training loss: 0.101392, accuracy: 0.984375\n",
      "Training loss: 0.0305806, accuracy: 0.984375\n",
      "Training loss: 0.0172341, accuracy: 1.0\n",
      "Training loss: 0.0116078, accuracy: 1.0\n",
      "Training loss: 0.00809737, accuracy: 1.0\n",
      "Training loss: 0.0141051, accuracy: 1.0\n",
      "Training loss: 0.217986, accuracy: 0.9375\n",
      "Training loss: 0.0103853, accuracy: 1.0\n",
      "Training loss: 0.0162815, accuracy: 1.0\n",
      "Training loss: 0.125274, accuracy: 0.984375\n",
      "Training loss: 0.0133527, accuracy: 1.0\n",
      "Training loss: 0.0143108, accuracy: 1.0\n",
      "Training loss: 0.0237098, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0135703, accuracy: 1.0\n",
      "Training loss: 0.0345062, accuracy: 0.984375\n",
      "Training loss: 0.0105709, accuracy: 1.0\n",
      "Training loss: 0.0566323, accuracy: 0.984375\n",
      "Training loss: 0.0222071, accuracy: 0.984375\n",
      "Training loss: 0.0102773, accuracy: 1.0\n",
      "Training loss: 0.00662083, accuracy: 1.0\n",
      "Training loss: 0.0470131, accuracy: 0.984375\n",
      "Training loss: 0.00981373, accuracy: 1.0\n",
      "Training loss: 0.00521857, accuracy: 1.0\n",
      "Training loss: 0.00503161, accuracy: 1.0\n",
      "Training loss: 0.00814203, accuracy: 1.0\n",
      "Training loss: 0.00332261, accuracy: 1.0\n",
      "Training loss: 0.00631409, accuracy: 1.0\n",
      "Training loss: 0.13343, accuracy: 0.96875\n",
      "----------------- Step 3200: validation accuracy 0.79232 ----------------\n",
      "Training loss: 0.0434676, accuracy: 0.984375\n",
      "Training loss: 0.0142983, accuracy: 1.0\n",
      "Training loss: 0.003297, accuracy: 1.0\n",
      "Training loss: 0.0139218, accuracy: 1.0\n",
      "Training loss: 0.00448707, accuracy: 1.0\n",
      "Training loss: 0.0807263, accuracy: 0.984375\n",
      "Training loss: 0.0672435, accuracy: 0.984375\n",
      "Training loss: 0.0378114, accuracy: 0.984375\n",
      "Training loss: 0.00692878, accuracy: 1.0\n",
      "Training loss: 0.00772607, accuracy: 1.0\n",
      "Training loss: 0.00983757, accuracy: 1.0\n",
      "Training loss: 0.0144635, accuracy: 1.0\n",
      "Training loss: 0.0210642, accuracy: 0.984375\n",
      "Training loss: 0.0458935, accuracy: 0.984375\n",
      "Training loss: 0.0317726, accuracy: 0.984375\n",
      "Training loss: 0.0145577, accuracy: 1.0\n",
      "Training loss: 0.0618926, accuracy: 0.984375\n",
      "Training loss: 0.00301454, accuracy: 1.0\n",
      "Training loss: 0.046135, accuracy: 0.984375\n",
      "Training loss: 0.00772176, accuracy: 1.0\n",
      "Training loss: 0.099419, accuracy: 0.984375\n",
      "Training loss: 0.154118, accuracy: 0.96875\n",
      "Training loss: 0.122531, accuracy: 0.984375\n",
      "Training loss: 0.10274, accuracy: 0.953125\n",
      "Training loss: 0.0305349, accuracy: 0.984375\n",
      "Training loss: 0.248045, accuracy: 0.96875\n",
      "Training loss: 0.0246777, accuracy: 0.984375\n",
      "Training loss: 0.00838276, accuracy: 1.0\n",
      "Training loss: 0.0519861, accuracy: 0.984375\n",
      "Training loss: 0.0076678, accuracy: 1.0\n",
      "Training loss: 0.013191, accuracy: 1.0\n",
      "Training loss: 0.0170672, accuracy: 0.984375\n",
      "Training loss: 0.00896414, accuracy: 1.0\n",
      "Training loss: 0.0396322, accuracy: 0.984375\n",
      "Training loss: 0.0773758, accuracy: 0.984375\n",
      "Training loss: 0.00740448, accuracy: 1.0\n",
      "Training loss: 0.0101227, accuracy: 1.0\n",
      "Training loss: 0.00379268, accuracy: 1.0\n",
      "Training loss: 0.0199877, accuracy: 1.0\n",
      "Training loss: 0.0429495, accuracy: 0.984375\n",
      "Training loss: 0.010472, accuracy: 1.0\n",
      "Training loss: 0.014454, accuracy: 1.0\n",
      "Training loss: 0.0118839, accuracy: 1.0\n",
      "Training loss: 0.0412781, accuracy: 0.984375\n",
      "Training loss: 0.0309629, accuracy: 0.984375\n",
      "Training loss: 0.00941744, accuracy: 1.0\n",
      "Training loss: 0.165754, accuracy: 0.9375\n",
      "Training loss: 0.175444, accuracy: 0.953125\n",
      "Training loss: 0.0516459, accuracy: 0.984375\n",
      "Training loss: 0.0116899, accuracy: 1.0\n",
      "Training loss: 0.0130687, accuracy: 1.0\n",
      "Training loss: 0.113446, accuracy: 0.984375\n",
      "Training loss: 0.0787386, accuracy: 0.96875\n",
      "Training loss: 0.0257913, accuracy: 0.984375\n",
      "Training loss: 0.091673, accuracy: 0.96875\n",
      "Training loss: 0.0617005, accuracy: 0.96875\n",
      "Training loss: 0.00929198, accuracy: 1.0\n",
      "Training loss: 0.0164676, accuracy: 0.984375\n",
      "Training loss: 0.0111317, accuracy: 1.0\n",
      "Training loss: 0.0273803, accuracy: 1.0\n",
      "Training loss: 0.011312, accuracy: 1.0\n",
      "Training loss: 0.0055845, accuracy: 1.0\n",
      "Training loss: 0.00783804, accuracy: 1.0\n",
      "Training loss: 0.0560808, accuracy: 0.984375\n",
      "Training loss: 0.0442056, accuracy: 0.984375\n",
      "Training loss: 0.0328543, accuracy: 0.96875\n",
      "Training loss: 0.145395, accuracy: 0.984375\n",
      "Training loss: 0.0264927, accuracy: 0.984375\n",
      "Training loss: 0.0124837, accuracy: 1.0\n",
      "Training loss: 0.0237678, accuracy: 1.0\n",
      "Training loss: 0.0556741, accuracy: 0.984375\n",
      "Training loss: 0.114496, accuracy: 0.984375\n",
      "Training loss: 0.0311141, accuracy: 0.984375\n",
      "Training loss: 0.109127, accuracy: 0.984375\n",
      "Training loss: 0.11472, accuracy: 0.984375\n",
      "Training loss: 0.0470193, accuracy: 0.984375\n",
      "Training loss: 0.065098, accuracy: 0.984375\n",
      "Training loss: 0.0054871, accuracy: 1.0\n",
      "Training loss: 0.173692, accuracy: 0.96875\n",
      "Training loss: 0.0203614, accuracy: 1.0\n",
      "Training loss: 0.163684, accuracy: 0.921875\n",
      "Training loss: 0.0350126, accuracy: 0.984375\n",
      "Training loss: 0.213551, accuracy: 0.953125\n",
      "Training loss: 0.107221, accuracy: 0.984375\n",
      "Training loss: 0.0874653, accuracy: 0.984375\n",
      "Training loss: 0.1336, accuracy: 0.953125\n",
      "Training loss: 0.0761877, accuracy: 0.984375\n",
      "Training loss: 0.00784466, accuracy: 1.0\n",
      "Training loss: 0.0159599, accuracy: 1.0\n",
      "Training loss: 0.0147631, accuracy: 1.0\n",
      "Training loss: 0.0245333, accuracy: 1.0\n",
      "Training loss: 0.123732, accuracy: 0.96875\n",
      "Training loss: 0.021033, accuracy: 0.984375\n",
      "Training loss: 0.0248568, accuracy: 0.984375\n",
      "Training loss: 0.0898647, accuracy: 0.96875\n",
      "Training loss: 0.0282993, accuracy: 1.0\n",
      "Training loss: 0.128727, accuracy: 0.953125\n",
      "Training loss: 0.049156, accuracy: 0.984375\n",
      "Training loss: 0.100448, accuracy: 0.984375\n",
      "Training loss: 0.102107, accuracy: 0.96875\n",
      "----------------- Step 3300: validation accuracy 0.84144 ----------------\n",
      "Training loss: 0.0366724, accuracy: 0.984375\n",
      "Training loss: 0.124637, accuracy: 0.953125\n",
      "Training loss: 0.0884314, accuracy: 0.984375\n",
      "Training loss: 0.00957897, accuracy: 1.0\n",
      "Training loss: 0.23539, accuracy: 0.9375\n",
      "Training loss: 0.102059, accuracy: 0.984375\n",
      "Training loss: 0.0781636, accuracy: 0.96875\n",
      "Training loss: 0.0135267, accuracy: 1.0\n",
      "Training loss: 0.0136965, accuracy: 1.0\n",
      "Training loss: 0.0405894, accuracy: 0.984375\n",
      "Training loss: 0.15054, accuracy: 0.953125\n",
      "Training loss: 0.015784, accuracy: 1.0\n",
      "Training loss: 0.0642173, accuracy: 0.984375\n",
      "Training loss: 0.0244375, accuracy: 1.0\n",
      "Training loss: 0.0346892, accuracy: 0.984375\n",
      "Training loss: 0.0140147, accuracy: 1.0\n",
      "Training loss: 0.0128481, accuracy: 1.0\n",
      "Training loss: 0.0746856, accuracy: 0.96875\n",
      "Training loss: 0.0862996, accuracy: 0.984375\n",
      "Training loss: 0.0379844, accuracy: 0.984375\n",
      "Training loss: 0.0174027, accuracy: 1.0\n",
      "Training loss: 0.014886, accuracy: 1.0\n",
      "Training loss: 0.0164971, accuracy: 1.0\n",
      "Training loss: 0.00623074, accuracy: 1.0\n",
      "Training loss: 0.063693, accuracy: 0.96875\n",
      "Training loss: 0.135699, accuracy: 0.953125\n",
      "Training loss: 0.0327104, accuracy: 0.984375\n",
      "Training loss: 0.0118309, accuracy: 1.0\n",
      "Training loss: 0.0192464, accuracy: 1.0\n",
      "Training loss: 0.0163569, accuracy: 1.0\n",
      "Training loss: 0.0148075, accuracy: 1.0\n",
      "Training loss: 0.137755, accuracy: 0.96875\n",
      "Training loss: 0.0362983, accuracy: 0.984375\n",
      "Training loss: 0.00687885, accuracy: 1.0\n",
      "Training loss: 0.0238775, accuracy: 1.0\n",
      "Training loss: 0.0194119, accuracy: 1.0\n",
      "Training loss: 0.0814011, accuracy: 0.96875\n",
      "Training loss: 0.0095302, accuracy: 1.0\n",
      "Training loss: 0.0195554, accuracy: 0.984375\n",
      "Training loss: 0.0220223, accuracy: 1.0\n",
      "Training loss: 0.0287528, accuracy: 0.984375\n",
      "Training loss: 0.0136064, accuracy: 1.0\n",
      "Training loss: 0.00452966, accuracy: 1.0\n",
      "Training loss: 0.0246828, accuracy: 1.0\n",
      "Training loss: 0.0862972, accuracy: 0.984375\n",
      "Training loss: 0.0243398, accuracy: 0.984375\n",
      "Training loss: 0.0399765, accuracy: 0.984375\n",
      "Training loss: 0.0206672, accuracy: 0.984375\n",
      "Training loss: 0.112786, accuracy: 0.96875\n",
      "Training loss: 0.118612, accuracy: 0.984375\n",
      "Training loss: 0.0063259, accuracy: 1.0\n",
      "Training loss: 0.0285921, accuracy: 0.984375\n",
      "Training loss: 0.0663592, accuracy: 0.96875\n",
      "Training loss: 0.00937678, accuracy: 1.0\n",
      "Training loss: 0.00988187, accuracy: 1.0\n",
      "Training loss: 0.143148, accuracy: 0.96875\n",
      "Training loss: 0.0346141, accuracy: 0.96875\n",
      "Training loss: 0.12479, accuracy: 0.96875\n",
      "Training loss: 0.0526138, accuracy: 0.984375\n",
      "Training loss: 0.0430073, accuracy: 0.984375\n",
      "Training loss: 0.0461795, accuracy: 0.96875\n",
      "Training loss: 0.0461035, accuracy: 0.984375\n",
      "Training loss: 0.0149873, accuracy: 1.0\n",
      "Training loss: 0.16057, accuracy: 0.9375\n",
      "Training loss: 0.0369207, accuracy: 0.984375\n",
      "Training loss: 0.0122897, accuracy: 1.0\n",
      "Training loss: 0.00808949, accuracy: 1.0\n",
      "Training loss: 0.0888429, accuracy: 0.984375\n",
      "Training loss: 0.0055559, accuracy: 1.0\n",
      "Training loss: 0.1163, accuracy: 0.984375\n",
      "Training loss: 0.0718456, accuracy: 0.953125\n",
      "Training loss: 0.0370474, accuracy: 0.984375\n",
      "Training loss: 0.0152408, accuracy: 1.0\n",
      "Training loss: 0.00471068, accuracy: 1.0\n",
      "Training loss: 0.10564, accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.00490888, accuracy: 1.0\n",
      "Training loss: 0.0829615, accuracy: 0.984375\n",
      "Training loss: 0.015369, accuracy: 1.0\n",
      "Training loss: 0.0134537, accuracy: 1.0\n",
      "Training loss: 0.0148629, accuracy: 0.984375\n",
      "Training loss: 0.0793731, accuracy: 0.984375\n",
      "Training loss: 0.00527884, accuracy: 1.0\n",
      "Training loss: 0.0831615, accuracy: 0.984375\n",
      "Training loss: 0.010834, accuracy: 1.0\n",
      "Training loss: 0.0126926, accuracy: 1.0\n",
      "Training loss: 0.082126, accuracy: 0.96875\n",
      "Training loss: 0.0407245, accuracy: 0.984375\n",
      "Training loss: 0.0376254, accuracy: 0.984375\n",
      "Training loss: 0.00557747, accuracy: 1.0\n",
      "Training loss: 0.0171075, accuracy: 1.0\n",
      "Training loss: 0.0180847, accuracy: 1.0\n",
      "Training loss: 0.0149796, accuracy: 1.0\n",
      "Training loss: 0.00627545, accuracy: 1.0\n",
      "Training loss: 0.00821392, accuracy: 1.0\n",
      "Training loss: 0.0437779, accuracy: 0.984375\n",
      "Training loss: 0.00864397, accuracy: 1.0\n",
      "Training loss: 0.0591329, accuracy: 0.96875\n",
      "Training loss: 0.0132963, accuracy: 1.0\n",
      "Training loss: 0.0369567, accuracy: 0.984375\n",
      "Training loss: 0.0242323, accuracy: 0.984375\n",
      "----------------- Step 3400: validation accuracy 0.83072 ----------------\n",
      "Training loss: 0.0155803, accuracy: 0.984375\n",
      "Training loss: 0.0296466, accuracy: 0.984375\n",
      "Training loss: 0.0334473, accuracy: 0.984375\n",
      "Training loss: 0.0261273, accuracy: 0.984375\n",
      "Training loss: 0.0303594, accuracy: 0.96875\n",
      "Training loss: 0.0787901, accuracy: 0.984375\n",
      "Training loss: 0.0277062, accuracy: 0.984375\n",
      "Training loss: 0.143785, accuracy: 0.953125\n",
      "Training loss: 0.011862, accuracy: 1.0\n",
      "Training loss: 0.0435127, accuracy: 0.984375\n",
      "Training loss: 0.0447398, accuracy: 0.984375\n",
      "Training loss: 0.0320888, accuracy: 0.984375\n",
      "Training loss: 0.0157778, accuracy: 1.0\n",
      "Training loss: 0.0386449, accuracy: 0.984375\n",
      "Training loss: 0.0239157, accuracy: 1.0\n",
      "Training loss: 0.00561765, accuracy: 1.0\n",
      "Training loss: 0.0104591, accuracy: 1.0\n",
      "Training loss: 0.0357896, accuracy: 0.984375\n",
      "Training loss: 0.00280602, accuracy: 1.0\n",
      "Training loss: 0.00267631, accuracy: 1.0\n",
      "Training loss: 0.0175033, accuracy: 1.0\n",
      "Training loss: 0.160425, accuracy: 0.953125\n",
      "Training loss: 0.0251904, accuracy: 0.984375\n",
      "Training loss: 0.00638821, accuracy: 1.0\n",
      "Training loss: 0.0385502, accuracy: 0.984375\n",
      "Training loss: 0.0119505, accuracy: 1.0\n",
      "Training loss: 0.112402, accuracy: 0.96875\n",
      "Training loss: 0.0383074, accuracy: 0.984375\n",
      "Training loss: 0.0332575, accuracy: 0.984375\n",
      "Training loss: 0.0828256, accuracy: 0.984375\n",
      "Training loss: 0.00232906, accuracy: 1.0\n",
      "Training loss: 0.0193381, accuracy: 0.984375\n",
      "Training loss: 0.0739375, accuracy: 0.984375\n",
      "Training loss: 0.104284, accuracy: 0.984375\n",
      "Training loss: 0.226276, accuracy: 0.96875\n",
      "Training loss: 0.113478, accuracy: 0.984375\n",
      "Training loss: 0.112663, accuracy: 0.984375\n",
      "Training loss: 0.00721365, accuracy: 1.0\n",
      "Training loss: 0.0674522, accuracy: 0.984375\n",
      "Training loss: 0.0326096, accuracy: 1.0\n",
      "Training loss: 0.0987391, accuracy: 0.984375\n",
      "Training loss: 0.0924763, accuracy: 0.984375\n",
      "Training loss: 0.135456, accuracy: 0.96875\n",
      "Training loss: 0.0290431, accuracy: 0.984375\n",
      "Training loss: 0.0215989, accuracy: 1.0\n",
      "Training loss: 0.0461047, accuracy: 0.984375\n",
      "Training loss: 0.0214138, accuracy: 1.0\n",
      "Training loss: 0.0170665, accuracy: 1.0\n",
      "Training loss: 0.0712241, accuracy: 0.984375\n",
      "Training loss: 0.0461544, accuracy: 0.96875\n",
      "Training loss: 0.0133242, accuracy: 1.0\n",
      "Training loss: 0.211143, accuracy: 0.953125\n",
      "Training loss: 0.0435829, accuracy: 0.984375\n",
      "Training loss: 0.0192987, accuracy: 1.0\n",
      "Training loss: 0.034561, accuracy: 0.984375\n",
      "Training loss: 0.0218388, accuracy: 0.984375\n",
      "Training loss: 0.154774, accuracy: 0.953125\n",
      "Training loss: 0.0133302, accuracy: 1.0\n",
      "Training loss: 0.00676539, accuracy: 1.0\n",
      "Training loss: 0.0110677, accuracy: 1.0\n",
      "Training loss: 0.0484915, accuracy: 0.96875\n",
      "Training loss: 0.0531229, accuracy: 0.984375\n",
      "Training loss: 0.0458154, accuracy: 0.984375\n",
      "Training loss: 0.0139541, accuracy: 1.0\n",
      "Training loss: 0.0610881, accuracy: 0.96875\n",
      "Training loss: 0.182072, accuracy: 0.9375\n",
      "Training loss: 0.0114966, accuracy: 1.0\n",
      "Training loss: 0.0107412, accuracy: 1.0\n",
      "Training loss: 0.0271069, accuracy: 0.984375\n",
      "Training loss: 0.0138971, accuracy: 1.0\n",
      "Training loss: 0.0209951, accuracy: 1.0\n",
      "Training loss: 0.0945922, accuracy: 0.984375\n",
      "Training loss: 0.00929745, accuracy: 1.0\n",
      "Training loss: 0.0472878, accuracy: 0.984375\n",
      "Training loss: 0.127689, accuracy: 0.984375\n",
      "Training loss: 0.0170728, accuracy: 1.0\n",
      "Training loss: 0.0150114, accuracy: 1.0\n",
      "Training loss: 0.0169445, accuracy: 1.0\n",
      "Training loss: 0.0105787, accuracy: 1.0\n",
      "Training loss: 0.0367266, accuracy: 0.984375\n",
      "Training loss: 0.00983496, accuracy: 1.0\n",
      "Training loss: 0.0456417, accuracy: 0.96875\n",
      "Training loss: 0.0137523, accuracy: 1.0\n",
      "Training loss: 0.0129016, accuracy: 1.0\n",
      "Training loss: 0.0798028, accuracy: 0.96875\n",
      "Training loss: 0.00588308, accuracy: 1.0\n",
      "Training loss: 0.0343592, accuracy: 0.984375\n",
      "Training loss: 0.0416514, accuracy: 0.984375\n",
      "Training loss: 0.00839302, accuracy: 1.0\n",
      "Training loss: 0.0104408, accuracy: 1.0\n",
      "Training loss: 0.0195541, accuracy: 0.984375\n",
      "Training loss: 0.0319169, accuracy: 0.984375\n",
      "Training loss: 0.133509, accuracy: 0.984375\n",
      "Training loss: 0.0462876, accuracy: 0.984375\n",
      "Training loss: 0.00356496, accuracy: 1.0\n",
      "Training loss: 0.00459012, accuracy: 1.0\n",
      "Training loss: 0.103593, accuracy: 0.96875\n",
      "Training loss: 0.0634078, accuracy: 0.96875\n",
      "Training loss: 0.024722, accuracy: 1.0\n",
      "Training loss: 0.00616562, accuracy: 1.0\n",
      "----------------- Step 3500: validation accuracy 0.8232 ----------------\n",
      "Training loss: 0.0024122, accuracy: 1.0\n",
      "Training loss: 0.00619075, accuracy: 1.0\n",
      "Training loss: 0.107213, accuracy: 0.984375\n",
      "Training loss: 0.0279023, accuracy: 1.0\n",
      "Training loss: 0.00276569, accuracy: 1.0\n",
      "Training loss: 0.00327066, accuracy: 1.0\n",
      "Training loss: 0.00516845, accuracy: 1.0\n",
      "Training loss: 0.00886342, accuracy: 1.0\n",
      "Training loss: 0.00365639, accuracy: 1.0\n",
      "Training loss: 0.0993862, accuracy: 0.984375\n",
      "Training loss: 0.00412468, accuracy: 1.0\n",
      "Training loss: 0.0245464, accuracy: 1.0\n",
      "Training loss: 0.121713, accuracy: 0.984375\n",
      "Training loss: 0.00321664, accuracy: 1.0\n",
      "Training loss: 0.139312, accuracy: 0.96875\n",
      "Training loss: 0.111506, accuracy: 0.984375\n",
      "Training loss: 0.0794148, accuracy: 0.984375\n",
      "Training loss: 0.00365868, accuracy: 1.0\n",
      "Training loss: 0.277705, accuracy: 0.953125\n",
      "Training loss: 0.0133553, accuracy: 1.0\n",
      "Training loss: 0.036466, accuracy: 0.96875\n",
      "Training loss: 0.00677404, accuracy: 1.0\n",
      "Training loss: 0.00775686, accuracy: 1.0\n",
      "Training loss: 0.0170368, accuracy: 1.0\n",
      "Training loss: 0.00821123, accuracy: 1.0\n",
      "Training loss: 0.0140244, accuracy: 1.0\n",
      "Training loss: 0.00594804, accuracy: 1.0\n",
      "Training loss: 0.00699274, accuracy: 1.0\n",
      "Training loss: 0.109956, accuracy: 0.984375\n",
      "Training loss: 0.00595399, accuracy: 1.0\n",
      "Training loss: 0.00475856, accuracy: 1.0\n",
      "Training loss: 0.0177913, accuracy: 1.0\n",
      "Training loss: 0.0573256, accuracy: 0.984375\n",
      "Training loss: 0.0305438, accuracy: 0.984375\n",
      "Training loss: 0.0416316, accuracy: 0.984375\n",
      "Training loss: 0.00821949, accuracy: 1.0\n",
      "Training loss: 0.0154346, accuracy: 1.0\n",
      "Training loss: 0.0153202, accuracy: 1.0\n",
      "Training loss: 0.00353811, accuracy: 1.0\n",
      "Training loss: 0.063967, accuracy: 0.984375\n",
      "Training loss: 0.0098221, accuracy: 1.0\n",
      "Training loss: 0.00666085, accuracy: 1.0\n",
      "Training loss: 0.00677223, accuracy: 1.0\n",
      "Training loss: 0.0219762, accuracy: 0.984375\n",
      "Training loss: 0.106644, accuracy: 0.984375\n",
      "Training loss: 0.0113961, accuracy: 1.0\n",
      "Training loss: 0.0112371, accuracy: 1.0\n",
      "Training loss: 0.0194234, accuracy: 1.0\n",
      "Training loss: 0.02277, accuracy: 1.0\n",
      "Training loss: 0.00617037, accuracy: 1.0\n",
      "Training loss: 0.00347036, accuracy: 1.0\n",
      "Training loss: 0.00612663, accuracy: 1.0\n",
      "Training loss: 0.00468781, accuracy: 1.0\n",
      "Training loss: 0.0257208, accuracy: 0.984375\n",
      "Training loss: 0.0394975, accuracy: 0.984375\n",
      "Training loss: 0.0142683, accuracy: 1.0\n",
      "Training loss: 0.0130807, accuracy: 0.984375\n",
      "Training loss: 0.0372955, accuracy: 0.984375\n",
      "Training loss: 0.0024357, accuracy: 1.0\n",
      "Training loss: 0.138129, accuracy: 0.984375\n",
      "Training loss: 0.00349708, accuracy: 1.0\n",
      "Training loss: 0.0104292, accuracy: 1.0\n",
      "Training loss: 0.00612752, accuracy: 1.0\n",
      "Training loss: 0.119775, accuracy: 0.984375\n",
      "Training loss: 0.00296712, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.00958412, accuracy: 1.0\n",
      "Training loss: 0.0708108, accuracy: 0.984375\n",
      "Training loss: 0.115347, accuracy: 0.984375\n",
      "Training loss: 0.00487304, accuracy: 1.0\n",
      "Training loss: 0.00348075, accuracy: 1.0\n",
      "Training loss: 0.00498819, accuracy: 1.0\n",
      "Training loss: 0.138793, accuracy: 0.953125\n",
      "Training loss: 0.0104019, accuracy: 1.0\n",
      "Training loss: 0.143838, accuracy: 0.96875\n",
      "Training loss: 0.00439816, accuracy: 1.0\n",
      "Training loss: 0.14089, accuracy: 0.96875\n",
      "Training loss: 0.112062, accuracy: 0.984375\n",
      "Training loss: 0.00606781, accuracy: 1.0\n",
      "Training loss: 0.103009, accuracy: 0.96875\n",
      "Training loss: 0.0624784, accuracy: 0.984375\n",
      "Training loss: 0.00378846, accuracy: 1.0\n",
      "Training loss: 0.00565438, accuracy: 1.0\n",
      "Training loss: 0.00979786, accuracy: 1.0\n",
      "Training loss: 0.00523635, accuracy: 1.0\n",
      "Training loss: 0.130282, accuracy: 0.96875\n",
      "Training loss: 0.00403378, accuracy: 1.0\n",
      "Training loss: 0.00538069, accuracy: 1.0\n",
      "Training loss: 0.00553317, accuracy: 1.0\n",
      "Training loss: 0.0137299, accuracy: 1.0\n",
      "Training loss: 0.0594703, accuracy: 0.984375\n",
      "Training loss: 0.0165224, accuracy: 1.0\n",
      "Training loss: 0.0369093, accuracy: 0.984375\n",
      "Training loss: 0.0424948, accuracy: 0.984375\n",
      "Training loss: 0.0169174, accuracy: 1.0\n",
      "Training loss: 0.0379385, accuracy: 0.984375\n",
      "Training loss: 0.10268, accuracy: 0.984375\n",
      "Training loss: 0.00722067, accuracy: 1.0\n",
      "Training loss: 0.134325, accuracy: 0.984375\n",
      "Training loss: 0.0909913, accuracy: 0.984375\n",
      "Training loss: 0.00733955, accuracy: 1.0\n",
      "----------------- Step 3600: validation accuracy 0.83984 ----------------\n",
      "Training loss: 0.00852983, accuracy: 1.0\n",
      "Training loss: 0.00463197, accuracy: 1.0\n",
      "Training loss: 0.0138887, accuracy: 1.0\n",
      "Training loss: 0.161709, accuracy: 0.96875\n",
      "Training loss: 0.00466651, accuracy: 1.0\n",
      "Training loss: 0.00374024, accuracy: 1.0\n",
      "Training loss: 0.0076235, accuracy: 1.0\n",
      "Training loss: 0.00610124, accuracy: 1.0\n",
      "Training loss: 0.00951575, accuracy: 1.0\n",
      "Training loss: 0.00457315, accuracy: 1.0\n",
      "Training loss: 0.00432167, accuracy: 1.0\n",
      "Training loss: 0.0667408, accuracy: 0.96875\n",
      "Training loss: 0.0121726, accuracy: 1.0\n",
      "Training loss: 0.00430364, accuracy: 1.0\n",
      "Training loss: 0.0984457, accuracy: 0.984375\n",
      "Training loss: 0.00747907, accuracy: 1.0\n",
      "Training loss: 0.00766567, accuracy: 1.0\n",
      "Training loss: 0.00833273, accuracy: 1.0\n",
      "Training loss: 0.0886554, accuracy: 0.984375\n",
      "Training loss: 0.00769681, accuracy: 1.0\n",
      "Training loss: 0.00701643, accuracy: 1.0\n",
      "Training loss: 0.0226654, accuracy: 0.984375\n",
      "Training loss: 0.0080989, accuracy: 1.0\n",
      "Training loss: 0.008432, accuracy: 1.0\n",
      "Training loss: 0.11216, accuracy: 0.984375\n",
      "Training loss: 0.0730541, accuracy: 0.984375\n",
      "Training loss: 0.00773775, accuracy: 1.0\n",
      "Training loss: 0.0154224, accuracy: 1.0\n",
      "Training loss: 0.00966173, accuracy: 1.0\n",
      "Training loss: 0.00429644, accuracy: 1.0\n",
      "Training loss: 0.00301693, accuracy: 1.0\n",
      "Training loss: 0.00214309, accuracy: 1.0\n",
      "Training loss: 0.0103177, accuracy: 1.0\n",
      "Training loss: 0.00304321, accuracy: 1.0\n",
      "Training loss: 0.0184391, accuracy: 0.984375\n",
      "Training loss: 0.00368528, accuracy: 1.0\n",
      "Training loss: 0.0314525, accuracy: 0.984375\n",
      "Training loss: 0.0425172, accuracy: 0.984375\n",
      "Training loss: 0.00349054, accuracy: 1.0\n",
      "Training loss: 0.00932755, accuracy: 1.0\n",
      "Training loss: 0.00433961, accuracy: 1.0\n",
      "Training loss: 0.00389161, accuracy: 1.0\n",
      "Training loss: 0.13738, accuracy: 0.96875\n",
      "Training loss: 0.00231171, accuracy: 1.0\n",
      "Training loss: 0.0459999, accuracy: 0.984375\n",
      "Training loss: 0.00268779, accuracy: 1.0\n",
      "Training loss: 0.00767694, accuracy: 1.0\n",
      "Training loss: 0.00856574, accuracy: 1.0\n",
      "Training loss: 0.00644287, accuracy: 1.0\n",
      "Training loss: 0.00499668, accuracy: 1.0\n",
      "Training loss: 0.0999134, accuracy: 0.984375\n",
      "Training loss: 0.00246578, accuracy: 1.0\n",
      "Training loss: 0.00268532, accuracy: 1.0\n",
      "Training loss: 0.00563546, accuracy: 1.0\n",
      "Training loss: 0.00700842, accuracy: 1.0\n",
      "Training loss: 0.00577795, accuracy: 1.0\n",
      "Training loss: 0.021544, accuracy: 1.0\n",
      "Training loss: 0.00236698, accuracy: 1.0\n",
      "Training loss: 0.00937241, accuracy: 1.0\n",
      "Training loss: 0.0111265, accuracy: 1.0\n",
      "Training loss: 0.0237493, accuracy: 1.0\n",
      "Training loss: 0.00393464, accuracy: 1.0\n",
      "Training loss: 0.0499259, accuracy: 0.96875\n",
      "Training loss: 0.00436104, accuracy: 1.0\n",
      "Training loss: 0.00141891, accuracy: 1.0\n",
      "Training loss: 0.0019443, accuracy: 1.0\n",
      "Training loss: 0.0036456, accuracy: 1.0\n",
      "Training loss: 0.00519755, accuracy: 1.0\n",
      "Training loss: 0.00175703, accuracy: 1.0\n",
      "Training loss: 0.00562614, accuracy: 1.0\n",
      "Training loss: 0.00141725, accuracy: 1.0\n",
      "Training loss: 0.0108188, accuracy: 1.0\n",
      "Training loss: 0.00167051, accuracy: 1.0\n",
      "Training loss: 0.132559, accuracy: 0.984375\n",
      "Training loss: 0.00133018, accuracy: 1.0\n",
      "Training loss: 0.00226569, accuracy: 1.0\n",
      "Training loss: 0.001411, accuracy: 1.0\n",
      "Training loss: 0.00219942, accuracy: 1.0\n",
      "Training loss: 0.0372916, accuracy: 0.984375\n",
      "Training loss: 0.0100076, accuracy: 1.0\n",
      "Training loss: 0.00748069, accuracy: 1.0\n",
      "Training loss: 0.0014627, accuracy: 1.0\n",
      "Training loss: 0.00121061, accuracy: 1.0\n",
      "Training loss: 0.00194622, accuracy: 1.0\n",
      "Training loss: 0.00199615, accuracy: 1.0\n",
      "Training loss: 0.000763555, accuracy: 1.0\n",
      "Training loss: 0.00257255, accuracy: 1.0\n",
      "Training loss: 0.00371751, accuracy: 1.0\n",
      "Training loss: 0.0016619, accuracy: 1.0\n",
      "Training loss: 0.037914, accuracy: 0.984375\n",
      "Training loss: 0.00119946, accuracy: 1.0\n",
      "Training loss: 0.00165965, accuracy: 1.0\n",
      "Training loss: 0.102385, accuracy: 0.984375\n",
      "Training loss: 0.00142496, accuracy: 1.0\n",
      "Training loss: 0.00443795, accuracy: 1.0\n",
      "Training loss: 0.0037509, accuracy: 1.0\n",
      "Training loss: 0.00079939, accuracy: 1.0\n",
      "Training loss: 0.00149659, accuracy: 1.0\n",
      "Training loss: 0.00185572, accuracy: 1.0\n",
      "Training loss: 0.00189662, accuracy: 1.0\n",
      "----------------- Step 3700: validation accuracy 0.83904 ----------------\n",
      "Training loss: 0.0282938, accuracy: 0.984375\n",
      "Training loss: 0.0057807, accuracy: 1.0\n",
      "Training loss: 0.015359, accuracy: 0.984375\n",
      "Training loss: 0.00519501, accuracy: 1.0\n",
      "Training loss: 0.0128016, accuracy: 0.984375\n",
      "Training loss: 0.0038792, accuracy: 1.0\n",
      "Training loss: 0.0168756, accuracy: 0.984375\n",
      "Training loss: 0.0620799, accuracy: 0.984375\n",
      "Training loss: 0.0032232, accuracy: 1.0\n",
      "Training loss: 0.0370333, accuracy: 0.984375\n",
      "Training loss: 0.000859175, accuracy: 1.0\n",
      "Training loss: 0.000973179, accuracy: 1.0\n",
      "Training loss: 0.0189058, accuracy: 0.984375\n",
      "Training loss: 0.0196141, accuracy: 0.984375\n",
      "Training loss: 0.0140904, accuracy: 1.0\n",
      "Training loss: 0.00636864, accuracy: 1.0\n",
      "Training loss: 0.108842, accuracy: 0.984375\n",
      "Training loss: 0.210203, accuracy: 0.953125\n",
      "Training loss: 0.00848111, accuracy: 1.0\n",
      "Training loss: 0.0434049, accuracy: 0.984375\n",
      "Training loss: 0.0407668, accuracy: 0.984375\n",
      "Training loss: 0.0375442, accuracy: 0.96875\n",
      "Training loss: 0.0205867, accuracy: 0.984375\n",
      "Training loss: 0.00137557, accuracy: 1.0\n",
      "Training loss: 0.00198448, accuracy: 1.0\n",
      "Training loss: 0.00163047, accuracy: 1.0\n",
      "Training loss: 0.127799, accuracy: 0.984375\n",
      "Training loss: 0.234598, accuracy: 0.96875\n",
      "Training loss: 0.132832, accuracy: 0.984375\n",
      "Training loss: 0.00371037, accuracy: 1.0\n",
      "Training loss: 0.0524254, accuracy: 0.96875\n",
      "Training loss: 0.0503429, accuracy: 0.984375\n",
      "Training loss: 0.0103054, accuracy: 1.0\n",
      "Training loss: 0.107853, accuracy: 0.96875\n",
      "Training loss: 0.165796, accuracy: 0.96875\n",
      "Training loss: 0.179702, accuracy: 0.953125\n",
      "Training loss: 0.0446283, accuracy: 0.984375\n",
      "Training loss: 0.014422, accuracy: 1.0\n",
      "Training loss: 0.0948973, accuracy: 0.984375\n",
      "Training loss: 0.050917, accuracy: 0.984375\n",
      "Training loss: 0.00647159, accuracy: 1.0\n",
      "Training loss: 0.094886, accuracy: 0.984375\n",
      "Training loss: 0.015145, accuracy: 1.0\n",
      "Training loss: 0.00527668, accuracy: 1.0\n",
      "Training loss: 0.0909445, accuracy: 0.984375\n",
      "Training loss: 0.0732466, accuracy: 0.984375\n",
      "Training loss: 0.0111868, accuracy: 1.0\n",
      "Training loss: 0.0269299, accuracy: 0.984375\n",
      "Training loss: 0.00832148, accuracy: 1.0\n",
      "Training loss: 0.0436193, accuracy: 0.984375\n",
      "Training loss: 0.0149805, accuracy: 1.0\n",
      "Training loss: 0.0140553, accuracy: 1.0\n",
      "Training loss: 0.0112231, accuracy: 1.0\n",
      "Training loss: 0.00912031, accuracy: 1.0\n",
      "Training loss: 0.0483234, accuracy: 0.96875\n",
      "Training loss: 0.0064525, accuracy: 1.0\n",
      "Training loss: 0.012017, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.00863955, accuracy: 1.0\n",
      "Training loss: 0.0836421, accuracy: 0.984375\n",
      "Training loss: 0.0220965, accuracy: 0.984375\n",
      "Training loss: 0.0170911, accuracy: 1.0\n",
      "Training loss: 0.00523265, accuracy: 1.0\n",
      "Training loss: 0.0108271, accuracy: 1.0\n",
      "Training loss: 0.00915665, accuracy: 1.0\n",
      "Training loss: 0.0739001, accuracy: 0.984375\n",
      "Training loss: 0.00682142, accuracy: 1.0\n",
      "Training loss: 0.0136427, accuracy: 1.0\n",
      "Training loss: 0.133258, accuracy: 0.984375\n",
      "Training loss: 0.00996572, accuracy: 1.0\n",
      "Training loss: 0.0120265, accuracy: 1.0\n",
      "Training loss: 0.0126267, accuracy: 1.0\n",
      "Training loss: 0.00954253, accuracy: 1.0\n",
      "Training loss: 0.0109479, accuracy: 1.0\n",
      "Training loss: 0.094061, accuracy: 0.984375\n",
      "Training loss: 0.0208464, accuracy: 0.984375\n",
      "Training loss: 0.00392678, accuracy: 1.0\n",
      "Training loss: 0.00281034, accuracy: 1.0\n",
      "Training loss: 0.00373045, accuracy: 1.0\n",
      "Training loss: 0.00687993, accuracy: 1.0\n",
      "Training loss: 0.00847485, accuracy: 1.0\n",
      "Training loss: 0.00497742, accuracy: 1.0\n",
      "Training loss: 0.0710164, accuracy: 0.984375\n",
      "Training loss: 0.00613761, accuracy: 1.0\n",
      "Training loss: 0.00241335, accuracy: 1.0\n",
      "Training loss: 0.033295, accuracy: 0.984375\n",
      "Training loss: 0.152299, accuracy: 0.984375\n",
      "Training loss: 0.0236184, accuracy: 0.984375\n",
      "Training loss: 0.00236493, accuracy: 1.0\n",
      "Training loss: 0.024125, accuracy: 0.984375\n",
      "Training loss: 0.00799101, accuracy: 1.0\n",
      "Training loss: 0.00488788, accuracy: 1.0\n",
      "Training loss: 0.0626074, accuracy: 0.96875\n",
      "Training loss: 0.0209203, accuracy: 0.984375\n",
      "Training loss: 0.0786221, accuracy: 0.984375\n",
      "Training loss: 0.0151347, accuracy: 0.984375\n",
      "Training loss: 0.0623149, accuracy: 0.984375\n",
      "Training loss: 0.057652, accuracy: 0.984375\n",
      "Training loss: 0.00775132, accuracy: 1.0\n",
      "Training loss: 0.00135121, accuracy: 1.0\n",
      "Training loss: 0.0536339, accuracy: 0.96875\n",
      "----------------- Step 3800: validation accuracy 0.8312 ----------------\n",
      "Training loss: 0.0035731, accuracy: 1.0\n",
      "Training loss: 0.0169779, accuracy: 0.984375\n",
      "Training loss: 0.00239698, accuracy: 1.0\n",
      "Training loss: 0.00361195, accuracy: 1.0\n",
      "Training loss: 0.00574535, accuracy: 1.0\n",
      "Training loss: 0.00704291, accuracy: 1.0\n",
      "Training loss: 0.0255238, accuracy: 0.984375\n",
      "Training loss: 0.108946, accuracy: 0.984375\n",
      "Training loss: 0.105978, accuracy: 0.984375\n",
      "Training loss: 0.00278824, accuracy: 1.0\n",
      "Training loss: 0.00209555, accuracy: 1.0\n",
      "Training loss: 0.224366, accuracy: 0.96875\n",
      "Training loss: 0.00859259, accuracy: 1.0\n",
      "Training loss: 0.0041573, accuracy: 1.0\n",
      "Training loss: 0.00297227, accuracy: 1.0\n",
      "Training loss: 0.00882211, accuracy: 1.0\n",
      "Training loss: 0.0249357, accuracy: 0.984375\n",
      "Training loss: 0.00572907, accuracy: 1.0\n",
      "Training loss: 0.00637189, accuracy: 1.0\n",
      "Training loss: 0.00733387, accuracy: 1.0\n",
      "Training loss: 0.00314944, accuracy: 1.0\n",
      "Training loss: 0.0975886, accuracy: 0.96875\n",
      "Training loss: 0.00963875, accuracy: 1.0\n",
      "Training loss: 0.0721049, accuracy: 0.984375\n",
      "Training loss: 0.00448108, accuracy: 1.0\n",
      "Training loss: 0.0094493, accuracy: 1.0\n",
      "Training loss: 0.0308683, accuracy: 0.984375\n",
      "Training loss: 0.00981048, accuracy: 1.0\n",
      "Training loss: 0.00271479, accuracy: 1.0\n",
      "Training loss: 0.00541951, accuracy: 1.0\n",
      "Training loss: 0.0600216, accuracy: 0.984375\n",
      "Training loss: 0.00246771, accuracy: 1.0\n",
      "Training loss: 0.0939798, accuracy: 0.984375\n",
      "Training loss: 0.00458052, accuracy: 1.0\n",
      "Training loss: 0.0096947, accuracy: 1.0\n",
      "Training loss: 0.00963472, accuracy: 1.0\n",
      "Training loss: 0.00318449, accuracy: 1.0\n",
      "Training loss: 0.120074, accuracy: 0.984375\n",
      "Training loss: 0.0136348, accuracy: 1.0\n",
      "Training loss: 0.00687352, accuracy: 1.0\n",
      "Training loss: 0.00547296, accuracy: 1.0\n",
      "Training loss: 0.022578, accuracy: 0.984375\n",
      "Training loss: 0.00423581, accuracy: 1.0\n",
      "Training loss: 0.00240919, accuracy: 1.0\n",
      "Training loss: 0.0136496, accuracy: 1.0\n",
      "Training loss: 0.0252971, accuracy: 0.984375\n",
      "Training loss: 0.0201194, accuracy: 0.984375\n",
      "Training loss: 0.0108131, accuracy: 1.0\n",
      "Training loss: 0.00802715, accuracy: 1.0\n",
      "Training loss: 0.0486709, accuracy: 0.984375\n",
      "Training loss: 0.0101515, accuracy: 1.0\n",
      "Training loss: 0.00318829, accuracy: 1.0\n",
      "Training loss: 0.0729037, accuracy: 0.984375\n",
      "Training loss: 0.00602703, accuracy: 1.0\n",
      "Training loss: 0.00419696, accuracy: 1.0\n",
      "Training loss: 0.0152958, accuracy: 0.984375\n",
      "Training loss: 0.134095, accuracy: 0.984375\n",
      "Training loss: 0.0175153, accuracy: 0.984375\n",
      "Training loss: 0.00584855, accuracy: 1.0\n",
      "Training loss: 0.0412205, accuracy: 0.96875\n",
      "Training loss: 0.105718, accuracy: 0.984375\n",
      "Training loss: 0.00402991, accuracy: 1.0\n",
      "Training loss: 0.00931856, accuracy: 1.0\n",
      "Training loss: 0.00336105, accuracy: 1.0\n",
      "Training loss: 0.12155, accuracy: 0.984375\n",
      "Training loss: 0.102069, accuracy: 0.96875\n",
      "Training loss: 0.103187, accuracy: 0.984375\n",
      "Training loss: 0.00237277, accuracy: 1.0\n",
      "Training loss: 0.102244, accuracy: 0.984375\n",
      "Training loss: 0.115355, accuracy: 0.984375\n",
      "Training loss: 0.0595443, accuracy: 0.984375\n",
      "Training loss: 0.0530965, accuracy: 0.96875\n",
      "Training loss: 0.0758219, accuracy: 0.984375\n",
      "Training loss: 0.0155467, accuracy: 0.984375\n",
      "Training loss: 0.00793855, accuracy: 1.0\n",
      "Training loss: 0.00802724, accuracy: 1.0\n",
      "Training loss: 0.0186943, accuracy: 0.984375\n",
      "Training loss: 0.0915962, accuracy: 0.984375\n",
      "Training loss: 0.00439652, accuracy: 1.0\n",
      "Training loss: 0.0067508, accuracy: 1.0\n",
      "Training loss: 0.0164376, accuracy: 1.0\n",
      "Training loss: 0.0213691, accuracy: 1.0\n",
      "Training loss: 0.0654016, accuracy: 0.953125\n",
      "Training loss: 0.0643951, accuracy: 0.96875\n",
      "Training loss: 0.0139429, accuracy: 1.0\n",
      "Training loss: 0.0585956, accuracy: 0.984375\n",
      "Training loss: 0.00986505, accuracy: 1.0\n",
      "Training loss: 0.115269, accuracy: 0.953125\n",
      "Training loss: 0.0691529, accuracy: 0.984375\n",
      "Training loss: 0.00622778, accuracy: 1.0\n",
      "Training loss: 0.144975, accuracy: 0.96875\n",
      "Training loss: 0.108691, accuracy: 0.984375\n",
      "Training loss: 0.00659962, accuracy: 1.0\n",
      "Training loss: 0.0195748, accuracy: 0.984375\n",
      "Training loss: 0.0155852, accuracy: 1.0\n",
      "Training loss: 0.0148034, accuracy: 1.0\n",
      "Training loss: 0.0821331, accuracy: 0.96875\n",
      "Training loss: 0.00598118, accuracy: 1.0\n",
      "Training loss: 0.00652754, accuracy: 1.0\n",
      "Training loss: 0.0277729, accuracy: 0.984375\n",
      "----------------- Step 3900: validation accuracy 0.83504 ----------------\n",
      "Training loss: 0.00608477, accuracy: 1.0\n",
      "Training loss: 0.0478991, accuracy: 0.984375\n",
      "Training loss: 0.00684096, accuracy: 1.0\n",
      "Training loss: 0.0319721, accuracy: 0.984375\n",
      "Training loss: 0.0287693, accuracy: 0.984375\n",
      "Training loss: 0.0466585, accuracy: 0.96875\n",
      "Training loss: 0.00795924, accuracy: 1.0\n",
      "Training loss: 0.00929177, accuracy: 1.0\n",
      "Training loss: 0.00902809, accuracy: 1.0\n",
      "Training loss: 0.00634179, accuracy: 1.0\n",
      "Training loss: 0.033541, accuracy: 0.984375\n",
      "Training loss: 0.011836, accuracy: 1.0\n",
      "Training loss: 0.0469911, accuracy: 0.984375\n",
      "Training loss: 0.0263869, accuracy: 0.984375\n",
      "Training loss: 0.00767925, accuracy: 1.0\n",
      "Training loss: 0.0144809, accuracy: 1.0\n",
      "Training loss: 0.008516, accuracy: 1.0\n",
      "Training loss: 0.110961, accuracy: 0.984375\n",
      "Training loss: 0.00447741, accuracy: 1.0\n",
      "Training loss: 0.00742997, accuracy: 1.0\n",
      "Training loss: 0.0122254, accuracy: 1.0\n",
      "Training loss: 0.0476006, accuracy: 0.953125\n",
      "Training loss: 0.113574, accuracy: 0.953125\n",
      "Training loss: 0.00268341, accuracy: 1.0\n",
      "Training loss: 0.00339673, accuracy: 1.0\n",
      "Training loss: 0.0221292, accuracy: 1.0\n",
      "Training loss: 0.00962468, accuracy: 1.0\n",
      "Training loss: 0.00565365, accuracy: 1.0\n",
      "Training loss: 0.00362917, accuracy: 1.0\n",
      "Training loss: 0.0576506, accuracy: 0.984375\n",
      "Training loss: 0.0251135, accuracy: 0.984375\n",
      "Training loss: 0.00792421, accuracy: 1.0\n",
      "Training loss: 0.00329365, accuracy: 1.0\n",
      "Training loss: 0.0472133, accuracy: 0.984375\n",
      "Training loss: 0.00704777, accuracy: 1.0\n",
      "Training loss: 0.0920722, accuracy: 0.984375\n",
      "Training loss: 0.00685075, accuracy: 1.0\n",
      "Training loss: 0.00429112, accuracy: 1.0\n",
      "Training loss: 0.00311128, accuracy: 1.0\n",
      "Training loss: 0.0057526, accuracy: 1.0\n",
      "Training loss: 0.0250532, accuracy: 1.0\n",
      "Training loss: 0.00736495, accuracy: 1.0\n",
      "Training loss: 0.0783594, accuracy: 0.984375\n",
      "Training loss: 0.0746946, accuracy: 0.984375\n",
      "Training loss: 0.0131471, accuracy: 1.0\n",
      "Training loss: 0.00710752, accuracy: 1.0\n",
      "Training loss: 0.00824142, accuracy: 1.0\n",
      "Training loss: 0.0546746, accuracy: 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0094884, accuracy: 1.0\n",
      "Training loss: 0.0542534, accuracy: 0.984375\n",
      "Training loss: 0.0119227, accuracy: 1.0\n",
      "Training loss: 0.00328983, accuracy: 1.0\n",
      "Training loss: 0.0293858, accuracy: 0.984375\n",
      "Training loss: 0.00795321, accuracy: 1.0\n",
      "Training loss: 0.0078708, accuracy: 1.0\n",
      "Training loss: 0.00401223, accuracy: 1.0\n",
      "Training loss: 0.0128651, accuracy: 1.0\n",
      "Training loss: 0.0909487, accuracy: 0.96875\n",
      "Training loss: 0.0112966, accuracy: 1.0\n",
      "Training loss: 0.00977072, accuracy: 1.0\n",
      "Training loss: 0.0510739, accuracy: 0.984375\n",
      "Training loss: 0.00400096, accuracy: 1.0\n",
      "Training loss: 0.00361933, accuracy: 1.0\n",
      "Training loss: 0.00162759, accuracy: 1.0\n",
      "Training loss: 0.0669596, accuracy: 0.984375\n",
      "Training loss: 0.00224342, accuracy: 1.0\n",
      "Training loss: 0.129709, accuracy: 0.984375\n",
      "Training loss: 0.0923357, accuracy: 0.984375\n",
      "Training loss: 0.00425163, accuracy: 1.0\n",
      "Training loss: 0.0235449, accuracy: 0.984375\n",
      "Training loss: 0.00376143, accuracy: 1.0\n",
      "Training loss: 0.0653592, accuracy: 0.984375\n",
      "Training loss: 0.0599228, accuracy: 0.96875\n",
      "Training loss: 0.0716338, accuracy: 0.984375\n",
      "Training loss: 0.0158456, accuracy: 0.984375\n",
      "Training loss: 0.00653396, accuracy: 1.0\n",
      "Training loss: 0.0475433, accuracy: 0.96875\n",
      "Training loss: 0.0917597, accuracy: 0.984375\n",
      "Training loss: 0.0245281, accuracy: 0.984375\n",
      "Training loss: 0.0173022, accuracy: 0.984375\n",
      "Training loss: 0.05629, accuracy: 0.984375\n",
      "Training loss: 0.00439552, accuracy: 1.0\n",
      "Training loss: 0.0221489, accuracy: 1.0\n",
      "Training loss: 0.00531786, accuracy: 1.0\n",
      "Training loss: 0.0717376, accuracy: 0.984375\n",
      "Training loss: 0.00420662, accuracy: 1.0\n",
      "Training loss: 0.00268671, accuracy: 1.0\n",
      "Training loss: 0.00455072, accuracy: 1.0\n",
      "Training loss: 0.0230708, accuracy: 0.984375\n",
      "Training loss: 0.108706, accuracy: 0.984375\n",
      "Training loss: 0.0450074, accuracy: 0.984375\n",
      "Training loss: 0.0134074, accuracy: 1.0\n",
      "Training loss: 0.146245, accuracy: 0.96875\n",
      "Training loss: 0.00302915, accuracy: 1.0\n",
      "Training loss: 0.00561455, accuracy: 1.0\n",
      "Training loss: 0.0105524, accuracy: 1.0\n",
      "Training loss: 0.0471383, accuracy: 0.984375\n",
      "Training loss: 0.0175087, accuracy: 1.0\n",
      "Training loss: 0.00354324, accuracy: 1.0\n",
      "Training loss: 0.00368346, accuracy: 1.0\n",
      "----------------- Step 4000: validation accuracy 0.83152 ----------------\n",
      "Training loss: 0.0182343, accuracy: 1.0\n",
      "Training loss: 0.12226, accuracy: 0.953125\n",
      "Training loss: 0.118317, accuracy: 0.9375\n",
      "Training loss: 0.0251459, accuracy: 0.984375\n",
      "Training loss: 0.00289339, accuracy: 1.0\n",
      "Training loss: 0.00713125, accuracy: 1.0\n",
      "Training loss: 0.0511907, accuracy: 0.953125\n",
      "Training loss: 0.0747917, accuracy: 0.96875\n",
      "Training loss: 0.00642118, accuracy: 1.0\n",
      "Training loss: 0.0104133, accuracy: 1.0\n",
      "Training loss: 0.0768346, accuracy: 0.96875\n",
      "Training loss: 0.0698524, accuracy: 0.984375\n",
      "Training loss: 0.0199555, accuracy: 1.0\n",
      "Training loss: 0.080486, accuracy: 0.984375\n",
      "Training loss: 0.0156534, accuracy: 0.984375\n",
      "Training loss: 0.00506411, accuracy: 1.0\n",
      "Training loss: 0.142167, accuracy: 0.953125\n",
      "Training loss: 0.00425192, accuracy: 1.0\n",
      "Training loss: 0.00288411, accuracy: 1.0\n",
      "Training loss: 0.119782, accuracy: 0.984375\n",
      "Training loss: 0.222078, accuracy: 0.96875\n",
      "Training loss: 0.112483, accuracy: 0.984375\n",
      "Training loss: 0.00822432, accuracy: 1.0\n",
      "Training loss: 0.0375156, accuracy: 0.984375\n",
      "Training loss: 0.0933222, accuracy: 0.96875\n",
      "Training loss: 0.013474, accuracy: 1.0\n",
      "Training loss: 0.130562, accuracy: 0.96875\n",
      "Training loss: 0.210289, accuracy: 0.96875\n",
      "Training loss: 0.134765, accuracy: 0.96875\n",
      "Training loss: 0.0171024, accuracy: 1.0\n",
      "Training loss: 0.0216437, accuracy: 1.0\n",
      "Training loss: 0.0152358, accuracy: 1.0\n",
      "Training loss: 0.014538, accuracy: 1.0\n",
      "Training loss: 0.0104918, accuracy: 1.0\n",
      "Training loss: 0.0200832, accuracy: 1.0\n",
      "Training loss: 0.0101222, accuracy: 1.0\n",
      "Training loss: 0.0188788, accuracy: 1.0\n",
      "Training loss: 0.0741354, accuracy: 0.984375\n",
      "Training loss: 0.0901311, accuracy: 0.984375\n",
      "Training loss: 0.0264041, accuracy: 1.0\n",
      "Training loss: 0.0191698, accuracy: 1.0\n",
      "Training loss: 0.0130003, accuracy: 1.0\n",
      "Training loss: 0.0570094, accuracy: 0.96875\n",
      "Training loss: 0.0110982, accuracy: 1.0\n",
      "Training loss: 0.00725037, accuracy: 1.0\n",
      "Training loss: 0.0156183, accuracy: 1.0\n",
      "Training loss: 0.0955466, accuracy: 0.984375\n",
      "Training loss: 0.0241929, accuracy: 0.984375\n",
      "Training loss: 0.00973099, accuracy: 1.0\n",
      "Training loss: 0.00629239, accuracy: 1.0\n",
      "Training loss: 0.00476689, accuracy: 1.0\n",
      "Training loss: 0.0788883, accuracy: 0.984375\n",
      "Training loss: 0.0132582, accuracy: 1.0\n",
      "Training loss: 0.00979207, accuracy: 1.0\n",
      "Training loss: 0.00603163, accuracy: 1.0\n",
      "Training loss: 0.00775619, accuracy: 1.0\n",
      "Training loss: 0.00732277, accuracy: 1.0\n",
      "Training loss: 0.0740058, accuracy: 0.984375\n",
      "Training loss: 0.0138807, accuracy: 1.0\n",
      "Training loss: 0.00338713, accuracy: 1.0\n",
      "Training loss: 0.25241, accuracy: 0.953125\n",
      "Training loss: 0.0175867, accuracy: 0.984375\n",
      "Training loss: 0.0282975, accuracy: 0.984375\n",
      "Training loss: 0.0127985, accuracy: 1.0\n",
      "Training loss: 0.0107317, accuracy: 1.0\n",
      "Training loss: 0.00419565, accuracy: 1.0\n",
      "Training loss: 0.0367941, accuracy: 0.984375\n",
      "Training loss: 0.0240229, accuracy: 0.984375\n",
      "Training loss: 0.0284182, accuracy: 0.984375\n",
      "Training loss: 0.00711186, accuracy: 1.0\n",
      "Training loss: 0.00316415, accuracy: 1.0\n",
      "Training loss: 0.00316991, accuracy: 1.0\n",
      "Training loss: 0.0174672, accuracy: 0.984375\n",
      "Training loss: 0.00980465, accuracy: 1.0\n",
      "Training loss: 0.00403774, accuracy: 1.0\n",
      "Training loss: 0.00244192, accuracy: 1.0\n",
      "Training loss: 0.0103654, accuracy: 1.0\n",
      "Training loss: 0.00312515, accuracy: 1.0\n",
      "Training loss: 0.104117, accuracy: 0.984375\n",
      "Training loss: 0.00204507, accuracy: 1.0\n",
      "Training loss: 0.022519, accuracy: 0.984375\n",
      "Training loss: 0.00515251, accuracy: 1.0\n",
      "Training loss: 0.0161151, accuracy: 1.0\n",
      "Training loss: 0.00804226, accuracy: 1.0\n",
      "Training loss: 0.0645498, accuracy: 0.96875\n",
      "Training loss: 0.0136655, accuracy: 1.0\n",
      "Training loss: 0.00201442, accuracy: 1.0\n",
      "Training loss: 0.00492574, accuracy: 1.0\n",
      "Training loss: 0.010863, accuracy: 1.0\n",
      "Training loss: 0.00599065, accuracy: 1.0\n",
      "Training loss: 0.00901919, accuracy: 1.0\n",
      "Training loss: 0.00176042, accuracy: 1.0\n",
      "Training loss: 0.0291658, accuracy: 0.984375\n",
      "Training loss: 0.00291848, accuracy: 1.0\n",
      "Training loss: 0.00158203, accuracy: 1.0\n",
      "Training loss: 0.0180664, accuracy: 0.984375\n",
      "Training loss: 0.00348678, accuracy: 1.0\n",
      "Training loss: 0.00412336, accuracy: 1.0\n",
      "Training loss: 0.00246725, accuracy: 1.0\n",
      "Training loss: 0.108132, accuracy: 0.984375\n",
      "----------------- Step 4100: validation accuracy 0.84176 ----------------\n",
      "Training loss: 0.102131, accuracy: 0.984375\n",
      "Training loss: 0.0811047, accuracy: 0.984375\n",
      "Training loss: 0.00207281, accuracy: 1.0\n",
      "Training loss: 0.0017606, accuracy: 1.0\n",
      "Training loss: 0.234235, accuracy: 0.96875\n",
      "Training loss: 0.0732601, accuracy: 0.96875\n",
      "Training loss: 0.00544523, accuracy: 1.0\n",
      "Training loss: 0.0166546, accuracy: 1.0\n",
      "Training loss: 0.00245779, accuracy: 1.0\n",
      "Training loss: 0.00183777, accuracy: 1.0\n",
      "Training loss: 0.0212256, accuracy: 0.984375\n",
      "Training loss: 0.00952377, accuracy: 1.0\n",
      "Training loss: 0.00217883, accuracy: 1.0\n",
      "Training loss: 0.00795945, accuracy: 1.0\n",
      "Training loss: 0.00712504, accuracy: 1.0\n",
      "Training loss: 0.115011, accuracy: 0.984375\n",
      "Training loss: 0.00364508, accuracy: 1.0\n",
      "Training loss: 0.00614685, accuracy: 1.0\n",
      "Training loss: 0.0126285, accuracy: 1.0\n",
      "Training loss: 0.010731, accuracy: 1.0\n",
      "Training loss: 0.0413285, accuracy: 0.984375\n",
      "Training loss: 0.00416951, accuracy: 1.0\n",
      "Training loss: 0.0122775, accuracy: 1.0\n",
      "Training loss: 0.0183105, accuracy: 0.984375\n",
      "Training loss: 0.00357367, accuracy: 1.0\n",
      "Training loss: 0.0823752, accuracy: 0.984375\n",
      "Training loss: 0.00539877, accuracy: 1.0\n",
      "Training loss: 0.00754297, accuracy: 1.0\n",
      "Training loss: 0.00510265, accuracy: 1.0\n",
      "Training loss: 0.00516938, accuracy: 1.0\n",
      "Training loss: 0.0948029, accuracy: 0.984375\n",
      "Training loss: 0.00865003, accuracy: 1.0\n",
      "Training loss: 0.00279563, accuracy: 1.0\n",
      "Training loss: 0.00490015, accuracy: 1.0\n",
      "Training loss: 0.0158779, accuracy: 1.0\n",
      "Training loss: 0.00240678, accuracy: 1.0\n",
      "Training loss: 0.0322223, accuracy: 0.984375\n",
      "Training loss: 0.0601035, accuracy: 0.984375\n",
      "Training loss: 0.00330446, accuracy: 1.0\n",
      "Training loss: 0.0164094, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0528412, accuracy: 0.96875\n",
      "Training loss: 0.00625049, accuracy: 1.0\n",
      "Training loss: 0.00777792, accuracy: 1.0\n",
      "Training loss: 0.00807116, accuracy: 1.0\n",
      "Training loss: 0.00765875, accuracy: 1.0\n",
      "Training loss: 0.119954, accuracy: 0.953125\n",
      "Training loss: 0.00426617, accuracy: 1.0\n",
      "Training loss: 0.0148935, accuracy: 1.0\n",
      "Training loss: 0.00589013, accuracy: 1.0\n",
      "Training loss: 0.147879, accuracy: 0.96875\n",
      "Training loss: 0.00164325, accuracy: 1.0\n",
      "Training loss: 0.00429739, accuracy: 1.0\n",
      "Training loss: 0.0619085, accuracy: 0.96875\n",
      "Training loss: 0.0163886, accuracy: 1.0\n",
      "Training loss: 0.0028445, accuracy: 1.0\n",
      "Training loss: 0.0062544, accuracy: 1.0\n",
      "Training loss: 0.00817794, accuracy: 1.0\n",
      "Training loss: 0.107122, accuracy: 0.984375\n",
      "Training loss: 0.0101572, accuracy: 1.0\n",
      "Training loss: 0.0196584, accuracy: 0.984375\n",
      "Training loss: 0.00749305, accuracy: 1.0\n",
      "Training loss: 0.129191, accuracy: 0.984375\n",
      "Training loss: 0.0037678, accuracy: 1.0\n",
      "Training loss: 0.00263501, accuracy: 1.0\n",
      "Training loss: 0.0280778, accuracy: 0.984375\n",
      "Training loss: 0.00996959, accuracy: 1.0\n",
      "Training loss: 0.0189577, accuracy: 0.984375\n",
      "Training loss: 0.00493924, accuracy: 1.0\n",
      "Training loss: 0.00326668, accuracy: 1.0\n",
      "Training loss: 0.00321672, accuracy: 1.0\n",
      "Training loss: 0.0914798, accuracy: 0.96875\n",
      "Training loss: 0.00123202, accuracy: 1.0\n",
      "Training loss: 0.00798649, accuracy: 1.0\n",
      "Training loss: 0.00252163, accuracy: 1.0\n",
      "Training loss: 0.0107222, accuracy: 1.0\n",
      "Training loss: 0.0425224, accuracy: 0.984375\n",
      "Training loss: 0.0332027, accuracy: 0.984375\n",
      "Training loss: 0.00556387, accuracy: 1.0\n",
      "Training loss: 0.0132753, accuracy: 1.0\n",
      "Training loss: 0.0937021, accuracy: 0.984375\n",
      "Training loss: 0.0171249, accuracy: 1.0\n",
      "Training loss: 0.00244488, accuracy: 1.0\n",
      "Training loss: 0.00251478, accuracy: 1.0\n",
      "Training loss: 0.0132954, accuracy: 1.0\n",
      "Training loss: 0.0230078, accuracy: 1.0\n",
      "Training loss: 0.00675056, accuracy: 1.0\n",
      "Training loss: 0.00202984, accuracy: 1.0\n",
      "Training loss: 0.00191755, accuracy: 1.0\n",
      "Training loss: 0.0537161, accuracy: 0.984375\n",
      "Training loss: 0.0104643, accuracy: 1.0\n",
      "Training loss: 0.00216619, accuracy: 1.0\n",
      "Training loss: 0.00204618, accuracy: 1.0\n",
      "Training loss: 0.00366533, accuracy: 1.0\n",
      "Training loss: 0.0109173, accuracy: 1.0\n",
      "Training loss: 0.00138531, accuracy: 1.0\n",
      "Training loss: 0.00715411, accuracy: 1.0\n",
      "Training loss: 0.000994171, accuracy: 1.0\n",
      "Training loss: 0.00825263, accuracy: 1.0\n",
      "Training loss: 0.00135218, accuracy: 1.0\n",
      "Training loss: 0.00105416, accuracy: 1.0\n",
      "Better accuracy found. LSTM model saved\n",
      "----------------- Step 4200: validation accuracy 0.84416 ----------------\n",
      "Training loss: 0.00247903, accuracy: 1.0\n",
      "Training loss: 0.000824246, accuracy: 1.0\n",
      "Training loss: 0.00261873, accuracy: 1.0\n",
      "Training loss: 0.00115091, accuracy: 1.0\n",
      "Training loss: 0.00588191, accuracy: 1.0\n",
      "Training loss: 0.000497115, accuracy: 1.0\n",
      "Training loss: 0.000853852, accuracy: 1.0\n",
      "Training loss: 0.000940601, accuracy: 1.0\n",
      "Training loss: 0.00387614, accuracy: 1.0\n",
      "Training loss: 0.00231902, accuracy: 1.0\n",
      "Training loss: 0.152468, accuracy: 0.984375\n",
      "Training loss: 0.00828879, accuracy: 1.0\n",
      "Training loss: 0.000773748, accuracy: 1.0\n",
      "Training loss: 0.00429935, accuracy: 1.0\n",
      "Training loss: 0.0903137, accuracy: 0.984375\n",
      "Training loss: 0.0112118, accuracy: 1.0\n",
      "Training loss: 0.0510663, accuracy: 0.984375\n",
      "Training loss: 0.00109646, accuracy: 1.0\n",
      "Training loss: 0.00389166, accuracy: 1.0\n",
      "Training loss: 0.045586, accuracy: 0.984375\n",
      "Training loss: 0.00108363, accuracy: 1.0\n",
      "Training loss: 0.000988574, accuracy: 1.0\n",
      "Training loss: 0.0480965, accuracy: 0.984375\n",
      "Training loss: 0.0245188, accuracy: 0.984375\n",
      "Training loss: 0.00483449, accuracy: 1.0\n",
      "Training loss: 0.0016232, accuracy: 1.0\n",
      "Training loss: 0.00176365, accuracy: 1.0\n",
      "Training loss: 0.0945517, accuracy: 0.984375\n",
      "Training loss: 0.0540732, accuracy: 0.984375\n",
      "Training loss: 0.00105794, accuracy: 1.0\n",
      "Training loss: 0.00169959, accuracy: 1.0\n",
      "Training loss: 0.00196789, accuracy: 1.0\n",
      "Training loss: 0.00124181, accuracy: 1.0\n",
      "Training loss: 0.0621894, accuracy: 0.984375\n",
      "Training loss: 0.00335012, accuracy: 1.0\n",
      "Training loss: 0.00194371, accuracy: 1.0\n",
      "Training loss: 0.0492125, accuracy: 0.984375\n",
      "Training loss: 0.00724337, accuracy: 1.0\n",
      "Training loss: 0.0049107, accuracy: 1.0\n",
      "Training loss: 0.0716767, accuracy: 0.984375\n",
      "Training loss: 0.0634151, accuracy: 0.96875\n",
      "Training loss: 0.00404928, accuracy: 1.0\n",
      "Training loss: 0.0164127, accuracy: 1.0\n",
      "Training loss: 0.00456089, accuracy: 1.0\n",
      "Training loss: 0.00871527, accuracy: 1.0\n",
      "Training loss: 0.00457362, accuracy: 1.0\n",
      "Training loss: 0.00668424, accuracy: 1.0\n",
      "Training loss: 0.00517392, accuracy: 1.0\n",
      "Training loss: 0.0105131, accuracy: 1.0\n",
      "Training loss: 0.0224708, accuracy: 0.984375\n",
      "Training loss: 0.00285081, accuracy: 1.0\n",
      "Training loss: 0.00546805, accuracy: 1.0\n",
      "Training loss: 0.00467522, accuracy: 1.0\n",
      "Training loss: 0.00350891, accuracy: 1.0\n",
      "Training loss: 0.00882615, accuracy: 1.0\n",
      "Training loss: 0.00162954, accuracy: 1.0\n",
      "Training loss: 0.00190901, accuracy: 1.0\n",
      "Training loss: 0.00776796, accuracy: 1.0\n",
      "Training loss: 0.00431999, accuracy: 1.0\n",
      "Training loss: 0.101377, accuracy: 0.984375\n",
      "Training loss: 0.00280511, accuracy: 1.0\n",
      "Training loss: 0.00183014, accuracy: 1.0\n",
      "Training loss: 0.00509291, accuracy: 1.0\n",
      "Training loss: 0.00448034, accuracy: 1.0\n",
      "Training loss: 0.00253391, accuracy: 1.0\n",
      "Training loss: 0.0230734, accuracy: 0.984375\n",
      "Training loss: 0.00187364, accuracy: 1.0\n",
      "Training loss: 0.00162632, accuracy: 1.0\n",
      "Training loss: 0.00144739, accuracy: 1.0\n",
      "Training loss: 0.0141067, accuracy: 0.984375\n",
      "Training loss: 0.00249897, accuracy: 1.0\n",
      "Training loss: 0.00415605, accuracy: 1.0\n",
      "Training loss: 0.00387934, accuracy: 1.0\n",
      "Training loss: 0.0351917, accuracy: 0.984375\n",
      "Training loss: 0.0014593, accuracy: 1.0\n",
      "Training loss: 0.0451347, accuracy: 0.96875\n",
      "Training loss: 0.00135335, accuracy: 1.0\n",
      "Training loss: 0.00135901, accuracy: 1.0\n",
      "Training loss: 0.00121677, accuracy: 1.0\n",
      "Training loss: 0.000875404, accuracy: 1.0\n",
      "Training loss: 0.0178977, accuracy: 0.984375\n",
      "Training loss: 0.00303781, accuracy: 1.0\n",
      "Training loss: 0.000670596, accuracy: 1.0\n",
      "Training loss: 0.000906163, accuracy: 1.0\n",
      "Training loss: 0.000759492, accuracy: 1.0\n",
      "Training loss: 0.0101922, accuracy: 1.0\n",
      "Training loss: 0.00929448, accuracy: 1.0\n",
      "Training loss: 0.00308773, accuracy: 1.0\n",
      "Training loss: 0.0521088, accuracy: 0.984375\n",
      "Training loss: 0.0102232, accuracy: 1.0\n",
      "Training loss: 0.012911, accuracy: 1.0\n",
      "Training loss: 0.00163009, accuracy: 1.0\n",
      "Training loss: 0.00470563, accuracy: 1.0\n",
      "Training loss: 0.00366128, accuracy: 1.0\n",
      "Training loss: 0.00164645, accuracy: 1.0\n",
      "Training loss: 0.0121308, accuracy: 1.0\n",
      "Training loss: 0.00622628, accuracy: 1.0\n",
      "Training loss: 0.0273612, accuracy: 0.984375\n",
      "Training loss: 0.000625314, accuracy: 1.0\n",
      "Training loss: 0.00145393, accuracy: 1.0\n",
      "----------------- Step 4300: validation accuracy 0.83088 ----------------\n",
      "Training loss: 0.00180065, accuracy: 1.0\n",
      "Training loss: 0.00110287, accuracy: 1.0\n",
      "Training loss: 0.00325991, accuracy: 1.0\n",
      "Training loss: 0.0953825, accuracy: 0.96875\n",
      "Training loss: 0.0701471, accuracy: 0.984375\n",
      "Training loss: 0.00398056, accuracy: 1.0\n",
      "Training loss: 0.0201701, accuracy: 0.984375\n",
      "Training loss: 0.00356496, accuracy: 1.0\n",
      "Training loss: 0.00117468, accuracy: 1.0\n",
      "Training loss: 0.000568099, accuracy: 1.0\n",
      "Training loss: 0.00120775, accuracy: 1.0\n",
      "Training loss: 0.000717815, accuracy: 1.0\n",
      "Training loss: 0.14562, accuracy: 0.984375\n",
      "Training loss: 0.208021, accuracy: 0.96875\n",
      "Training loss: 0.157726, accuracy: 0.96875\n",
      "Training loss: 0.0509614, accuracy: 0.96875\n",
      "Training loss: 0.0592393, accuracy: 0.984375\n",
      "Training loss: 0.00310531, accuracy: 1.0\n",
      "Training loss: 0.122791, accuracy: 0.984375\n",
      "Training loss: 0.00526954, accuracy: 1.0\n",
      "Training loss: 0.125854, accuracy: 0.984375\n",
      "Training loss: 0.00566384, accuracy: 1.0\n",
      "Training loss: 0.0399446, accuracy: 0.984375\n",
      "Training loss: 0.00869291, accuracy: 1.0\n",
      "Training loss: 0.0125869, accuracy: 1.0\n",
      "Training loss: 0.0032406, accuracy: 1.0\n",
      "Training loss: 0.00514677, accuracy: 1.0\n",
      "Training loss: 0.00956456, accuracy: 1.0\n",
      "Training loss: 0.00475202, accuracy: 1.0\n",
      "Training loss: 0.0030651, accuracy: 1.0\n",
      "Training loss: 0.0836516, accuracy: 0.984375\n",
      "Training loss: 0.00480008, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.00519823, accuracy: 1.0\n",
      "Training loss: 0.00712185, accuracy: 1.0\n",
      "Training loss: 0.00438812, accuracy: 1.0\n",
      "Training loss: 0.00328795, accuracy: 1.0\n",
      "Training loss: 0.00406151, accuracy: 1.0\n",
      "Training loss: 0.0045388, accuracy: 1.0\n",
      "Training loss: 0.00989388, accuracy: 1.0\n",
      "Training loss: 0.0157951, accuracy: 0.984375\n",
      "Training loss: 0.00223423, accuracy: 1.0\n",
      "Training loss: 0.0116598, accuracy: 1.0\n",
      "Training loss: 0.00375965, accuracy: 1.0\n",
      "Training loss: 0.00289106, accuracy: 1.0\n",
      "Training loss: 0.0137072, accuracy: 0.984375\n",
      "Training loss: 0.0113794, accuracy: 1.0\n",
      "Training loss: 0.00681696, accuracy: 1.0\n",
      "Training loss: 0.0342251, accuracy: 0.984375\n",
      "Training loss: 0.00306145, accuracy: 1.0\n",
      "Training loss: 0.00412127, accuracy: 1.0\n",
      "Training loss: 0.0823173, accuracy: 0.984375\n",
      "Training loss: 0.00249272, accuracy: 1.0\n",
      "Training loss: 0.00253575, accuracy: 1.0\n",
      "Training loss: 0.117055, accuracy: 0.984375\n",
      "Training loss: 0.00175266, accuracy: 1.0\n",
      "Training loss: 0.00456534, accuracy: 1.0\n",
      "Training loss: 0.00941583, accuracy: 1.0\n",
      "Training loss: 0.00406921, accuracy: 1.0\n",
      "Training loss: 0.00295953, accuracy: 1.0\n",
      "Training loss: 0.00303879, accuracy: 1.0\n",
      "Training loss: 0.0171029, accuracy: 1.0\n",
      "Training loss: 0.00409834, accuracy: 1.0\n",
      "Training loss: 0.00228904, accuracy: 1.0\n",
      "Training loss: 0.00210999, accuracy: 1.0\n",
      "Training loss: 0.00165786, accuracy: 1.0\n",
      "Training loss: 0.00208596, accuracy: 1.0\n",
      "Training loss: 0.0525384, accuracy: 0.984375\n",
      "Training loss: 0.00233193, accuracy: 1.0\n",
      "Training loss: 0.00273499, accuracy: 1.0\n",
      "Training loss: 0.00414324, accuracy: 1.0\n",
      "Training loss: 0.0016083, accuracy: 1.0\n",
      "Training loss: 0.135139, accuracy: 0.96875\n",
      "Training loss: 0.0014044, accuracy: 1.0\n",
      "Training loss: 0.00360089, accuracy: 1.0\n",
      "Training loss: 0.00351583, accuracy: 1.0\n",
      "Training loss: 0.00535772, accuracy: 1.0\n",
      "Training loss: 0.0186501, accuracy: 0.984375\n",
      "Training loss: 0.00930681, accuracy: 1.0\n",
      "Training loss: 0.00970496, accuracy: 1.0\n",
      "Training loss: 0.00184359, accuracy: 1.0\n",
      "Training loss: 0.00220617, accuracy: 1.0\n",
      "Training loss: 0.00271675, accuracy: 1.0\n",
      "Training loss: 0.0761217, accuracy: 0.984375\n",
      "Training loss: 0.0194963, accuracy: 0.984375\n",
      "Training loss: 0.00116903, accuracy: 1.0\n",
      "Training loss: 0.000853753, accuracy: 1.0\n",
      "Training loss: 0.00333147, accuracy: 1.0\n",
      "Training loss: 0.00485149, accuracy: 1.0\n",
      "Training loss: 0.0010054, accuracy: 1.0\n",
      "Training loss: 0.0242374, accuracy: 0.984375\n",
      "Training loss: 0.00396156, accuracy: 1.0\n",
      "Training loss: 0.0608998, accuracy: 0.984375\n",
      "Training loss: 0.0892797, accuracy: 0.96875\n",
      "Training loss: 0.075174, accuracy: 0.984375\n",
      "Training loss: 0.0301929, accuracy: 0.984375\n",
      "Training loss: 0.00262087, accuracy: 1.0\n",
      "Training loss: 0.00170407, accuracy: 1.0\n",
      "Training loss: 0.211833, accuracy: 0.96875\n",
      "Training loss: 0.00252491, accuracy: 1.0\n",
      "Training loss: 0.00991215, accuracy: 1.0\n",
      "----------------- Step 4400: validation accuracy 0.82592 ----------------\n",
      "Training loss: 0.00695376, accuracy: 1.0\n",
      "Training loss: 0.0461622, accuracy: 0.984375\n",
      "Training loss: 0.00164477, accuracy: 1.0\n",
      "Training loss: 0.00754567, accuracy: 1.0\n",
      "Training loss: 0.00292857, accuracy: 1.0\n",
      "Training loss: 0.00889832, accuracy: 1.0\n",
      "Training loss: 0.0238995, accuracy: 0.984375\n",
      "Training loss: 0.00733432, accuracy: 1.0\n",
      "Training loss: 0.103079, accuracy: 0.984375\n",
      "Training loss: 0.00311701, accuracy: 1.0\n",
      "Training loss: 0.0532881, accuracy: 0.984375\n",
      "Training loss: 0.0055497, accuracy: 1.0\n",
      "Training loss: 0.00985197, accuracy: 1.0\n",
      "Training loss: 0.0464448, accuracy: 0.96875\n",
      "Training loss: 0.0120459, accuracy: 1.0\n",
      "Training loss: 0.0203081, accuracy: 0.984375\n",
      "Training loss: 0.0112284, accuracy: 1.0\n",
      "Training loss: 0.00478326, accuracy: 1.0\n",
      "Training loss: 0.0752717, accuracy: 0.984375\n",
      "Training loss: 0.0199406, accuracy: 0.984375\n",
      "Training loss: 0.0312933, accuracy: 0.984375\n",
      "Training loss: 0.0446937, accuracy: 0.984375\n",
      "Training loss: 0.0665589, accuracy: 0.984375\n",
      "Training loss: 0.101416, accuracy: 0.984375\n",
      "Training loss: 0.0101175, accuracy: 1.0\n",
      "Training loss: 0.0293729, accuracy: 0.984375\n",
      "Training loss: 0.00911962, accuracy: 1.0\n",
      "Training loss: 0.0135595, accuracy: 1.0\n",
      "Training loss: 0.0028898, accuracy: 1.0\n",
      "Training loss: 0.0108615, accuracy: 1.0\n",
      "Training loss: 0.0155068, accuracy: 1.0\n",
      "Training loss: 0.00578482, accuracy: 1.0\n",
      "Training loss: 0.0183902, accuracy: 0.984375\n",
      "Training loss: 0.00518462, accuracy: 1.0\n",
      "Training loss: 0.00566801, accuracy: 1.0\n",
      "Training loss: 0.0510753, accuracy: 0.96875\n",
      "Training loss: 0.00844798, accuracy: 1.0\n",
      "Training loss: 0.0972223, accuracy: 0.953125\n",
      "Training loss: 0.177199, accuracy: 0.96875\n",
      "Training loss: 0.0198605, accuracy: 0.984375\n",
      "Training loss: 0.00487031, accuracy: 1.0\n",
      "Training loss: 0.00254441, accuracy: 1.0\n",
      "Training loss: 0.120277, accuracy: 0.984375\n",
      "Training loss: 0.0018732, accuracy: 1.0\n",
      "Training loss: 0.00488112, accuracy: 1.0\n",
      "Training loss: 0.0193223, accuracy: 1.0\n",
      "Training loss: 0.0399726, accuracy: 0.984375\n",
      "Training loss: 0.00171599, accuracy: 1.0\n",
      "Training loss: 0.0121149, accuracy: 1.0\n",
      "Training loss: 0.00239903, accuracy: 1.0\n",
      "Training loss: 0.148386, accuracy: 0.96875\n",
      "Training loss: 0.00768103, accuracy: 1.0\n",
      "Training loss: 0.0103963, accuracy: 1.0\n",
      "Training loss: 0.0824805, accuracy: 0.953125\n",
      "Training loss: 0.0982825, accuracy: 0.984375\n",
      "Training loss: 0.0318066, accuracy: 0.984375\n",
      "Training loss: 0.00465378, accuracy: 1.0\n",
      "Training loss: 0.00429581, accuracy: 1.0\n",
      "Training loss: 0.0629298, accuracy: 0.984375\n",
      "Training loss: 0.00660113, accuracy: 1.0\n",
      "Training loss: 0.00398003, accuracy: 1.0\n",
      "Training loss: 0.00380407, accuracy: 1.0\n",
      "Training loss: 0.00845891, accuracy: 1.0\n",
      "Training loss: 0.100457, accuracy: 0.984375\n",
      "Training loss: 0.010996, accuracy: 1.0\n",
      "Training loss: 0.00439665, accuracy: 1.0\n",
      "Training loss: 0.00275425, accuracy: 1.0\n",
      "Training loss: 0.00583473, accuracy: 1.0\n",
      "Training loss: 0.0134679, accuracy: 1.0\n",
      "Training loss: 0.0705026, accuracy: 0.96875\n",
      "Training loss: 0.00254114, accuracy: 1.0\n",
      "Training loss: 0.0370241, accuracy: 0.984375\n",
      "Training loss: 0.0453052, accuracy: 0.96875\n",
      "Training loss: 0.0158207, accuracy: 1.0\n",
      "Training loss: 0.121195, accuracy: 0.96875\n",
      "Training loss: 0.00341172, accuracy: 1.0\n",
      "Training loss: 0.0969096, accuracy: 0.953125\n",
      "Training loss: 0.0146714, accuracy: 1.0\n",
      "Training loss: 0.0138944, accuracy: 1.0\n",
      "Training loss: 0.00678426, accuracy: 1.0\n",
      "Training loss: 0.00897482, accuracy: 1.0\n",
      "Training loss: 0.0166928, accuracy: 1.0\n",
      "Training loss: 0.0176205, accuracy: 0.984375\n",
      "Training loss: 0.00813213, accuracy: 1.0\n",
      "Training loss: 0.0367788, accuracy: 0.984375\n",
      "Training loss: 0.00845629, accuracy: 1.0\n",
      "Training loss: 0.00216906, accuracy: 1.0\n",
      "Training loss: 0.00251749, accuracy: 1.0\n",
      "Training loss: 0.00189557, accuracy: 1.0\n",
      "Training loss: 0.00176868, accuracy: 1.0\n",
      "Training loss: 0.0251904, accuracy: 0.984375\n",
      "Training loss: 0.0243734, accuracy: 0.984375\n",
      "Training loss: 0.00457425, accuracy: 1.0\n",
      "Training loss: 0.00216146, accuracy: 1.0\n",
      "Training loss: 0.0803086, accuracy: 0.984375\n",
      "Training loss: 0.0195106, accuracy: 0.984375\n",
      "Training loss: 0.00513629, accuracy: 1.0\n",
      "Training loss: 0.0020382, accuracy: 1.0\n",
      "Training loss: 0.0900374, accuracy: 0.96875\n",
      "Training loss: 0.0014417, accuracy: 1.0\n",
      "----------------- Step 4500: validation accuracy 0.83888 ----------------\n",
      "Training loss: 0.00152889, accuracy: 1.0\n",
      "Training loss: 0.0127701, accuracy: 1.0\n",
      "Training loss: 0.0876801, accuracy: 0.984375\n",
      "Training loss: 0.131203, accuracy: 0.984375\n",
      "Training loss: 0.00494961, accuracy: 1.0\n",
      "Training loss: 0.0020064, accuracy: 1.0\n",
      "Training loss: 0.00612673, accuracy: 1.0\n",
      "Training loss: 0.00709818, accuracy: 1.0\n",
      "Training loss: 0.00607825, accuracy: 1.0\n",
      "Training loss: 0.0689135, accuracy: 0.984375\n",
      "Training loss: 0.00219283, accuracy: 1.0\n",
      "Training loss: 0.00683057, accuracy: 1.0\n",
      "Training loss: 0.00813032, accuracy: 1.0\n",
      "Training loss: 0.00545773, accuracy: 1.0\n",
      "Training loss: 0.0017913, accuracy: 1.0\n",
      "Training loss: 0.0925903, accuracy: 0.953125\n",
      "Training loss: 0.00781621, accuracy: 1.0\n",
      "Training loss: 0.00275687, accuracy: 1.0\n",
      "Training loss: 0.0717165, accuracy: 0.984375\n",
      "Training loss: 0.0031963, accuracy: 1.0\n",
      "Training loss: 0.00415264, accuracy: 1.0\n",
      "Training loss: 0.00256173, accuracy: 1.0\n",
      "Training loss: 0.00156089, accuracy: 1.0\n",
      "Training loss: 0.0021075, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0610654, accuracy: 0.984375\n",
      "Training loss: 0.00676377, accuracy: 1.0\n",
      "Training loss: 0.00549809, accuracy: 1.0\n",
      "Training loss: 0.00302354, accuracy: 1.0\n",
      "Training loss: 0.00147925, accuracy: 1.0\n",
      "Training loss: 0.00345621, accuracy: 1.0\n",
      "Training loss: 0.00278938, accuracy: 1.0\n",
      "Training loss: 0.0603484, accuracy: 0.984375\n",
      "Training loss: 0.00792425, accuracy: 1.0\n",
      "Training loss: 0.00320166, accuracy: 1.0\n",
      "Training loss: 0.00318812, accuracy: 1.0\n",
      "Training loss: 0.002765, accuracy: 1.0\n",
      "Training loss: 0.00291009, accuracy: 1.0\n",
      "Training loss: 0.00551585, accuracy: 1.0\n",
      "Training loss: 0.00218708, accuracy: 1.0\n",
      "Training loss: 0.0184863, accuracy: 0.984375\n",
      "Training loss: 0.00194245, accuracy: 1.0\n",
      "Training loss: 0.00903565, accuracy: 1.0\n",
      "Training loss: 0.00181011, accuracy: 1.0\n",
      "Training loss: 0.0708493, accuracy: 0.96875\n",
      "Training loss: 0.00678607, accuracy: 1.0\n",
      "Training loss: 0.0159245, accuracy: 0.984375\n",
      "Training loss: 0.0659013, accuracy: 0.96875\n",
      "Training loss: 0.0952354, accuracy: 0.984375\n",
      "Training loss: 0.0138895, accuracy: 0.984375\n",
      "Training loss: 0.00313671, accuracy: 1.0\n",
      "Training loss: 0.0658148, accuracy: 0.984375\n",
      "Training loss: 0.0036223, accuracy: 1.0\n",
      "Training loss: 0.0964922, accuracy: 0.984375\n",
      "Training loss: 0.0252668, accuracy: 0.984375\n",
      "Training loss: 0.0224514, accuracy: 0.984375\n",
      "Training loss: 0.0313095, accuracy: 0.984375\n",
      "Training loss: 0.0053886, accuracy: 1.0\n",
      "Training loss: 0.0841514, accuracy: 0.984375\n",
      "Training loss: 0.0750655, accuracy: 0.96875\n",
      "Training loss: 0.0108582, accuracy: 1.0\n",
      "Training loss: 0.00254511, accuracy: 1.0\n",
      "Training loss: 0.0841821, accuracy: 0.96875\n",
      "Training loss: 0.010318, accuracy: 1.0\n",
      "Training loss: 0.0150067, accuracy: 1.0\n",
      "Training loss: 0.00888392, accuracy: 1.0\n",
      "Training loss: 0.00936418, accuracy: 1.0\n",
      "Training loss: 0.00892551, accuracy: 1.0\n",
      "Training loss: 0.00302017, accuracy: 1.0\n",
      "Training loss: 0.0155707, accuracy: 1.0\n",
      "Training loss: 0.00614124, accuracy: 1.0\n",
      "Training loss: 0.0363429, accuracy: 0.984375\n",
      "Training loss: 0.00334802, accuracy: 1.0\n",
      "Training loss: 0.00358761, accuracy: 1.0\n",
      "Training loss: 0.0110162, accuracy: 1.0\n",
      "Training loss: 0.00351157, accuracy: 1.0\n",
      "Training loss: 0.00184291, accuracy: 1.0\n",
      "Training loss: 0.00290751, accuracy: 1.0\n",
      "Training loss: 0.0133694, accuracy: 1.0\n",
      "Training loss: 0.00414776, accuracy: 1.0\n",
      "Training loss: 0.0484258, accuracy: 0.96875\n",
      "Training loss: 0.0129782, accuracy: 1.0\n",
      "Training loss: 0.0177366, accuracy: 0.984375\n",
      "Training loss: 0.00443983, accuracy: 1.0\n",
      "Training loss: 0.0116471, accuracy: 1.0\n",
      "Training loss: 0.00491053, accuracy: 1.0\n",
      "Training loss: 0.0164989, accuracy: 0.984375\n",
      "Training loss: 0.00299183, accuracy: 1.0\n",
      "Training loss: 0.00252322, accuracy: 1.0\n",
      "Training loss: 0.00350993, accuracy: 1.0\n",
      "Training loss: 0.00359027, accuracy: 1.0\n",
      "Training loss: 0.000860565, accuracy: 1.0\n",
      "Training loss: 0.00202912, accuracy: 1.0\n",
      "Training loss: 0.00438343, accuracy: 1.0\n",
      "Training loss: 0.025262, accuracy: 0.984375\n",
      "Training loss: 0.030112, accuracy: 0.984375\n",
      "Training loss: 0.00145146, accuracy: 1.0\n",
      "Training loss: 0.0847392, accuracy: 0.984375\n",
      "Training loss: 0.010299, accuracy: 1.0\n",
      "Training loss: 0.0544802, accuracy: 0.984375\n",
      "Training loss: 0.0343592, accuracy: 0.984375\n",
      "----------------- Step 4600: validation accuracy 0.83424 ----------------\n",
      "Training loss: 0.00270675, accuracy: 1.0\n",
      "Training loss: 0.0368094, accuracy: 0.984375\n",
      "Training loss: 0.00260025, accuracy: 1.0\n",
      "Training loss: 0.00484193, accuracy: 1.0\n",
      "Training loss: 0.00159785, accuracy: 1.0\n",
      "Training loss: 0.14631, accuracy: 0.96875\n",
      "Training loss: 0.115377, accuracy: 0.984375\n",
      "Training loss: 0.124094, accuracy: 0.984375\n",
      "Training loss: 0.00196751, accuracy: 1.0\n",
      "Training loss: 0.0740501, accuracy: 0.984375\n",
      "Training loss: 0.050767, accuracy: 0.984375\n",
      "Training loss: 0.14, accuracy: 0.96875\n",
      "Training loss: 0.0179546, accuracy: 0.984375\n",
      "Training loss: 0.126866, accuracy: 0.984375\n",
      "Training loss: 0.00378081, accuracy: 1.0\n",
      "Training loss: 0.063645, accuracy: 0.984375\n",
      "Training loss: 0.0301099, accuracy: 0.984375\n",
      "Training loss: 0.00318062, accuracy: 1.0\n",
      "Training loss: 0.0314924, accuracy: 0.984375\n",
      "Training loss: 0.0688951, accuracy: 0.984375\n",
      "Training loss: 0.0155976, accuracy: 1.0\n",
      "Training loss: 0.169249, accuracy: 0.9375\n",
      "Training loss: 0.068474, accuracy: 0.96875\n",
      "Training loss: 0.0964995, accuracy: 0.984375\n",
      "Training loss: 0.0162438, accuracy: 1.0\n",
      "Training loss: 0.0052015, accuracy: 1.0\n",
      "Training loss: 0.0139258, accuracy: 1.0\n",
      "Training loss: 0.00637766, accuracy: 1.0\n",
      "Training loss: 0.0375115, accuracy: 0.96875\n",
      "Training loss: 0.0251564, accuracy: 0.984375\n",
      "Training loss: 0.0213415, accuracy: 1.0\n",
      "Training loss: 0.135632, accuracy: 0.953125\n",
      "Training loss: 0.0869754, accuracy: 0.984375\n",
      "Training loss: 0.236312, accuracy: 0.96875\n",
      "Training loss: 0.013947, accuracy: 1.0\n",
      "Training loss: 0.0172929, accuracy: 1.0\n",
      "Training loss: 0.00701627, accuracy: 1.0\n",
      "Training loss: 0.051551, accuracy: 0.984375\n",
      "Training loss: 0.0121248, accuracy: 1.0\n",
      "Training loss: 0.0294637, accuracy: 0.984375\n",
      "Training loss: 0.0220344, accuracy: 0.984375\n",
      "Training loss: 0.00884381, accuracy: 1.0\n",
      "Training loss: 0.00631225, accuracy: 1.0\n",
      "Training loss: 0.148554, accuracy: 0.96875\n",
      "Training loss: 0.00754583, accuracy: 1.0\n",
      "Training loss: 0.00583486, accuracy: 1.0\n",
      "Training loss: 0.146462, accuracy: 0.96875\n",
      "Training loss: 0.00549812, accuracy: 1.0\n",
      "Training loss: 0.0991458, accuracy: 0.984375\n",
      "Training loss: 0.0527941, accuracy: 0.984375\n",
      "Training loss: 0.0581858, accuracy: 0.96875\n",
      "Training loss: 0.0094264, accuracy: 1.0\n",
      "Training loss: 0.00610672, accuracy: 1.0\n",
      "Training loss: 0.0728565, accuracy: 0.96875\n",
      "Training loss: 0.0222193, accuracy: 0.984375\n",
      "Training loss: 0.00556217, accuracy: 1.0\n",
      "Training loss: 0.0126348, accuracy: 1.0\n",
      "Training loss: 0.00492742, accuracy: 1.0\n",
      "Training loss: 0.00599338, accuracy: 1.0\n",
      "Training loss: 0.00882765, accuracy: 1.0\n",
      "Training loss: 0.00477664, accuracy: 1.0\n",
      "Training loss: 0.0208227, accuracy: 0.984375\n",
      "Training loss: 0.0181435, accuracy: 0.984375\n",
      "Training loss: 0.016384, accuracy: 1.0\n",
      "Training loss: 0.0912605, accuracy: 0.984375\n",
      "Training loss: 0.0227929, accuracy: 0.984375\n",
      "Training loss: 0.050426, accuracy: 0.984375\n",
      "Training loss: 0.00421411, accuracy: 1.0\n",
      "Training loss: 0.0920511, accuracy: 0.96875\n",
      "Training loss: 0.0739787, accuracy: 0.984375\n",
      "Training loss: 0.0101642, accuracy: 1.0\n",
      "Training loss: 0.00604583, accuracy: 1.0\n",
      "Training loss: 0.00587632, accuracy: 1.0\n",
      "Training loss: 0.161207, accuracy: 0.953125\n",
      "Training loss: 0.00311544, accuracy: 1.0\n",
      "Training loss: 0.0132219, accuracy: 1.0\n",
      "Training loss: 0.0302941, accuracy: 0.984375\n",
      "Training loss: 0.0366574, accuracy: 0.984375\n",
      "Training loss: 0.00178566, accuracy: 1.0\n",
      "Training loss: 0.00402298, accuracy: 1.0\n",
      "Training loss: 0.00447031, accuracy: 1.0\n",
      "Training loss: 0.0278221, accuracy: 0.984375\n",
      "Training loss: 0.00408636, accuracy: 1.0\n",
      "Training loss: 0.00833824, accuracy: 1.0\n",
      "Training loss: 0.155303, accuracy: 0.96875\n",
      "Training loss: 0.0552161, accuracy: 0.984375\n",
      "Training loss: 0.0868975, accuracy: 0.984375\n",
      "Training loss: 0.131746, accuracy: 0.96875\n",
      "Training loss: 0.00676525, accuracy: 1.0\n",
      "Training loss: 0.00489197, accuracy: 1.0\n",
      "Training loss: 0.181823, accuracy: 0.96875\n",
      "Training loss: 0.00562604, accuracy: 1.0\n",
      "Training loss: 0.00971097, accuracy: 1.0\n",
      "Training loss: 0.00696648, accuracy: 1.0\n",
      "Training loss: 0.00488213, accuracy: 1.0\n",
      "Training loss: 0.0042975, accuracy: 1.0\n",
      "Training loss: 0.037852, accuracy: 0.984375\n",
      "Training loss: 0.0169354, accuracy: 1.0\n",
      "Training loss: 0.0045056, accuracy: 1.0\n",
      "Training loss: 0.0337382, accuracy: 0.984375\n",
      "----------------- Step 4700: validation accuracy 0.8352 ----------------\n",
      "Training loss: 0.0379637, accuracy: 0.984375\n",
      "Training loss: 0.011023, accuracy: 1.0\n",
      "Training loss: 0.00542026, accuracy: 1.0\n",
      "Training loss: 0.031429, accuracy: 0.984375\n",
      "Training loss: 0.040237, accuracy: 0.984375\n",
      "Training loss: 0.0481753, accuracy: 0.984375\n",
      "Training loss: 0.0632804, accuracy: 0.984375\n",
      "Training loss: 0.00936836, accuracy: 1.0\n",
      "Training loss: 0.0353099, accuracy: 0.984375\n",
      "Training loss: 0.027485, accuracy: 1.0\n",
      "Training loss: 0.00888274, accuracy: 1.0\n",
      "Training loss: 0.0793379, accuracy: 0.96875\n",
      "Training loss: 0.00767399, accuracy: 1.0\n",
      "Training loss: 0.0585164, accuracy: 0.96875\n",
      "Training loss: 0.00695354, accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.00513043, accuracy: 1.0\n",
      "Training loss: 0.106284, accuracy: 0.984375\n",
      "Training loss: 0.0129687, accuracy: 1.0\n",
      "Training loss: 0.0066368, accuracy: 1.0\n",
      "Training loss: 0.00759397, accuracy: 1.0\n",
      "Training loss: 0.0248049, accuracy: 0.984375\n",
      "Training loss: 0.0106188, accuracy: 1.0\n",
      "Training loss: 0.00723049, accuracy: 1.0\n",
      "Training loss: 0.0203069, accuracy: 0.984375\n",
      "Training loss: 0.00357334, accuracy: 1.0\n",
      "Training loss: 0.0578045, accuracy: 0.984375\n",
      "Training loss: 0.0390613, accuracy: 0.984375\n",
      "Training loss: 0.0108876, accuracy: 1.0\n",
      "Training loss: 0.00391955, accuracy: 1.0\n",
      "Training loss: 0.00727179, accuracy: 1.0\n",
      "Training loss: 0.00294991, accuracy: 1.0\n",
      "Training loss: 0.0671941, accuracy: 0.984375\n",
      "Training loss: 0.00662755, accuracy: 1.0\n",
      "Training loss: 0.00404395, accuracy: 1.0\n",
      "Training loss: 0.00276867, accuracy: 1.0\n",
      "Training loss: 0.126809, accuracy: 0.984375\n",
      "Training loss: 0.00325459, accuracy: 1.0\n",
      "Training loss: 0.00601155, accuracy: 1.0\n",
      "Training loss: 0.0343877, accuracy: 1.0\n",
      "Training loss: 0.0152249, accuracy: 1.0\n",
      "Training loss: 0.00288835, accuracy: 1.0\n",
      "Training loss: 0.00935045, accuracy: 1.0\n",
      "Training loss: 0.0495002, accuracy: 0.984375\n",
      "Training loss: 0.197003, accuracy: 0.953125\n",
      "Training loss: 0.0275063, accuracy: 1.0\n",
      "Training loss: 0.0189099, accuracy: 1.0\n",
      "Training loss: 0.00418974, accuracy: 1.0\n",
      "Training loss: 0.129535, accuracy: 0.984375\n",
      "Training loss: 0.0183456, accuracy: 0.984375\n",
      "Training loss: 0.0119254, accuracy: 1.0\n",
      "Training loss: 0.0343102, accuracy: 0.984375\n",
      "Training loss: 0.0863126, accuracy: 0.984375\n",
      "Training loss: 0.0263845, accuracy: 0.984375\n",
      "Training loss: 0.0210222, accuracy: 0.984375\n",
      "Training loss: 0.0463927, accuracy: 0.984375\n",
      "Training loss: 0.0167065, accuracy: 0.984375\n",
      "Training loss: 0.096281, accuracy: 0.984375\n",
      "Training loss: 0.0024339, accuracy: 1.0\n",
      "Training loss: 0.007913, accuracy: 1.0\n",
      "Training loss: 0.00559381, accuracy: 1.0\n",
      "Training loss: 0.00507601, accuracy: 1.0\n",
      "Training loss: 0.00664236, accuracy: 1.0\n",
      "Training loss: 0.0353672, accuracy: 0.984375\n",
      "Training loss: 0.00411453, accuracy: 1.0\n",
      "Training loss: 0.00790376, accuracy: 1.0\n",
      "Training loss: 0.00819681, accuracy: 1.0\n",
      "Training loss: 0.0122101, accuracy: 1.0\n",
      "Training loss: 0.00387632, accuracy: 1.0\n",
      "Training loss: 0.00441858, accuracy: 1.0\n",
      "Training loss: 0.00891275, accuracy: 1.0\n",
      "Training loss: 0.00751535, accuracy: 1.0\n",
      "Training loss: 0.00995224, accuracy: 1.0\n",
      "Training loss: 0.00159789, accuracy: 1.0\n",
      "Training loss: 0.0364031, accuracy: 0.984375\n",
      "Training loss: 0.0385289, accuracy: 0.96875\n",
      "Training loss: 0.00403381, accuracy: 1.0\n",
      "Training loss: 0.00123868, accuracy: 1.0\n",
      "Training loss: 0.00155506, accuracy: 1.0\n",
      "Training loss: 0.00544839, accuracy: 1.0\n",
      "Training loss: 0.000950502, accuracy: 1.0\n",
      "Training loss: 0.00135224, accuracy: 1.0\n",
      "Training loss: 0.00278689, accuracy: 1.0\n",
      "Training loss: 0.00258731, accuracy: 1.0\n",
      "Training loss: 0.00969255, accuracy: 1.0\n",
      "Training loss: 0.00709532, accuracy: 1.0\n",
      "Training loss: 0.0196342, accuracy: 0.984375\n",
      "Training loss: 0.00248803, accuracy: 1.0\n",
      "Training loss: 0.00148788, accuracy: 1.0\n",
      "Training loss: 0.006956, accuracy: 1.0\n",
      "Training loss: 0.0103906, accuracy: 1.0\n",
      "Training loss: 0.0197512, accuracy: 0.984375\n",
      "Training loss: 0.0172884, accuracy: 0.984375\n",
      "Training loss: 0.00105112, accuracy: 1.0\n",
      "Training loss: 0.00131825, accuracy: 1.0\n",
      "Training loss: 0.00503503, accuracy: 1.0\n",
      "Training loss: 0.00175185, accuracy: 1.0\n",
      "Training loss: 0.150791, accuracy: 0.984375\n",
      "Training loss: 0.0266792, accuracy: 0.984375\n",
      "Training loss: 0.00135814, accuracy: 1.0\n",
      "Training loss: 0.00559624, accuracy: 1.0\n",
      "----------------- Step 4800: validation accuracy 0.83904 ----------------\n",
      "Training loss: 0.00241471, accuracy: 1.0\n",
      "Training loss: 0.00116596, accuracy: 1.0\n",
      "Training loss: 0.000553238, accuracy: 1.0\n",
      "Training loss: 0.000660367, accuracy: 1.0\n",
      "Training loss: 0.0053673, accuracy: 1.0\n",
      "Training loss: 0.00123244, accuracy: 1.0\n",
      "Training loss: 0.0821822, accuracy: 0.984375\n",
      "Training loss: 0.00196917, accuracy: 1.0\n",
      "Training loss: 0.0559112, accuracy: 0.96875\n",
      "Training loss: 0.00103031, accuracy: 1.0\n",
      "Training loss: 0.0365864, accuracy: 0.984375\n",
      "Training loss: 0.00102035, accuracy: 1.0\n",
      "Training loss: 0.00131105, accuracy: 1.0\n",
      "Training loss: 0.00695222, accuracy: 1.0\n",
      "Training loss: 0.0611062, accuracy: 0.984375\n",
      "Training loss: 0.000635753, accuracy: 1.0\n",
      "Training loss: 0.000763253, accuracy: 1.0\n",
      "Training loss: 0.00181339, accuracy: 1.0\n",
      "Training loss: 0.000947693, accuracy: 1.0\n",
      "Training loss: 0.0047772, accuracy: 1.0\n",
      "Training loss: 0.0027321, accuracy: 1.0\n",
      "Training loss: 0.0257176, accuracy: 0.984375\n",
      "Training loss: 0.00128479, accuracy: 1.0\n",
      "Training loss: 0.0108962, accuracy: 1.0\n",
      "Training loss: 0.000741161, accuracy: 1.0\n",
      "Training loss: 0.0168362, accuracy: 0.984375\n",
      "Training loss: 0.00115691, accuracy: 1.0\n",
      "Training loss: 0.00133707, accuracy: 1.0\n",
      "Training loss: 0.00249363, accuracy: 1.0\n",
      "Training loss: 0.00803453, accuracy: 1.0\n",
      "Training loss: 0.00203743, accuracy: 1.0\n",
      "Training loss: 0.000866811, accuracy: 1.0\n",
      "Training loss: 0.00296617, accuracy: 1.0\n",
      "Training loss: 0.00146401, accuracy: 1.0\n",
      "Training loss: 0.00185966, accuracy: 1.0\n",
      "Training loss: 0.090507, accuracy: 0.984375\n",
      "Training loss: 0.000979674, accuracy: 1.0\n",
      "Training loss: 0.0053331, accuracy: 1.0\n",
      "Training loss: 0.0900146, accuracy: 0.984375\n",
      "Training loss: 0.0106368, accuracy: 1.0\n",
      "Training loss: 0.00994424, accuracy: 1.0\n",
      "Training loss: 0.0195646, accuracy: 0.984375\n",
      "Training loss: 0.0287009, accuracy: 0.984375\n",
      "Training loss: 0.00188903, accuracy: 1.0\n",
      "Training loss: 0.0023595, accuracy: 1.0\n",
      "Training loss: 0.102457, accuracy: 0.984375\n",
      "Training loss: 0.00255449, accuracy: 1.0\n",
      "Training loss: 0.000749154, accuracy: 1.0\n",
      "Training loss: 0.00179709, accuracy: 1.0\n",
      "Training loss: 0.0203212, accuracy: 0.984375\n",
      "Training loss: 0.0125965, accuracy: 1.0\n",
      "Training loss: 0.00933652, accuracy: 1.0\n",
      "Training loss: 0.00296405, accuracy: 1.0\n",
      "Training loss: 0.000624268, accuracy: 1.0\n",
      "Training loss: 0.0144194, accuracy: 1.0\n",
      "Training loss: 0.00105382, accuracy: 1.0\n",
      "Training loss: 0.00512088, accuracy: 1.0\n",
      "Training loss: 0.0170378, accuracy: 0.984375\n",
      "Training loss: 0.000998365, accuracy: 1.0\n",
      "Training loss: 0.0185116, accuracy: 0.984375\n",
      "Training loss: 0.00207382, accuracy: 1.0\n",
      "Training loss: 0.002572, accuracy: 1.0\n",
      "Training loss: 0.0138676, accuracy: 0.984375\n",
      "Training loss: 0.00130587, accuracy: 1.0\n",
      "Training loss: 0.00109621, accuracy: 1.0\n",
      "Training loss: 0.0045748, accuracy: 1.0\n",
      "Training loss: 0.00407639, accuracy: 1.0\n",
      "Training loss: 0.00223929, accuracy: 1.0\n",
      "Training loss: 0.000940995, accuracy: 1.0\n",
      "Training loss: 0.00119867, accuracy: 1.0\n",
      "Training loss: 0.107993, accuracy: 0.984375\n",
      "Training loss: 0.000809215, accuracy: 1.0\n",
      "Training loss: 0.0530256, accuracy: 0.984375\n",
      "Training loss: 0.00318728, accuracy: 1.0\n",
      "Training loss: 0.00939417, accuracy: 1.0\n",
      "Training loss: 0.0014201, accuracy: 1.0\n",
      "Training loss: 0.00173084, accuracy: 1.0\n",
      "Training loss: 0.00253903, accuracy: 1.0\n",
      "Training loss: 0.00619906, accuracy: 1.0\n",
      "Training loss: 0.00361938, accuracy: 1.0\n",
      "Training loss: 0.0262853, accuracy: 0.984375\n",
      "Training loss: 0.000924806, accuracy: 1.0\n",
      "Training loss: 0.00197889, accuracy: 1.0\n",
      "Training loss: 0.000828855, accuracy: 1.0\n",
      "Training loss: 0.000790386, accuracy: 1.0\n",
      "Training loss: 0.0040542, accuracy: 1.0\n",
      "Training loss: 0.000884824, accuracy: 1.0\n",
      "Training loss: 0.00874343, accuracy: 1.0\n",
      "Training loss: 0.000614315, accuracy: 1.0\n",
      "Training loss: 0.0703483, accuracy: 0.984375\n",
      "Training loss: 0.0119178, accuracy: 1.0\n",
      "Training loss: 0.0109685, accuracy: 1.0\n",
      "Training loss: 0.00465541, accuracy: 1.0\n",
      "Training loss: 0.000802706, accuracy: 1.0\n",
      "Training loss: 0.0008273, accuracy: 1.0\n",
      "Training loss: 0.00188828, accuracy: 1.0\n",
      "Training loss: 0.00124037, accuracy: 1.0\n",
      "Training loss: 0.00170696, accuracy: 1.0\n",
      "Training loss: 0.212466, accuracy: 0.96875\n",
      "Training loss: 0.111229, accuracy: 0.984375\n",
      "----------------- Step 4900: validation accuracy 0.8336 ----------------\n",
      "Training loss: 0.121443, accuracy: 0.984375\n",
      "Training loss: 0.0816236, accuracy: 0.984375\n",
      "Training loss: 0.00308248, accuracy: 1.0\n",
      "Training loss: 0.00224638, accuracy: 1.0\n",
      "Training loss: 0.0588913, accuracy: 0.984375\n",
      "Training loss: 0.00538529, accuracy: 1.0\n",
      "Training loss: 0.134928, accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0281824, accuracy: 0.984375\n",
      "Training loss: 0.0160642, accuracy: 0.984375\n",
      "Training loss: 0.00319698, accuracy: 1.0\n",
      "Training loss: 0.0646329, accuracy: 0.984375\n",
      "Training loss: 0.0349235, accuracy: 0.96875\n",
      "Training loss: 0.00652195, accuracy: 1.0\n",
      "Training loss: 0.00220341, accuracy: 1.0\n",
      "Training loss: 0.00366302, accuracy: 1.0\n",
      "Training loss: 0.116826, accuracy: 0.984375\n",
      "Training loss: 0.00308413, accuracy: 1.0\n",
      "Training loss: 0.00308918, accuracy: 1.0\n",
      "Training loss: 0.0183787, accuracy: 0.984375\n",
      "Training loss: 0.0154482, accuracy: 1.0\n",
      "Training loss: 0.021238, accuracy: 0.984375\n",
      "Training loss: 0.0509633, accuracy: 0.984375\n",
      "Training loss: 0.0213522, accuracy: 0.984375\n",
      "Training loss: 0.00565588, accuracy: 1.0\n",
      "Training loss: 0.00319117, accuracy: 1.0\n",
      "Training loss: 0.0027498, accuracy: 1.0\n",
      "Training loss: 0.106513, accuracy: 0.96875\n",
      "Training loss: 0.00309907, accuracy: 1.0\n",
      "Training loss: 0.00380978, accuracy: 1.0\n",
      "Training loss: 0.00763373, accuracy: 1.0\n",
      "Training loss: 0.00786878, accuracy: 1.0\n",
      "Training loss: 0.00578057, accuracy: 1.0\n",
      "Training loss: 0.0105142, accuracy: 1.0\n",
      "Training loss: 0.0301498, accuracy: 0.96875\n",
      "Training loss: 0.00224764, accuracy: 1.0\n",
      "Training loss: 0.00463382, accuracy: 1.0\n",
      "Training loss: 0.0713456, accuracy: 0.984375\n",
      "Training loss: 0.00380384, accuracy: 1.0\n",
      "Training loss: 0.00671869, accuracy: 1.0\n",
      "Training loss: 0.158002, accuracy: 0.96875\n",
      "Training loss: 0.0022241, accuracy: 1.0\n",
      "Training loss: 0.00705736, accuracy: 1.0\n",
      "Training loss: 0.0217249, accuracy: 1.0\n",
      "Training loss: 0.00255854, accuracy: 1.0\n",
      "Training loss: 0.00402602, accuracy: 1.0\n",
      "Training loss: 0.00177446, accuracy: 1.0\n",
      "Training loss: 0.0198176, accuracy: 0.984375\n",
      "Training loss: 0.00291978, accuracy: 1.0\n",
      "Training loss: 0.00193208, accuracy: 1.0\n",
      "Training loss: 0.00492316, accuracy: 1.0\n",
      "Training loss: 0.00149889, accuracy: 1.0\n",
      "Training loss: 0.00296329, accuracy: 1.0\n",
      "Training loss: 0.00142969, accuracy: 1.0\n",
      "Training loss: 0.00244358, accuracy: 1.0\n",
      "Training loss: 0.0144815, accuracy: 1.0\n",
      "Training loss: 0.00790532, accuracy: 1.0\n",
      "Training loss: 0.00229817, accuracy: 1.0\n",
      "Training loss: 0.123061, accuracy: 0.984375\n",
      "Training loss: 0.00123942, accuracy: 1.0\n",
      "Training loss: 0.00321965, accuracy: 1.0\n",
      "Training loss: 0.00294071, accuracy: 1.0\n",
      "Training loss: 0.00362218, accuracy: 1.0\n",
      "Training loss: 0.00410954, accuracy: 1.0\n",
      "Training loss: 0.00733613, accuracy: 1.0\n",
      "Training loss: 0.00185303, accuracy: 1.0\n",
      "Training loss: 0.00131621, accuracy: 1.0\n",
      "Training loss: 0.0200498, accuracy: 0.984375\n",
      "Training loss: 0.00148638, accuracy: 1.0\n",
      "Training loss: 0.0031714, accuracy: 1.0\n",
      "Training loss: 0.00173161, accuracy: 1.0\n",
      "Training loss: 0.00315008, accuracy: 1.0\n",
      "Training loss: 0.00118538, accuracy: 1.0\n",
      "Training loss: 0.00182891, accuracy: 1.0\n",
      "Training loss: 0.00131847, accuracy: 1.0\n",
      "Training loss: 0.00578898, accuracy: 1.0\n",
      "Training loss: 0.0189908, accuracy: 0.984375\n",
      "Training loss: 0.0129763, accuracy: 1.0\n",
      "Training loss: 0.00429993, accuracy: 1.0\n",
      "Training loss: 0.0155003, accuracy: 0.984375\n",
      "Training loss: 0.0836211, accuracy: 0.984375\n",
      "Training loss: 0.0415707, accuracy: 0.96875\n",
      "Training loss: 0.000755992, accuracy: 1.0\n",
      "Training loss: 0.0219619, accuracy: 0.984375\n",
      "Training loss: 0.184291, accuracy: 0.96875\n",
      "Training loss: 0.00832332, accuracy: 1.0\n",
      "Training loss: 0.0015499, accuracy: 1.0\n",
      "Training loss: 0.00100632, accuracy: 1.0\n",
      "Training loss: 0.00109065, accuracy: 1.0\n",
      "Training loss: 0.000891726, accuracy: 1.0\n",
      "Training loss: 0.0135633, accuracy: 0.984375\n",
      "Training loss: 0.0110112, accuracy: 1.0\n",
      "Training loss: 0.00496288, accuracy: 1.0\n",
      "Training loss: 0.00114589, accuracy: 1.0\n",
      "Training loss: 0.00455912, accuracy: 1.0\n",
      "Training loss: 0.00971225, accuracy: 1.0\n",
      "Training loss: 0.00125387, accuracy: 1.0\n",
      "Training loss: 0.160712, accuracy: 0.953125\n",
      "Training loss: 0.0108127, accuracy: 1.0\n",
      "Training loss: 0.0509996, accuracy: 0.984375\n"
     ]
    }
   ],
   "source": [
    "lstm_model.train_model(steps=1, epochs=5000, validate_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's do a test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_text1 = \"This is such a horrible movie\"\n",
    "raw_text2 = \"OMG, this is such an amazing movie. I love it!\"\n",
    "raw_text3 = \"It is okay. Not too bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97637618  0.02362388]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model.predict(raw_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7.06913113e-07   9.99999285e-01]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model.predict(raw_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99948263e-01   5.16991240e-05]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model.predict(raw_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset, label = lstm_model.data_helper.load_raw_data()\n",
    "sample_dataset = sample_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample0 = sample_dataset.review[0]\n",
    "sample1 = sample_dataset.review[1]\n",
    "sample2 = sample_dataset.review[2]\n",
    "sample3 = sample_dataset.review[3]\n",
    "\n",
    "# labels = np.array(sample_dataset.sentiment)\n",
    "# labels_onehot = np.zeros((labels.shape[0], 2))\n",
    "# labels_onehot[np.arange(len(labels_onehot)), labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.56751173e-12   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model.predict(sample0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.14126025e-12   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model.predict(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   2.98706226e-10]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model.predict(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99745905e-01   2.54134357e-04]]\n"
     ]
    }
   ],
   "source": [
    "lstm_model.predict(sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
