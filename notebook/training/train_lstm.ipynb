{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import autoreload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.lstm import lstm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data exists, load directly from pickle file\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_classifier(num_wds=200, \n",
    "                        embed_size=300,\n",
    "                        lstm_size=128, \n",
    "                        dense_size=[1024, 256], \n",
    "                        class_num=2, \n",
    "                        learning_rate=0.0003,\n",
    "                        batch_size=256, \n",
    "                        root_dir=module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sample, y_sample = lstm_model.data_helper.get_next_batch(epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.01816, accuracy: 0.515625\n",
      "Training loss: 0.918369, accuracy: 0.507813\n",
      "Training loss: 0.842667, accuracy: 0.535156\n",
      "Training loss: 0.814327, accuracy: 0.546875\n",
      "Training loss: 0.73459, accuracy: 0.578125\n",
      "Training loss: 0.756917, accuracy: 0.542969\n",
      "Training loss: 0.841825, accuracy: 0.507813\n",
      "Training loss: 0.685669, accuracy: 0.566406\n",
      "Training loss: 0.750649, accuracy: 0.542969\n",
      "Training loss: 0.680109, accuracy: 0.609375\n",
      "Training loss: 0.663383, accuracy: 0.566406\n",
      "Training loss: 0.698709, accuracy: 0.59375\n",
      "Training loss: 0.702809, accuracy: 0.59375\n",
      "Training loss: 0.736316, accuracy: 0.527344\n",
      "Training loss: 0.726636, accuracy: 0.542969\n",
      "Training loss: 0.702456, accuracy: 0.578125\n",
      "----------------- Step 0: validation accuracy 0.50128 ----------------\n",
      "Training loss: 0.826364, accuracy: 0.523438\n",
      "Training loss: 0.796337, accuracy: 0.546875\n",
      "Training loss: 0.769928, accuracy: 0.558594\n",
      "Training loss: 0.692682, accuracy: 0.597656\n",
      "Training loss: 0.697924, accuracy: 0.589844\n",
      "Training loss: 0.771285, accuracy: 0.511719\n",
      "Training loss: 0.700412, accuracy: 0.589844\n",
      "Training loss: 0.724203, accuracy: 0.527344\n",
      "Training loss: 0.683297, accuracy: 0.578125\n",
      "Training loss: 0.656521, accuracy: 0.601563\n",
      "Training loss: 0.679257, accuracy: 0.609375\n",
      "Training loss: 0.720248, accuracy: 0.519531\n",
      "Training loss: 0.698686, accuracy: 0.574219\n",
      "Training loss: 0.66083, accuracy: 0.597656\n",
      "Training loss: 0.683832, accuracy: 0.585938\n",
      "Training loss: 0.638923, accuracy: 0.628906\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 1.00927, accuracy: 0.429688\n",
      "Training loss: 0.879194, accuracy: 0.480469\n",
      "Training loss: 0.858254, accuracy: 0.496094\n",
      "Training loss: 0.784537, accuracy: 0.503906\n",
      "Training loss: 0.760123, accuracy: 0.480469\n",
      "Training loss: 0.742982, accuracy: 0.535156\n",
      "Training loss: 0.645726, accuracy: 0.621094\n",
      "Training loss: 0.668587, accuracy: 0.566406\n",
      "Training loss: 0.652964, accuracy: 0.574219\n",
      "Training loss: 0.692946, accuracy: 0.527344\n",
      "Training loss: 0.630324, accuracy: 0.621094\n",
      "Training loss: 0.673875, accuracy: 0.511719\n",
      "Training loss: 0.678629, accuracy: 0.558594\n",
      "Training loss: 0.653084, accuracy: 0.566406\n",
      "Training loss: 0.671027, accuracy: 0.542969\n",
      "Training loss: 0.683, accuracy: 0.539063\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.938539, accuracy: 0.472656\n",
      "Training loss: 0.888941, accuracy: 0.496094\n",
      "Training loss: 0.798488, accuracy: 0.554688\n",
      "Training loss: 0.798725, accuracy: 0.511719\n",
      "Training loss: 0.743446, accuracy: 0.542969\n",
      "Training loss: 0.731718, accuracy: 0.5625\n",
      "Training loss: 0.7149, accuracy: 0.503906\n",
      "Training loss: 0.64908, accuracy: 0.582031\n",
      "Training loss: 0.63579, accuracy: 0.566406\n",
      "Training loss: 0.680239, accuracy: 0.535156\n",
      "Training loss: 0.63797, accuracy: 0.570313\n",
      "Training loss: 0.653788, accuracy: 0.542969\n",
      "Training loss: 0.629506, accuracy: 0.597656\n",
      "Training loss: 0.629815, accuracy: 0.617188\n",
      "Training loss: 0.628805, accuracy: 0.589844\n",
      "Training loss: 0.647524, accuracy: 0.558594\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.812959, accuracy: 0.527344\n",
      "Training loss: 0.792745, accuracy: 0.492188\n",
      "Training loss: 0.758439, accuracy: 0.539063\n",
      "Training loss: 0.709895, accuracy: 0.5625\n",
      "Training loss: 0.686614, accuracy: 0.546875\n",
      "Training loss: 0.684985, accuracy: 0.53125\n",
      "Training loss: 0.667281, accuracy: 0.570313\n",
      "Training loss: 0.659389, accuracy: 0.566406\n",
      "Training loss: 0.68944, accuracy: 0.546875\n",
      "Training loss: 0.670856, accuracy: 0.5625\n",
      "Training loss: 0.660278, accuracy: 0.566406\n",
      "Training loss: 0.637894, accuracy: 0.613281\n",
      "Training loss: 0.6662, accuracy: 0.5625\n",
      "Training loss: 0.610577, accuracy: 0.613281\n",
      "Training loss: 0.646487, accuracy: 0.59375\n",
      "Training loss: 0.651993, accuracy: 0.566406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.928539, accuracy: 0.464844\n",
      "Training loss: 0.90535, accuracy: 0.496094\n",
      "Training loss: 0.827713, accuracy: 0.507813\n",
      "Training loss: 0.782052, accuracy: 0.527344\n",
      "Training loss: 0.661437, accuracy: 0.59375\n",
      "Training loss: 0.645244, accuracy: 0.617188\n",
      "Training loss: 0.671949, accuracy: 0.558594\n",
      "Training loss: 0.695453, accuracy: 0.53125\n",
      "Training loss: 0.686428, accuracy: 0.515625\n",
      "Training loss: 0.661005, accuracy: 0.558594\n",
      "Training loss: 0.634765, accuracy: 0.570313\n",
      "Training loss: 0.636875, accuracy: 0.59375\n",
      "Training loss: 0.619294, accuracy: 0.601563\n",
      "Training loss: 0.628838, accuracy: 0.589844\n",
      "Training loss: 0.635911, accuracy: 0.585938\n",
      "Training loss: 0.629662, accuracy: 0.585938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.833619, accuracy: 0.472656\n",
      "Training loss: 0.773292, accuracy: 0.496094\n",
      "Training loss: 0.772609, accuracy: 0.535156\n",
      "Training loss: 0.749195, accuracy: 0.5\n",
      "Training loss: 0.705158, accuracy: 0.546875\n",
      "Training loss: 0.635413, accuracy: 0.675781\n",
      "Training loss: 0.650029, accuracy: 0.566406\n",
      "Training loss: 0.678271, accuracy: 0.542969\n",
      "Training loss: 0.661176, accuracy: 0.566406\n",
      "Training loss: 0.66168, accuracy: 0.578125\n",
      "Training loss: 0.638142, accuracy: 0.578125\n",
      "Training loss: 0.654842, accuracy: 0.542969\n",
      "Training loss: 0.66187, accuracy: 0.550781\n",
      "Training loss: 0.64026, accuracy: 0.578125\n",
      "Training loss: 0.637901, accuracy: 0.570313\n",
      "Training loss: 0.635399, accuracy: 0.578125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.845669, accuracy: 0.46875\n",
      "Training loss: 0.804663, accuracy: 0.542969\n",
      "Training loss: 0.741164, accuracy: 0.539063\n",
      "Training loss: 0.684315, accuracy: 0.53125\n",
      "Training loss: 0.697801, accuracy: 0.542969\n",
      "Training loss: 0.686485, accuracy: 0.523438\n",
      "Training loss: 0.687428, accuracy: 0.539063\n",
      "Training loss: 0.664719, accuracy: 0.574219\n",
      "Training loss: 0.679334, accuracy: 0.542969\n",
      "Training loss: 0.660716, accuracy: 0.5625\n",
      "Training loss: 0.645413, accuracy: 0.578125\n",
      "Training loss: 0.616337, accuracy: 0.617188\n",
      "Training loss: 0.644614, accuracy: 0.582031\n",
      "Training loss: 0.667431, accuracy: 0.535156\n",
      "Training loss: 0.663478, accuracy: 0.539063\n",
      "Training loss: 0.6248, accuracy: 0.578125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.752437, accuracy: 0.53125\n",
      "Training loss: 0.762848, accuracy: 0.542969\n",
      "Training loss: 0.734339, accuracy: 0.488281\n",
      "Training loss: 0.703218, accuracy: 0.511719\n",
      "Training loss: 0.70786, accuracy: 0.542969\n",
      "Training loss: 0.684847, accuracy: 0.507813\n",
      "Training loss: 0.661955, accuracy: 0.585938\n",
      "Training loss: 0.670954, accuracy: 0.546875\n",
      "Training loss: 0.664386, accuracy: 0.527344\n",
      "Training loss: 0.634585, accuracy: 0.570313\n",
      "Training loss: 0.626303, accuracy: 0.597656\n",
      "Training loss: 0.620201, accuracy: 0.585938\n",
      "Training loss: 0.622616, accuracy: 0.597656\n",
      "Training loss: 0.647176, accuracy: 0.558594\n",
      "Training loss: 0.625692, accuracy: 0.566406\n",
      "Training loss: 0.606717, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.838072, accuracy: 0.546875\n",
      "Training loss: 0.859327, accuracy: 0.542969\n",
      "Training loss: 0.854061, accuracy: 0.460938\n",
      "Training loss: 0.728124, accuracy: 0.515625\n",
      "Training loss: 0.728614, accuracy: 0.511719\n",
      "Training loss: 0.728369, accuracy: 0.53125\n",
      "Training loss: 0.68704, accuracy: 0.511719\n",
      "Training loss: 0.655509, accuracy: 0.570313\n",
      "Training loss: 0.647866, accuracy: 0.554688\n",
      "Training loss: 0.621696, accuracy: 0.589844\n",
      "Training loss: 0.644448, accuracy: 0.558594\n",
      "Training loss: 0.631059, accuracy: 0.5625\n",
      "Training loss: 0.638572, accuracy: 0.550781\n",
      "Training loss: 0.599815, accuracy: 0.628906\n",
      "Training loss: 0.625356, accuracy: 0.59375\n",
      "Training loss: 0.626111, accuracy: 0.558594\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.755798, accuracy: 0.507813\n",
      "Training loss: 0.802211, accuracy: 0.492188\n",
      "Training loss: 0.74388, accuracy: 0.492188\n",
      "Training loss: 0.683189, accuracy: 0.542969\n",
      "Training loss: 0.659757, accuracy: 0.597656\n",
      "Training loss: 0.674181, accuracy: 0.527344\n",
      "Training loss: 0.65614, accuracy: 0.546875\n",
      "Training loss: 0.618076, accuracy: 0.613281\n",
      "Training loss: 0.645198, accuracy: 0.523438\n",
      "Training loss: 0.632916, accuracy: 0.578125\n",
      "Training loss: 0.641914, accuracy: 0.535156\n",
      "Training loss: 0.618053, accuracy: 0.570313\n",
      "Training loss: 0.658596, accuracy: 0.519531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.648238, accuracy: 0.535156\n",
      "Training loss: 0.641222, accuracy: 0.582031\n",
      "Training loss: 0.607291, accuracy: 0.589844\n",
      "----------------- Step 10: validation accuracy 0.4976 ----------------\n",
      "Training loss: 0.832243, accuracy: 0.5\n",
      "Training loss: 0.804576, accuracy: 0.460938\n",
      "Training loss: 0.775878, accuracy: 0.484375\n",
      "Training loss: 0.714721, accuracy: 0.519531\n",
      "Training loss: 0.695977, accuracy: 0.589844\n",
      "Training loss: 0.655805, accuracy: 0.589844\n",
      "Training loss: 0.638295, accuracy: 0.5625\n",
      "Training loss: 0.655834, accuracy: 0.578125\n",
      "Training loss: 0.625439, accuracy: 0.589844\n",
      "Training loss: 0.643956, accuracy: 0.566406\n",
      "Training loss: 0.636214, accuracy: 0.570313\n",
      "Training loss: 0.636146, accuracy: 0.582031\n",
      "Training loss: 0.656763, accuracy: 0.5625\n",
      "Training loss: 0.628093, accuracy: 0.574219\n",
      "Training loss: 0.619479, accuracy: 0.605469\n",
      "Training loss: 0.609952, accuracy: 0.605469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.800247, accuracy: 0.558594\n",
      "Training loss: 0.799401, accuracy: 0.582031\n",
      "Training loss: 0.761355, accuracy: 0.511719\n",
      "Training loss: 0.726388, accuracy: 0.519531\n",
      "Training loss: 0.672603, accuracy: 0.542969\n",
      "Training loss: 0.675486, accuracy: 0.550781\n",
      "Training loss: 0.635341, accuracy: 0.605469\n",
      "Training loss: 0.648703, accuracy: 0.554688\n",
      "Training loss: 0.637355, accuracy: 0.527344\n",
      "Training loss: 0.648207, accuracy: 0.542969\n",
      "Training loss: 0.617283, accuracy: 0.605469\n",
      "Training loss: 0.609166, accuracy: 0.605469\n",
      "Training loss: 0.626446, accuracy: 0.585938\n",
      "Training loss: 0.627099, accuracy: 0.574219\n",
      "Training loss: 0.634105, accuracy: 0.558594\n",
      "Training loss: 0.619382, accuracy: 0.566406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.860674, accuracy: 0.410156\n",
      "Training loss: 0.794655, accuracy: 0.511719\n",
      "Training loss: 0.778952, accuracy: 0.4375\n",
      "Training loss: 0.708125, accuracy: 0.5625\n",
      "Training loss: 0.695342, accuracy: 0.550781\n",
      "Training loss: 0.647813, accuracy: 0.605469\n",
      "Training loss: 0.627107, accuracy: 0.59375\n",
      "Training loss: 0.650099, accuracy: 0.5625\n",
      "Training loss: 0.638321, accuracy: 0.554688\n",
      "Training loss: 0.635116, accuracy: 0.609375\n",
      "Training loss: 0.640438, accuracy: 0.558594\n",
      "Training loss: 0.636751, accuracy: 0.589844\n",
      "Training loss: 0.665527, accuracy: 0.546875\n",
      "Training loss: 0.652331, accuracy: 0.550781\n",
      "Training loss: 0.64854, accuracy: 0.554688\n",
      "Training loss: 0.630491, accuracy: 0.558594\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.851068, accuracy: 0.496094\n",
      "Training loss: 0.836628, accuracy: 0.515625\n",
      "Training loss: 0.811488, accuracy: 0.460938\n",
      "Training loss: 0.74955, accuracy: 0.492188\n",
      "Training loss: 0.745193, accuracy: 0.507813\n",
      "Training loss: 0.695259, accuracy: 0.492188\n",
      "Training loss: 0.653329, accuracy: 0.542969\n",
      "Training loss: 0.645148, accuracy: 0.605469\n",
      "Training loss: 0.641008, accuracy: 0.566406\n",
      "Training loss: 0.63379, accuracy: 0.53125\n",
      "Training loss: 0.626856, accuracy: 0.582031\n",
      "Training loss: 0.612091, accuracy: 0.613281\n",
      "Training loss: 0.626751, accuracy: 0.597656\n",
      "Training loss: 0.629316, accuracy: 0.546875\n",
      "Training loss: 0.614689, accuracy: 0.570313\n",
      "Training loss: 0.615179, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.854608, accuracy: 0.453125\n",
      "Training loss: 0.813984, accuracy: 0.472656\n",
      "Training loss: 0.769985, accuracy: 0.515625\n",
      "Training loss: 0.702197, accuracy: 0.546875\n",
      "Training loss: 0.674846, accuracy: 0.574219\n",
      "Training loss: 0.662976, accuracy: 0.605469\n",
      "Training loss: 0.653676, accuracy: 0.558594\n",
      "Training loss: 0.634018, accuracy: 0.558594\n",
      "Training loss: 0.623044, accuracy: 0.578125\n",
      "Training loss: 0.622251, accuracy: 0.578125\n",
      "Training loss: 0.587437, accuracy: 0.585938\n",
      "Training loss: 0.598887, accuracy: 0.585938\n",
      "Training loss: 0.60044, accuracy: 0.601563\n",
      "Training loss: 0.604184, accuracy: 0.59375\n",
      "Training loss: 0.584926, accuracy: 0.601563\n",
      "Training loss: 0.619721, accuracy: 0.53125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.843206, accuracy: 0.453125\n",
      "Training loss: 0.816147, accuracy: 0.472656\n",
      "Training loss: 0.773218, accuracy: 0.496094\n",
      "Training loss: 0.73263, accuracy: 0.503906\n",
      "Training loss: 0.702399, accuracy: 0.523438\n",
      "Training loss: 0.682711, accuracy: 0.515625\n",
      "Training loss: 0.663409, accuracy: 0.519531\n",
      "Training loss: 0.652874, accuracy: 0.53125\n",
      "Training loss: 0.62628, accuracy: 0.585938\n",
      "Training loss: 0.628644, accuracy: 0.558594\n",
      "Training loss: 0.623615, accuracy: 0.574219\n",
      "Training loss: 0.620848, accuracy: 0.566406\n",
      "Training loss: 0.603493, accuracy: 0.601563\n",
      "Training loss: 0.607604, accuracy: 0.609375\n",
      "Training loss: 0.604655, accuracy: 0.589844\n",
      "Training loss: 0.61069, accuracy: 0.597656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.821164, accuracy: 0.449219\n",
      "Training loss: 0.790147, accuracy: 0.441406\n",
      "Training loss: 0.759652, accuracy: 0.5\n",
      "Training loss: 0.740622, accuracy: 0.496094\n",
      "Training loss: 0.711302, accuracy: 0.507813\n",
      "Training loss: 0.690301, accuracy: 0.519531\n",
      "Training loss: 0.651852, accuracy: 0.5625\n",
      "Training loss: 0.646525, accuracy: 0.5625\n",
      "Training loss: 0.632791, accuracy: 0.570313\n",
      "Training loss: 0.62282, accuracy: 0.585938\n",
      "Training loss: 0.610144, accuracy: 0.585938\n",
      "Training loss: 0.611909, accuracy: 0.605469\n",
      "Training loss: 0.61714, accuracy: 0.550781\n",
      "Training loss: 0.642374, accuracy: 0.511719\n",
      "Training loss: 0.628158, accuracy: 0.527344\n",
      "Training loss: 0.623383, accuracy: 0.574219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.769016, accuracy: 0.527344\n",
      "Training loss: 0.754905, accuracy: 0.5\n",
      "Training loss: 0.706707, accuracy: 0.527344\n",
      "Training loss: 0.70305, accuracy: 0.5\n",
      "Training loss: 0.667655, accuracy: 0.527344\n",
      "Training loss: 0.652757, accuracy: 0.523438\n",
      "Training loss: 0.64048, accuracy: 0.566406\n",
      "Training loss: 0.627977, accuracy: 0.546875\n",
      "Training loss: 0.625288, accuracy: 0.605469\n",
      "Training loss: 0.631036, accuracy: 0.542969\n",
      "Training loss: 0.618211, accuracy: 0.539063\n",
      "Training loss: 0.610267, accuracy: 0.550781\n",
      "Training loss: 0.62031, accuracy: 0.554688\n",
      "Training loss: 0.622936, accuracy: 0.527344\n",
      "Training loss: 0.632703, accuracy: 0.492188\n",
      "Training loss: 0.608123, accuracy: 0.554688\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.846516, accuracy: 0.496094\n",
      "Training loss: 0.803707, accuracy: 0.484375\n",
      "Training loss: 0.821553, accuracy: 0.53125\n",
      "Training loss: 0.745786, accuracy: 0.515625\n",
      "Training loss: 0.720192, accuracy: 0.53125\n",
      "Training loss: 0.694348, accuracy: 0.558594\n",
      "Training loss: 0.649355, accuracy: 0.574219\n",
      "Training loss: 0.601832, accuracy: 0.589844\n",
      "Training loss: 0.612025, accuracy: 0.625\n",
      "Training loss: 0.607344, accuracy: 0.628906\n",
      "Training loss: 0.607403, accuracy: 0.617188\n",
      "Training loss: 0.602786, accuracy: 0.621094\n",
      "Training loss: 0.600474, accuracy: 0.574219\n",
      "Training loss: 0.614949, accuracy: 0.546875\n",
      "Training loss: 0.597297, accuracy: 0.566406\n",
      "Training loss: 0.593425, accuracy: 0.585938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.747782, accuracy: 0.59375\n",
      "Training loss: 0.715326, accuracy: 0.550781\n",
      "Training loss: 0.720465, accuracy: 0.515625\n",
      "Training loss: 0.68691, accuracy: 0.566406\n",
      "Training loss: 0.691825, accuracy: 0.507813\n",
      "Training loss: 0.656017, accuracy: 0.578125\n",
      "Training loss: 0.638748, accuracy: 0.5\n",
      "Training loss: 0.626924, accuracy: 0.550781\n",
      "Training loss: 0.605038, accuracy: 0.589844\n",
      "Training loss: 0.621003, accuracy: 0.554688\n",
      "Training loss: 0.616718, accuracy: 0.539063\n",
      "Training loss: 0.614864, accuracy: 0.546875\n",
      "Training loss: 0.609263, accuracy: 0.570313\n",
      "Training loss: 0.611383, accuracy: 0.546875\n",
      "Training loss: 0.613569, accuracy: 0.53125\n",
      "Training loss: 0.609409, accuracy: 0.53125\n",
      "----------------- Step 20: validation accuracy 0.5016 ----------------\n",
      "Training loss: 0.739214, accuracy: 0.542969\n",
      "Training loss: 0.723191, accuracy: 0.484375\n",
      "Training loss: 0.732389, accuracy: 0.539063\n",
      "Training loss: 0.674498, accuracy: 0.527344\n",
      "Training loss: 0.669123, accuracy: 0.542969\n",
      "Training loss: 0.641739, accuracy: 0.539063\n",
      "Training loss: 0.628462, accuracy: 0.589844\n",
      "Training loss: 0.623857, accuracy: 0.582031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.617662, accuracy: 0.570313\n",
      "Training loss: 0.637394, accuracy: 0.539063\n",
      "Training loss: 0.598809, accuracy: 0.574219\n",
      "Training loss: 0.611819, accuracy: 0.582031\n",
      "Training loss: 0.59907, accuracy: 0.628906\n",
      "Training loss: 0.59249, accuracy: 0.605469\n",
      "Training loss: 0.599972, accuracy: 0.59375\n",
      "Training loss: 0.617262, accuracy: 0.53125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.78684, accuracy: 0.507813\n",
      "Training loss: 0.752437, accuracy: 0.546875\n",
      "Training loss: 0.702767, accuracy: 0.527344\n",
      "Training loss: 0.693748, accuracy: 0.542969\n",
      "Training loss: 0.682077, accuracy: 0.535156\n",
      "Training loss: 0.640756, accuracy: 0.539063\n",
      "Training loss: 0.640818, accuracy: 0.53125\n",
      "Training loss: 0.600746, accuracy: 0.621094\n",
      "Training loss: 0.600947, accuracy: 0.625\n",
      "Training loss: 0.589992, accuracy: 0.601563\n",
      "Training loss: 0.588353, accuracy: 0.632813\n",
      "Training loss: 0.595728, accuracy: 0.570313\n",
      "Training loss: 0.584116, accuracy: 0.632813\n",
      "Training loss: 0.60411, accuracy: 0.566406\n",
      "Training loss: 0.589932, accuracy: 0.59375\n",
      "Training loss: 0.595134, accuracy: 0.582031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.818156, accuracy: 0.472656\n",
      "Training loss: 0.777662, accuracy: 0.496094\n",
      "Training loss: 0.745299, accuracy: 0.464844\n",
      "Training loss: 0.716565, accuracy: 0.523438\n",
      "Training loss: 0.681111, accuracy: 0.535156\n",
      "Training loss: 0.661713, accuracy: 0.527344\n",
      "Training loss: 0.631289, accuracy: 0.5625\n",
      "Training loss: 0.609756, accuracy: 0.589844\n",
      "Training loss: 0.60348, accuracy: 0.578125\n",
      "Training loss: 0.592607, accuracy: 0.613281\n",
      "Training loss: 0.589867, accuracy: 0.644531\n",
      "Training loss: 0.599544, accuracy: 0.636719\n",
      "Training loss: 0.588961, accuracy: 0.632813\n",
      "Training loss: 0.581846, accuracy: 0.640625\n",
      "Training loss: 0.595731, accuracy: 0.621094\n",
      "Training loss: 0.576246, accuracy: 0.640625\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.826534, accuracy: 0.507813\n",
      "Training loss: 0.784525, accuracy: 0.480469\n",
      "Training loss: 0.767875, accuracy: 0.53125\n",
      "Training loss: 0.705302, accuracy: 0.570313\n",
      "Training loss: 0.708452, accuracy: 0.527344\n",
      "Training loss: 0.687996, accuracy: 0.554688\n",
      "Training loss: 0.62309, accuracy: 0.597656\n",
      "Training loss: 0.617555, accuracy: 0.558594\n",
      "Training loss: 0.606775, accuracy: 0.597656\n",
      "Training loss: 0.624804, accuracy: 0.558594\n",
      "Training loss: 0.608198, accuracy: 0.59375\n",
      "Training loss: 0.611984, accuracy: 0.574219\n",
      "Training loss: 0.615204, accuracy: 0.574219\n",
      "Training loss: 0.615258, accuracy: 0.578125\n",
      "Training loss: 0.60939, accuracy: 0.5625\n",
      "Training loss: 0.616087, accuracy: 0.53125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.771876, accuracy: 0.539063\n",
      "Training loss: 0.787018, accuracy: 0.585938\n",
      "Training loss: 0.767713, accuracy: 0.523438\n",
      "Training loss: 0.726396, accuracy: 0.53125\n",
      "Training loss: 0.683071, accuracy: 0.53125\n",
      "Training loss: 0.691593, accuracy: 0.503906\n",
      "Training loss: 0.634907, accuracy: 0.566406\n",
      "Training loss: 0.634759, accuracy: 0.5625\n",
      "Training loss: 0.622237, accuracy: 0.640625\n",
      "Training loss: 0.611308, accuracy: 0.511719\n",
      "Training loss: 0.615155, accuracy: 0.542969\n",
      "Training loss: 0.608984, accuracy: 0.578125\n",
      "Training loss: 0.603937, accuracy: 0.582031\n",
      "Training loss: 0.614556, accuracy: 0.523438\n",
      "Training loss: 0.595015, accuracy: 0.585938\n",
      "Training loss: 0.598207, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.846694, accuracy: 0.5\n",
      "Training loss: 0.852847, accuracy: 0.5\n",
      "Training loss: 0.776316, accuracy: 0.523438\n",
      "Training loss: 0.743162, accuracy: 0.476563\n",
      "Training loss: 0.724052, accuracy: 0.511719\n",
      "Training loss: 0.674686, accuracy: 0.527344\n",
      "Training loss: 0.64372, accuracy: 0.558594\n",
      "Training loss: 0.642712, accuracy: 0.535156\n",
      "Training loss: 0.650376, accuracy: 0.492188\n",
      "Training loss: 0.647223, accuracy: 0.519531\n",
      "Training loss: 0.635732, accuracy: 0.527344\n",
      "Training loss: 0.619923, accuracy: 0.5625\n",
      "Training loss: 0.62532, accuracy: 0.515625\n",
      "Training loss: 0.624337, accuracy: 0.535156\n",
      "Training loss: 0.615961, accuracy: 0.550781\n",
      "Training loss: 0.61742, accuracy: 0.523438\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.775491, accuracy: 0.519531\n",
      "Training loss: 0.771626, accuracy: 0.5\n",
      "Training loss: 0.761407, accuracy: 0.480469\n",
      "Training loss: 0.714691, accuracy: 0.570313\n",
      "Training loss: 0.688378, accuracy: 0.554688\n",
      "Training loss: 0.673288, accuracy: 0.535156\n",
      "Training loss: 0.667795, accuracy: 0.492188\n",
      "Training loss: 0.640571, accuracy: 0.523438\n",
      "Training loss: 0.623762, accuracy: 0.558594\n",
      "Training loss: 0.619305, accuracy: 0.527344\n",
      "Training loss: 0.606519, accuracy: 0.589844\n",
      "Training loss: 0.5985, accuracy: 0.617188\n",
      "Training loss: 0.617609, accuracy: 0.574219\n",
      "Training loss: 0.600651, accuracy: 0.589844\n",
      "Training loss: 0.611917, accuracy: 0.582031\n",
      "Training loss: 0.611238, accuracy: 0.582031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.825279, accuracy: 0.527344\n",
      "Training loss: 0.810317, accuracy: 0.476563\n",
      "Training loss: 0.775161, accuracy: 0.578125\n",
      "Training loss: 0.745277, accuracy: 0.535156\n",
      "Training loss: 0.688982, accuracy: 0.589844\n",
      "Training loss: 0.662703, accuracy: 0.582031\n",
      "Training loss: 0.655073, accuracy: 0.519531\n",
      "Training loss: 0.632848, accuracy: 0.613281\n",
      "Training loss: 0.620133, accuracy: 0.5625\n",
      "Training loss: 0.580725, accuracy: 0.707031\n",
      "Training loss: 0.598518, accuracy: 0.621094\n",
      "Training loss: 0.592881, accuracy: 0.550781\n",
      "Training loss: 0.595579, accuracy: 0.59375\n",
      "Training loss: 0.585992, accuracy: 0.574219\n",
      "Training loss: 0.578427, accuracy: 0.625\n",
      "Training loss: 0.595965, accuracy: 0.535156\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.796013, accuracy: 0.515625\n",
      "Training loss: 0.763867, accuracy: 0.488281\n",
      "Training loss: 0.754975, accuracy: 0.527344\n",
      "Training loss: 0.769141, accuracy: 0.472656\n",
      "Training loss: 0.698021, accuracy: 0.546875\n",
      "Training loss: 0.690015, accuracy: 0.546875\n",
      "Training loss: 0.677091, accuracy: 0.511719\n",
      "Training loss: 0.639555, accuracy: 0.628906\n",
      "Training loss: 0.638948, accuracy: 0.574219\n",
      "Training loss: 0.632369, accuracy: 0.558594\n",
      "Training loss: 0.63778, accuracy: 0.523438\n",
      "Training loss: 0.628824, accuracy: 0.570313\n",
      "Training loss: 0.612708, accuracy: 0.601563\n",
      "Training loss: 0.630136, accuracy: 0.53125\n",
      "Training loss: 0.615939, accuracy: 0.582031\n",
      "Training loss: 0.611491, accuracy: 0.601563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.752347, accuracy: 0.527344\n",
      "Training loss: 0.741143, accuracy: 0.550781\n",
      "Training loss: 0.73772, accuracy: 0.488281\n",
      "Training loss: 0.705016, accuracy: 0.546875\n",
      "Training loss: 0.670604, accuracy: 0.566406\n",
      "Training loss: 0.659349, accuracy: 0.566406\n",
      "Training loss: 0.656092, accuracy: 0.5625\n",
      "Training loss: 0.625765, accuracy: 0.566406\n",
      "Training loss: 0.63164, accuracy: 0.585938\n",
      "Training loss: 0.628866, accuracy: 0.554688\n",
      "Training loss: 0.627617, accuracy: 0.570313\n",
      "Training loss: 0.633911, accuracy: 0.566406\n",
      "Training loss: 0.648335, accuracy: 0.527344\n",
      "Training loss: 0.622982, accuracy: 0.585938\n",
      "Training loss: 0.619789, accuracy: 0.597656\n",
      "Training loss: 0.624223, accuracy: 0.566406\n",
      "----------------- Step 30: validation accuracy 0.50336 ----------------\n",
      "Training loss: 0.789043, accuracy: 0.542969\n",
      "Training loss: 0.792721, accuracy: 0.507813\n",
      "Training loss: 0.754432, accuracy: 0.507813\n",
      "Training loss: 0.742517, accuracy: 0.535156\n",
      "Training loss: 0.70158, accuracy: 0.527344\n",
      "Training loss: 0.68383, accuracy: 0.570313\n",
      "Training loss: 0.660373, accuracy: 0.558594\n",
      "Training loss: 0.639605, accuracy: 0.5625\n",
      "Training loss: 0.631211, accuracy: 0.609375\n",
      "Training loss: 0.616398, accuracy: 0.582031\n",
      "Training loss: 0.631926, accuracy: 0.546875\n",
      "Training loss: 0.617767, accuracy: 0.597656\n",
      "Training loss: 0.632813, accuracy: 0.582031\n",
      "Training loss: 0.606229, accuracy: 0.585938\n",
      "Training loss: 0.612868, accuracy: 0.59375\n",
      "Training loss: 0.619853, accuracy: 0.578125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.768952, accuracy: 0.515625\n",
      "Training loss: 0.761001, accuracy: 0.5\n",
      "Training loss: 0.769138, accuracy: 0.460938\n",
      "Training loss: 0.728166, accuracy: 0.496094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.738568, accuracy: 0.464844\n",
      "Training loss: 0.696092, accuracy: 0.511719\n",
      "Training loss: 0.656619, accuracy: 0.570313\n",
      "Training loss: 0.648701, accuracy: 0.546875\n",
      "Training loss: 0.643969, accuracy: 0.53125\n",
      "Training loss: 0.640159, accuracy: 0.519531\n",
      "Training loss: 0.628537, accuracy: 0.523438\n",
      "Training loss: 0.633575, accuracy: 0.527344\n",
      "Training loss: 0.628329, accuracy: 0.546875\n",
      "Training loss: 0.619049, accuracy: 0.539063\n",
      "Training loss: 0.609351, accuracy: 0.582031\n",
      "Training loss: 0.615093, accuracy: 0.582031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.790883, accuracy: 0.515625\n",
      "Training loss: 0.760193, accuracy: 0.507813\n",
      "Training loss: 0.744402, accuracy: 0.492188\n",
      "Training loss: 0.722316, accuracy: 0.546875\n",
      "Training loss: 0.689994, accuracy: 0.535156\n",
      "Training loss: 0.679346, accuracy: 0.503906\n",
      "Training loss: 0.645137, accuracy: 0.589844\n",
      "Training loss: 0.641281, accuracy: 0.53125\n",
      "Training loss: 0.642933, accuracy: 0.488281\n",
      "Training loss: 0.627798, accuracy: 0.5625\n",
      "Training loss: 0.621184, accuracy: 0.550781\n",
      "Training loss: 0.607333, accuracy: 0.5625\n",
      "Training loss: 0.59873, accuracy: 0.609375\n",
      "Training loss: 0.630807, accuracy: 0.558594\n",
      "Training loss: 0.614023, accuracy: 0.566406\n",
      "Training loss: 0.612765, accuracy: 0.5625\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.736049, accuracy: 0.492188\n",
      "Training loss: 0.728359, accuracy: 0.488281\n",
      "Training loss: 0.704829, accuracy: 0.539063\n",
      "Training loss: 0.70585, accuracy: 0.507813\n",
      "Training loss: 0.665866, accuracy: 0.558594\n",
      "Training loss: 0.655579, accuracy: 0.558594\n",
      "Training loss: 0.623553, accuracy: 0.617188\n",
      "Training loss: 0.639321, accuracy: 0.613281\n",
      "Training loss: 0.620567, accuracy: 0.613281\n",
      "Training loss: 0.615224, accuracy: 0.636719\n",
      "Training loss: 0.629779, accuracy: 0.609375\n",
      "Training loss: 0.613965, accuracy: 0.574219\n",
      "Training loss: 0.609749, accuracy: 0.625\n",
      "Training loss: 0.617189, accuracy: 0.597656\n",
      "Training loss: 0.616358, accuracy: 0.5625\n",
      "Training loss: 0.607008, accuracy: 0.597656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.800121, accuracy: 0.472656\n",
      "Training loss: 0.785756, accuracy: 0.484375\n",
      "Training loss: 0.776627, accuracy: 0.46875\n",
      "Training loss: 0.726641, accuracy: 0.503906\n",
      "Training loss: 0.706131, accuracy: 0.484375\n",
      "Training loss: 0.683151, accuracy: 0.539063\n",
      "Training loss: 0.678544, accuracy: 0.515625\n",
      "Training loss: 0.640941, accuracy: 0.527344\n",
      "Training loss: 0.642463, accuracy: 0.554688\n",
      "Training loss: 0.621202, accuracy: 0.574219\n",
      "Training loss: 0.62754, accuracy: 0.558594\n",
      "Training loss: 0.609678, accuracy: 0.585938\n",
      "Training loss: 0.603166, accuracy: 0.597656\n",
      "Training loss: 0.606029, accuracy: 0.574219\n",
      "Training loss: 0.613593, accuracy: 0.558594\n",
      "Training loss: 0.620543, accuracy: 0.515625\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.692924, accuracy: 0.519531\n",
      "Training loss: 0.700318, accuracy: 0.511719\n",
      "Training loss: 0.67405, accuracy: 0.53125\n",
      "Training loss: 0.706504, accuracy: 0.492188\n",
      "Training loss: 0.667645, accuracy: 0.535156\n",
      "Training loss: 0.646084, accuracy: 0.601563\n",
      "Training loss: 0.653838, accuracy: 0.515625\n",
      "Training loss: 0.641918, accuracy: 0.5625\n",
      "Training loss: 0.634925, accuracy: 0.574219\n",
      "Training loss: 0.634477, accuracy: 0.5625\n",
      "Training loss: 0.622321, accuracy: 0.546875\n",
      "Training loss: 0.629135, accuracy: 0.542969\n",
      "Training loss: 0.622909, accuracy: 0.578125\n",
      "Training loss: 0.610511, accuracy: 0.597656\n",
      "Training loss: 0.617308, accuracy: 0.597656\n",
      "Training loss: 0.622718, accuracy: 0.578125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.769247, accuracy: 0.441406\n",
      "Training loss: 0.731353, accuracy: 0.527344\n",
      "Training loss: 0.719997, accuracy: 0.523438\n",
      "Training loss: 0.706671, accuracy: 0.496094\n",
      "Training loss: 0.674609, accuracy: 0.554688\n",
      "Training loss: 0.657561, accuracy: 0.539063\n",
      "Training loss: 0.646812, accuracy: 0.558594\n",
      "Training loss: 0.633138, accuracy: 0.542969\n",
      "Training loss: 0.623359, accuracy: 0.558594\n",
      "Training loss: 0.605408, accuracy: 0.589844\n",
      "Training loss: 0.619315, accuracy: 0.542969\n",
      "Training loss: 0.607592, accuracy: 0.59375\n",
      "Training loss: 0.614129, accuracy: 0.5625\n",
      "Training loss: 0.617592, accuracy: 0.503906\n",
      "Training loss: 0.609664, accuracy: 0.539063\n",
      "Training loss: 0.609446, accuracy: 0.546875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.790778, accuracy: 0.5\n",
      "Training loss: 0.788382, accuracy: 0.511719\n",
      "Training loss: 0.738635, accuracy: 0.515625\n",
      "Training loss: 0.719402, accuracy: 0.550781\n",
      "Training loss: 0.688525, accuracy: 0.515625\n",
      "Training loss: 0.651593, accuracy: 0.542969\n",
      "Training loss: 0.642714, accuracy: 0.5\n",
      "Training loss: 0.612334, accuracy: 0.578125\n",
      "Training loss: 0.585259, accuracy: 0.652344\n",
      "Training loss: 0.594498, accuracy: 0.601563\n",
      "Training loss: 0.584114, accuracy: 0.585938\n",
      "Training loss: 0.58809, accuracy: 0.589844\n",
      "Training loss: 0.586603, accuracy: 0.574219\n",
      "Training loss: 0.586829, accuracy: 0.589844\n",
      "Training loss: 0.583561, accuracy: 0.578125\n",
      "Training loss: 0.581037, accuracy: 0.589844\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.717173, accuracy: 0.542969\n",
      "Training loss: 0.70595, accuracy: 0.5625\n",
      "Training loss: 0.711871, accuracy: 0.527344\n",
      "Training loss: 0.667568, accuracy: 0.625\n",
      "Training loss: 0.663316, accuracy: 0.574219\n",
      "Training loss: 0.638872, accuracy: 0.59375\n",
      "Training loss: 0.641639, accuracy: 0.566406\n",
      "Training loss: 0.601017, accuracy: 0.636719\n",
      "Training loss: 0.60051, accuracy: 0.578125\n",
      "Training loss: 0.599989, accuracy: 0.589844\n",
      "Training loss: 0.59426, accuracy: 0.617188\n",
      "Training loss: 0.592575, accuracy: 0.621094\n",
      "Training loss: 0.590267, accuracy: 0.628906\n",
      "Training loss: 0.588252, accuracy: 0.628906\n",
      "Training loss: 0.589573, accuracy: 0.617188\n",
      "Training loss: 0.583421, accuracy: 0.621094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.763845, accuracy: 0.5625\n",
      "Training loss: 0.774906, accuracy: 0.496094\n",
      "Training loss: 0.747477, accuracy: 0.511719\n",
      "Training loss: 0.726534, accuracy: 0.546875\n",
      "Training loss: 0.67307, accuracy: 0.5625\n",
      "Training loss: 0.647159, accuracy: 0.550781\n",
      "Training loss: 0.627818, accuracy: 0.535156\n",
      "Training loss: 0.606856, accuracy: 0.652344\n",
      "Training loss: 0.622023, accuracy: 0.535156\n",
      "Training loss: 0.61187, accuracy: 0.558594\n",
      "Training loss: 0.62081, accuracy: 0.511719\n",
      "Training loss: 0.600638, accuracy: 0.59375\n",
      "Training loss: 0.604466, accuracy: 0.578125\n",
      "Training loss: 0.609391, accuracy: 0.582031\n",
      "Training loss: 0.597452, accuracy: 0.589844\n",
      "Training loss: 0.613022, accuracy: 0.554688\n",
      "----------------- Step 40: validation accuracy 0.4952 ----------------\n",
      "Training loss: 0.760217, accuracy: 0.546875\n",
      "Training loss: 0.750306, accuracy: 0.523438\n",
      "Training loss: 0.714591, accuracy: 0.542969\n",
      "Training loss: 0.713362, accuracy: 0.519531\n",
      "Training loss: 0.688548, accuracy: 0.484375\n",
      "Training loss: 0.647885, accuracy: 0.566406\n",
      "Training loss: 0.644772, accuracy: 0.601563\n",
      "Training loss: 0.632194, accuracy: 0.527344\n",
      "Training loss: 0.601214, accuracy: 0.578125\n",
      "Training loss: 0.605878, accuracy: 0.59375\n",
      "Training loss: 0.603444, accuracy: 0.582031\n",
      "Training loss: 0.596866, accuracy: 0.566406\n",
      "Training loss: 0.598669, accuracy: 0.570313\n",
      "Training loss: 0.6092, accuracy: 0.535156\n",
      "Training loss: 0.600148, accuracy: 0.523438\n",
      "Training loss: 0.592831, accuracy: 0.625\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.754005, accuracy: 0.476563\n",
      "Training loss: 0.736825, accuracy: 0.496094\n",
      "Training loss: 0.732413, accuracy: 0.488281\n",
      "Training loss: 0.686571, accuracy: 0.511719\n",
      "Training loss: 0.685271, accuracy: 0.570313\n",
      "Training loss: 0.662634, accuracy: 0.535156\n",
      "Training loss: 0.672463, accuracy: 0.507813\n",
      "Training loss: 0.636065, accuracy: 0.5625\n",
      "Training loss: 0.635058, accuracy: 0.535156\n",
      "Training loss: 0.632384, accuracy: 0.574219\n",
      "Training loss: 0.640112, accuracy: 0.515625\n",
      "Training loss: 0.632292, accuracy: 0.566406\n",
      "Training loss: 0.626527, accuracy: 0.574219\n",
      "Training loss: 0.628969, accuracy: 0.539063\n",
      "Training loss: 0.634988, accuracy: 0.546875\n",
      "Training loss: 0.631758, accuracy: 0.527344\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.857131, accuracy: 0.480469\n",
      "Training loss: 0.817414, accuracy: 0.488281\n",
      "Training loss: 0.773166, accuracy: 0.546875\n",
      "Training loss: 0.784336, accuracy: 0.476563\n",
      "Training loss: 0.694379, accuracy: 0.5\n",
      "Training loss: 0.69154, accuracy: 0.535156\n",
      "Training loss: 0.632689, accuracy: 0.574219\n",
      "Training loss: 0.644086, accuracy: 0.554688\n",
      "Training loss: 0.615322, accuracy: 0.605469\n",
      "Training loss: 0.606988, accuracy: 0.617188\n",
      "Training loss: 0.601429, accuracy: 0.578125\n",
      "Training loss: 0.586244, accuracy: 0.613281\n",
      "Training loss: 0.578125, accuracy: 0.632813\n",
      "Training loss: 0.585207, accuracy: 0.59375\n",
      "Training loss: 0.57255, accuracy: 0.640625\n",
      "Training loss: 0.57167, accuracy: 0.589844\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.794246, accuracy: 0.558594\n",
      "Training loss: 0.805606, accuracy: 0.496094\n",
      "Training loss: 0.799787, accuracy: 0.488281\n",
      "Training loss: 0.756347, accuracy: 0.503906\n",
      "Training loss: 0.706269, accuracy: 0.484375\n",
      "Training loss: 0.68752, accuracy: 0.589844\n",
      "Training loss: 0.682352, accuracy: 0.527344\n",
      "Training loss: 0.647444, accuracy: 0.59375\n",
      "Training loss: 0.634681, accuracy: 0.5625\n",
      "Training loss: 0.637554, accuracy: 0.5625\n",
      "Training loss: 0.622529, accuracy: 0.566406\n",
      "Training loss: 0.630451, accuracy: 0.535156\n",
      "Training loss: 0.628373, accuracy: 0.5625\n",
      "Training loss: 0.631108, accuracy: 0.554688\n",
      "Training loss: 0.6296, accuracy: 0.550781\n",
      "Training loss: 0.614653, accuracy: 0.582031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.768793, accuracy: 0.445313\n",
      "Training loss: 0.725698, accuracy: 0.511719\n",
      "Training loss: 0.715295, accuracy: 0.511719\n",
      "Training loss: 0.690729, accuracy: 0.488281\n",
      "Training loss: 0.682749, accuracy: 0.5625\n",
      "Training loss: 0.648349, accuracy: 0.578125\n",
      "Training loss: 0.638269, accuracy: 0.558594\n",
      "Training loss: 0.624611, accuracy: 0.554688\n",
      "Training loss: 0.618338, accuracy: 0.542969\n",
      "Training loss: 0.609477, accuracy: 0.554688\n",
      "Training loss: 0.611606, accuracy: 0.574219\n",
      "Training loss: 0.601853, accuracy: 0.582031\n",
      "Training loss: 0.594177, accuracy: 0.59375\n",
      "Training loss: 0.58874, accuracy: 0.59375\n",
      "Training loss: 0.580384, accuracy: 0.601563\n",
      "Training loss: 0.581394, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.749401, accuracy: 0.527344\n",
      "Training loss: 0.77894, accuracy: 0.429688\n",
      "Training loss: 0.74521, accuracy: 0.480469\n",
      "Training loss: 0.728566, accuracy: 0.472656\n",
      "Training loss: 0.686209, accuracy: 0.53125\n",
      "Training loss: 0.678003, accuracy: 0.523438\n",
      "Training loss: 0.663581, accuracy: 0.496094\n",
      "Training loss: 0.629676, accuracy: 0.546875\n",
      "Training loss: 0.622935, accuracy: 0.578125\n",
      "Training loss: 0.619208, accuracy: 0.546875\n",
      "Training loss: 0.621444, accuracy: 0.542969\n",
      "Training loss: 0.61884, accuracy: 0.523438\n",
      "Training loss: 0.617239, accuracy: 0.554688\n",
      "Training loss: 0.601451, accuracy: 0.582031\n",
      "Training loss: 0.60595, accuracy: 0.535156\n",
      "Training loss: 0.602827, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.710972, accuracy: 0.507813\n",
      "Training loss: 0.719922, accuracy: 0.523438\n",
      "Training loss: 0.694112, accuracy: 0.558594\n",
      "Training loss: 0.675182, accuracy: 0.511719\n",
      "Training loss: 0.695326, accuracy: 0.535156\n",
      "Training loss: 0.664122, accuracy: 0.535156\n",
      "Training loss: 0.661138, accuracy: 0.5625\n",
      "Training loss: 0.651742, accuracy: 0.523438\n",
      "Training loss: 0.636106, accuracy: 0.574219\n",
      "Training loss: 0.635721, accuracy: 0.589844\n",
      "Training loss: 0.638168, accuracy: 0.5625\n",
      "Training loss: 0.635293, accuracy: 0.566406\n",
      "Training loss: 0.622885, accuracy: 0.59375\n",
      "Training loss: 0.624933, accuracy: 0.609375\n",
      "Training loss: 0.623204, accuracy: 0.597656\n",
      "Training loss: 0.633705, accuracy: 0.5625\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.807045, accuracy: 0.484375\n",
      "Training loss: 0.791183, accuracy: 0.484375\n",
      "Training loss: 0.75808, accuracy: 0.523438\n",
      "Training loss: 0.738365, accuracy: 0.527344\n",
      "Training loss: 0.721038, accuracy: 0.445313\n",
      "Training loss: 0.665351, accuracy: 0.625\n",
      "Training loss: 0.655102, accuracy: 0.542969\n",
      "Training loss: 0.664907, accuracy: 0.503906\n",
      "Training loss: 0.64293, accuracy: 0.535156\n",
      "Training loss: 0.643057, accuracy: 0.554688\n",
      "Training loss: 0.640241, accuracy: 0.550781\n",
      "Training loss: 0.652685, accuracy: 0.542969\n",
      "Training loss: 0.641374, accuracy: 0.535156\n",
      "Training loss: 0.645996, accuracy: 0.542969\n",
      "Training loss: 0.634259, accuracy: 0.550781\n",
      "Training loss: 0.642756, accuracy: 0.554688\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.827472, accuracy: 0.488281\n",
      "Training loss: 0.81763, accuracy: 0.488281\n",
      "Training loss: 0.796869, accuracy: 0.457031\n",
      "Training loss: 0.772367, accuracy: 0.484375\n",
      "Training loss: 0.723431, accuracy: 0.503906\n",
      "Training loss: 0.677425, accuracy: 0.5625\n",
      "Training loss: 0.660062, accuracy: 0.542969\n",
      "Training loss: 0.633507, accuracy: 0.605469\n",
      "Training loss: 0.622754, accuracy: 0.601563\n",
      "Training loss: 0.622719, accuracy: 0.582031\n",
      "Training loss: 0.616917, accuracy: 0.597656\n",
      "Training loss: 0.614857, accuracy: 0.570313\n",
      "Training loss: 0.615187, accuracy: 0.574219\n",
      "Training loss: 0.597031, accuracy: 0.640625\n",
      "Training loss: 0.601756, accuracy: 0.613281\n",
      "Training loss: 0.601529, accuracy: 0.621094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.734554, accuracy: 0.480469\n",
      "Training loss: 0.707056, accuracy: 0.460938\n",
      "Training loss: 0.699703, accuracy: 0.519531\n",
      "Training loss: 0.695981, accuracy: 0.496094\n",
      "Training loss: 0.678623, accuracy: 0.519531\n",
      "Training loss: 0.65839, accuracy: 0.535156\n",
      "Training loss: 0.663999, accuracy: 0.507813\n",
      "Training loss: 0.635344, accuracy: 0.59375\n",
      "Training loss: 0.638142, accuracy: 0.53125\n",
      "Training loss: 0.639774, accuracy: 0.550781\n",
      "Training loss: 0.62939, accuracy: 0.582031\n",
      "Training loss: 0.629234, accuracy: 0.574219\n",
      "Training loss: 0.621511, accuracy: 0.609375\n",
      "Training loss: 0.619648, accuracy: 0.589844\n",
      "Training loss: 0.637843, accuracy: 0.515625\n",
      "Training loss: 0.636755, accuracy: 0.511719\n",
      "----------------- Step 50: validation accuracy 0.50112 ----------------\n",
      "Training loss: 0.800473, accuracy: 0.511719\n",
      "Training loss: 0.790856, accuracy: 0.527344\n",
      "Training loss: 0.783872, accuracy: 0.480469\n",
      "Training loss: 0.772642, accuracy: 0.480469\n",
      "Training loss: 0.724751, accuracy: 0.539063\n",
      "Training loss: 0.698654, accuracy: 0.523438\n",
      "Training loss: 0.675071, accuracy: 0.566406\n",
      "Training loss: 0.65067, accuracy: 0.511719\n",
      "Training loss: 0.62574, accuracy: 0.578125\n",
      "Training loss: 0.621409, accuracy: 0.601563\n",
      "Training loss: 0.620813, accuracy: 0.570313\n",
      "Training loss: 0.611248, accuracy: 0.582031\n",
      "Training loss: 0.606223, accuracy: 0.578125\n",
      "Training loss: 0.606607, accuracy: 0.613281\n",
      "Training loss: 0.609114, accuracy: 0.605469\n",
      "Training loss: 0.607967, accuracy: 0.539063\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.751487, accuracy: 0.519531\n",
      "Training loss: 0.764644, accuracy: 0.484375\n",
      "Training loss: 0.729539, accuracy: 0.46875\n",
      "Training loss: 0.717565, accuracy: 0.464844\n",
      "Training loss: 0.704925, accuracy: 0.550781\n",
      "Training loss: 0.674567, accuracy: 0.539063\n",
      "Training loss: 0.669576, accuracy: 0.519531\n",
      "Training loss: 0.657436, accuracy: 0.566406\n",
      "Training loss: 0.660747, accuracy: 0.546875\n",
      "Training loss: 0.66194, accuracy: 0.496094\n",
      "Training loss: 0.634858, accuracy: 0.566406\n",
      "Training loss: 0.62784, accuracy: 0.574219\n",
      "Training loss: 0.625241, accuracy: 0.578125\n",
      "Training loss: 0.63589, accuracy: 0.550781\n",
      "Training loss: 0.63447, accuracy: 0.574219\n",
      "Training loss: 0.642016, accuracy: 0.519531\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.745041, accuracy: 0.480469\n",
      "Training loss: 0.735772, accuracy: 0.5\n",
      "Training loss: 0.738064, accuracy: 0.441406\n",
      "Training loss: 0.724155, accuracy: 0.464844\n",
      "Training loss: 0.675913, accuracy: 0.5625\n",
      "Training loss: 0.663151, accuracy: 0.574219\n",
      "Training loss: 0.648334, accuracy: 0.554688\n",
      "Training loss: 0.653445, accuracy: 0.550781\n",
      "Training loss: 0.623809, accuracy: 0.601563\n",
      "Training loss: 0.627728, accuracy: 0.589844\n",
      "Training loss: 0.614817, accuracy: 0.625\n",
      "Training loss: 0.625301, accuracy: 0.539063\n",
      "Training loss: 0.610406, accuracy: 0.613281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.61113, accuracy: 0.585938\n",
      "Training loss: 0.6114, accuracy: 0.582031\n",
      "Training loss: 0.602708, accuracy: 0.597656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.733619, accuracy: 0.59375\n",
      "Training loss: 0.751751, accuracy: 0.496094\n",
      "Training loss: 0.720079, accuracy: 0.527344\n",
      "Training loss: 0.692604, accuracy: 0.535156\n",
      "Training loss: 0.672562, accuracy: 0.546875\n",
      "Training loss: 0.651971, accuracy: 0.527344\n",
      "Training loss: 0.648951, accuracy: 0.605469\n",
      "Training loss: 0.631764, accuracy: 0.59375\n",
      "Training loss: 0.622225, accuracy: 0.59375\n",
      "Training loss: 0.625398, accuracy: 0.546875\n",
      "Training loss: 0.620301, accuracy: 0.566406\n",
      "Training loss: 0.621417, accuracy: 0.566406\n",
      "Training loss: 0.610132, accuracy: 0.597656\n",
      "Training loss: 0.619224, accuracy: 0.5625\n",
      "Training loss: 0.598687, accuracy: 0.652344\n",
      "Training loss: 0.605271, accuracy: 0.621094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.762585, accuracy: 0.507813\n",
      "Training loss: 0.76197, accuracy: 0.492188\n",
      "Training loss: 0.744191, accuracy: 0.539063\n",
      "Training loss: 0.701175, accuracy: 0.546875\n",
      "Training loss: 0.676294, accuracy: 0.515625\n",
      "Training loss: 0.658113, accuracy: 0.542969\n",
      "Training loss: 0.63179, accuracy: 0.519531\n",
      "Training loss: 0.619293, accuracy: 0.574219\n",
      "Training loss: 0.606866, accuracy: 0.582031\n",
      "Training loss: 0.600337, accuracy: 0.566406\n",
      "Training loss: 0.593316, accuracy: 0.578125\n",
      "Training loss: 0.594717, accuracy: 0.589844\n",
      "Training loss: 0.592313, accuracy: 0.570313\n",
      "Training loss: 0.580636, accuracy: 0.609375\n",
      "Training loss: 0.58171, accuracy: 0.589844\n",
      "Training loss: 0.571623, accuracy: 0.609375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.755479, accuracy: 0.53125\n",
      "Training loss: 0.753604, accuracy: 0.511719\n",
      "Training loss: 0.739315, accuracy: 0.480469\n",
      "Training loss: 0.721905, accuracy: 0.464844\n",
      "Training loss: 0.664243, accuracy: 0.566406\n",
      "Training loss: 0.657881, accuracy: 0.535156\n",
      "Training loss: 0.646876, accuracy: 0.546875\n",
      "Training loss: 0.638758, accuracy: 0.570313\n",
      "Training loss: 0.629082, accuracy: 0.5625\n",
      "Training loss: 0.618452, accuracy: 0.582031\n",
      "Training loss: 0.600283, accuracy: 0.613281\n",
      "Training loss: 0.614596, accuracy: 0.566406\n",
      "Training loss: 0.599514, accuracy: 0.601563\n",
      "Training loss: 0.603921, accuracy: 0.597656\n",
      "Training loss: 0.605931, accuracy: 0.585938\n",
      "Training loss: 0.597778, accuracy: 0.585938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.747356, accuracy: 0.496094\n",
      "Training loss: 0.754807, accuracy: 0.5\n",
      "Training loss: 0.744941, accuracy: 0.457031\n",
      "Training loss: 0.711345, accuracy: 0.492188\n",
      "Training loss: 0.677809, accuracy: 0.5625\n",
      "Training loss: 0.669787, accuracy: 0.53125\n",
      "Training loss: 0.651539, accuracy: 0.5625\n",
      "Training loss: 0.64172, accuracy: 0.570313\n",
      "Training loss: 0.620512, accuracy: 0.597656\n",
      "Training loss: 0.626241, accuracy: 0.5625\n",
      "Training loss: 0.619066, accuracy: 0.589844\n",
      "Training loss: 0.612629, accuracy: 0.597656\n",
      "Training loss: 0.610329, accuracy: 0.609375\n",
      "Training loss: 0.609104, accuracy: 0.609375\n",
      "Training loss: 0.595375, accuracy: 0.617188\n",
      "Training loss: 0.60041, accuracy: 0.609375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.748742, accuracy: 0.554688\n",
      "Training loss: 0.758204, accuracy: 0.546875\n",
      "Training loss: 0.725698, accuracy: 0.523438\n",
      "Training loss: 0.681121, accuracy: 0.578125\n",
      "Training loss: 0.6645, accuracy: 0.585938\n",
      "Training loss: 0.65028, accuracy: 0.566406\n",
      "Training loss: 0.624455, accuracy: 0.582031\n",
      "Training loss: 0.619341, accuracy: 0.554688\n",
      "Training loss: 0.603038, accuracy: 0.601563\n",
      "Training loss: 0.601026, accuracy: 0.5625\n",
      "Training loss: 0.599484, accuracy: 0.578125\n",
      "Training loss: 0.583242, accuracy: 0.613281\n",
      "Training loss: 0.584087, accuracy: 0.597656\n",
      "Training loss: 0.58634, accuracy: 0.554688\n",
      "Training loss: 0.595229, accuracy: 0.550781\n",
      "Training loss: 0.580981, accuracy: 0.601563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.748695, accuracy: 0.464844\n",
      "Training loss: 0.727714, accuracy: 0.480469\n",
      "Training loss: 0.721412, accuracy: 0.484375\n",
      "Training loss: 0.708312, accuracy: 0.515625\n",
      "Training loss: 0.666629, accuracy: 0.570313\n",
      "Training loss: 0.64746, accuracy: 0.550781\n",
      "Training loss: 0.63957, accuracy: 0.554688\n",
      "Training loss: 0.627451, accuracy: 0.535156\n",
      "Training loss: 0.615192, accuracy: 0.570313\n",
      "Training loss: 0.608045, accuracy: 0.578125\n",
      "Training loss: 0.612361, accuracy: 0.546875\n",
      "Training loss: 0.606475, accuracy: 0.582031\n",
      "Training loss: 0.61355, accuracy: 0.53125\n",
      "Training loss: 0.597971, accuracy: 0.628906\n",
      "Training loss: 0.599573, accuracy: 0.585938\n",
      "Training loss: 0.600775, accuracy: 0.601563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.745499, accuracy: 0.527344\n",
      "Training loss: 0.730495, accuracy: 0.550781\n",
      "Training loss: 0.693344, accuracy: 0.542969\n",
      "Training loss: 0.686463, accuracy: 0.558594\n",
      "Training loss: 0.651143, accuracy: 0.5625\n",
      "Training loss: 0.633167, accuracy: 0.558594\n",
      "Training loss: 0.627013, accuracy: 0.550781\n",
      "Training loss: 0.615493, accuracy: 0.574219\n",
      "Training loss: 0.608454, accuracy: 0.589844\n",
      "Training loss: 0.603188, accuracy: 0.570313\n",
      "Training loss: 0.610918, accuracy: 0.53125\n",
      "Training loss: 0.599463, accuracy: 0.566406\n",
      "Training loss: 0.602007, accuracy: 0.578125\n",
      "Training loss: 0.594402, accuracy: 0.550781\n",
      "Training loss: 0.592631, accuracy: 0.542969\n",
      "Training loss: 0.590319, accuracy: 0.59375\n",
      "----------------- Step 60: validation accuracy 0.50656 ----------------\n",
      "Training loss: 0.779212, accuracy: 0.527344\n",
      "Training loss: 0.737175, accuracy: 0.542969\n",
      "Training loss: 0.72719, accuracy: 0.53125\n",
      "Training loss: 0.694796, accuracy: 0.589844\n",
      "Training loss: 0.68979, accuracy: 0.546875\n",
      "Training loss: 0.643121, accuracy: 0.558594\n",
      "Training loss: 0.629988, accuracy: 0.582031\n",
      "Training loss: 0.620232, accuracy: 0.589844\n",
      "Training loss: 0.614634, accuracy: 0.558594\n",
      "Training loss: 0.604791, accuracy: 0.601563\n",
      "Training loss: 0.619527, accuracy: 0.558594\n",
      "Training loss: 0.604812, accuracy: 0.613281\n",
      "Training loss: 0.603853, accuracy: 0.589844\n",
      "Training loss: 0.6087, accuracy: 0.621094\n",
      "Training loss: 0.604753, accuracy: 0.605469\n",
      "Training loss: 0.600595, accuracy: 0.609375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.780915, accuracy: 0.589844\n",
      "Training loss: 0.771397, accuracy: 0.5625\n",
      "Training loss: 0.752026, accuracy: 0.574219\n",
      "Training loss: 0.699487, accuracy: 0.601563\n",
      "Training loss: 0.701667, accuracy: 0.566406\n",
      "Training loss: 0.64728, accuracy: 0.585938\n",
      "Training loss: 0.628585, accuracy: 0.621094\n",
      "Training loss: 0.614795, accuracy: 0.605469\n",
      "Training loss: 0.614158, accuracy: 0.625\n",
      "Training loss: 0.613998, accuracy: 0.597656\n",
      "Training loss: 0.598612, accuracy: 0.609375\n",
      "Training loss: 0.612162, accuracy: 0.597656\n",
      "Training loss: 0.601262, accuracy: 0.589844\n",
      "Training loss: 0.592126, accuracy: 0.636719\n",
      "Training loss: 0.58998, accuracy: 0.632813\n",
      "Training loss: 0.59147, accuracy: 0.613281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.777681, accuracy: 0.542969\n",
      "Training loss: 0.758152, accuracy: 0.570313\n",
      "Training loss: 0.751475, accuracy: 0.550781\n",
      "Training loss: 0.728842, accuracy: 0.554688\n",
      "Training loss: 0.696077, accuracy: 0.574219\n",
      "Training loss: 0.674433, accuracy: 0.546875\n",
      "Training loss: 0.653045, accuracy: 0.601563\n",
      "Training loss: 0.641823, accuracy: 0.554688\n",
      "Training loss: 0.62531, accuracy: 0.582031\n",
      "Training loss: 0.618491, accuracy: 0.605469\n",
      "Training loss: 0.606239, accuracy: 0.582031\n",
      "Training loss: 0.606299, accuracy: 0.597656\n",
      "Training loss: 0.603757, accuracy: 0.570313\n",
      "Training loss: 0.603205, accuracy: 0.59375\n",
      "Training loss: 0.603068, accuracy: 0.632813\n",
      "Training loss: 0.599146, accuracy: 0.613281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.82596, accuracy: 0.527344\n",
      "Training loss: 0.80668, accuracy: 0.535156\n",
      "Training loss: 0.797345, accuracy: 0.515625\n",
      "Training loss: 0.764675, accuracy: 0.496094\n",
      "Training loss: 0.712873, accuracy: 0.542969\n",
      "Training loss: 0.683538, accuracy: 0.511719\n",
      "Training loss: 0.649968, accuracy: 0.605469\n",
      "Training loss: 0.629882, accuracy: 0.585938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.614308, accuracy: 0.574219\n",
      "Training loss: 0.615651, accuracy: 0.589844\n",
      "Training loss: 0.599682, accuracy: 0.601563\n",
      "Training loss: 0.599834, accuracy: 0.59375\n",
      "Training loss: 0.590056, accuracy: 0.644531\n",
      "Training loss: 0.590592, accuracy: 0.589844\n",
      "Training loss: 0.594504, accuracy: 0.582031\n",
      "Training loss: 0.588272, accuracy: 0.625\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.740423, accuracy: 0.511719\n",
      "Training loss: 0.71072, accuracy: 0.515625\n",
      "Training loss: 0.702749, accuracy: 0.53125\n",
      "Training loss: 0.677102, accuracy: 0.550781\n",
      "Training loss: 0.666378, accuracy: 0.578125\n",
      "Training loss: 0.651162, accuracy: 0.554688\n",
      "Training loss: 0.643997, accuracy: 0.550781\n",
      "Training loss: 0.626611, accuracy: 0.570313\n",
      "Training loss: 0.632157, accuracy: 0.578125\n",
      "Training loss: 0.635505, accuracy: 0.554688\n",
      "Training loss: 0.642593, accuracy: 0.570313\n",
      "Training loss: 0.628786, accuracy: 0.566406\n",
      "Training loss: 0.618618, accuracy: 0.59375\n",
      "Training loss: 0.627296, accuracy: 0.566406\n",
      "Training loss: 0.622175, accuracy: 0.570313\n",
      "Training loss: 0.623772, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.731968, accuracy: 0.503906\n",
      "Training loss: 0.726087, accuracy: 0.515625\n",
      "Training loss: 0.708602, accuracy: 0.511719\n",
      "Training loss: 0.690843, accuracy: 0.535156\n",
      "Training loss: 0.681774, accuracy: 0.539063\n",
      "Training loss: 0.6491, accuracy: 0.542969\n",
      "Training loss: 0.644836, accuracy: 0.585938\n",
      "Training loss: 0.629474, accuracy: 0.570313\n",
      "Training loss: 0.612758, accuracy: 0.589844\n",
      "Training loss: 0.612013, accuracy: 0.558594\n",
      "Training loss: 0.606588, accuracy: 0.589844\n",
      "Training loss: 0.597845, accuracy: 0.585938\n",
      "Training loss: 0.595519, accuracy: 0.601563\n",
      "Training loss: 0.597391, accuracy: 0.566406\n",
      "Training loss: 0.59663, accuracy: 0.589844\n",
      "Training loss: 0.600521, accuracy: 0.582031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.728234, accuracy: 0.554688\n",
      "Training loss: 0.722449, accuracy: 0.539063\n",
      "Training loss: 0.683304, accuracy: 0.5625\n",
      "Training loss: 0.690811, accuracy: 0.550781\n",
      "Training loss: 0.687547, accuracy: 0.554688\n",
      "Training loss: 0.659667, accuracy: 0.578125\n",
      "Training loss: 0.650839, accuracy: 0.601563\n",
      "Training loss: 0.643465, accuracy: 0.566406\n",
      "Training loss: 0.638978, accuracy: 0.554688\n",
      "Training loss: 0.632887, accuracy: 0.574219\n",
      "Training loss: 0.622682, accuracy: 0.597656\n",
      "Training loss: 0.632125, accuracy: 0.535156\n",
      "Training loss: 0.615681, accuracy: 0.597656\n",
      "Training loss: 0.62192, accuracy: 0.558594\n",
      "Training loss: 0.617431, accuracy: 0.582031\n",
      "Training loss: 0.610039, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.778872, accuracy: 0.445313\n",
      "Training loss: 0.755193, accuracy: 0.464844\n",
      "Training loss: 0.726797, accuracy: 0.546875\n",
      "Training loss: 0.708317, accuracy: 0.5\n",
      "Training loss: 0.679969, accuracy: 0.570313\n",
      "Training loss: 0.669944, accuracy: 0.582031\n",
      "Training loss: 0.656876, accuracy: 0.609375\n",
      "Training loss: 0.655962, accuracy: 0.539063\n",
      "Training loss: 0.638089, accuracy: 0.546875\n",
      "Training loss: 0.637053, accuracy: 0.558594\n",
      "Training loss: 0.624185, accuracy: 0.597656\n",
      "Training loss: 0.636423, accuracy: 0.566406\n",
      "Training loss: 0.612494, accuracy: 0.59375\n",
      "Training loss: 0.618034, accuracy: 0.53125\n",
      "Training loss: 0.616187, accuracy: 0.5625\n",
      "Training loss: 0.623376, accuracy: 0.523438\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.75519, accuracy: 0.519531\n",
      "Training loss: 0.712622, accuracy: 0.542969\n",
      "Training loss: 0.722403, accuracy: 0.480469\n",
      "Training loss: 0.683181, accuracy: 0.523438\n",
      "Training loss: 0.6557, accuracy: 0.5625\n",
      "Training loss: 0.626597, accuracy: 0.5625\n",
      "Training loss: 0.616755, accuracy: 0.578125\n",
      "Training loss: 0.612772, accuracy: 0.578125\n",
      "Training loss: 0.606824, accuracy: 0.5625\n",
      "Training loss: 0.596293, accuracy: 0.574219\n",
      "Training loss: 0.586817, accuracy: 0.5625\n",
      "Training loss: 0.587917, accuracy: 0.59375\n",
      "Training loss: 0.580966, accuracy: 0.550781\n",
      "Training loss: 0.577419, accuracy: 0.59375\n",
      "Training loss: 0.573453, accuracy: 0.570313\n",
      "Training loss: 0.576964, accuracy: 0.585938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.721224, accuracy: 0.539063\n",
      "Training loss: 0.734306, accuracy: 0.5\n",
      "Training loss: 0.692782, accuracy: 0.527344\n",
      "Training loss: 0.679409, accuracy: 0.570313\n",
      "Training loss: 0.654827, accuracy: 0.582031\n",
      "Training loss: 0.648198, accuracy: 0.53125\n",
      "Training loss: 0.627009, accuracy: 0.601563\n",
      "Training loss: 0.618456, accuracy: 0.601563\n",
      "Training loss: 0.60569, accuracy: 0.621094\n",
      "Training loss: 0.594148, accuracy: 0.617188\n",
      "Training loss: 0.591639, accuracy: 0.613281\n",
      "Training loss: 0.581431, accuracy: 0.628906\n",
      "Training loss: 0.587746, accuracy: 0.625\n",
      "Training loss: 0.57395, accuracy: 0.640625\n",
      "Training loss: 0.582562, accuracy: 0.621094\n",
      "Training loss: 0.576166, accuracy: 0.625\n",
      "----------------- Step 70: validation accuracy 0.50768 ----------------\n",
      "Training loss: 0.77524, accuracy: 0.472656\n",
      "Training loss: 0.758301, accuracy: 0.441406\n",
      "Training loss: 0.72792, accuracy: 0.53125\n",
      "Training loss: 0.709018, accuracy: 0.476563\n",
      "Training loss: 0.674924, accuracy: 0.480469\n",
      "Training loss: 0.652142, accuracy: 0.558594\n",
      "Training loss: 0.640599, accuracy: 0.582031\n",
      "Training loss: 0.634102, accuracy: 0.582031\n",
      "Training loss: 0.6197, accuracy: 0.578125\n",
      "Training loss: 0.618384, accuracy: 0.578125\n",
      "Training loss: 0.621058, accuracy: 0.589844\n",
      "Training loss: 0.621241, accuracy: 0.582031\n",
      "Training loss: 0.621102, accuracy: 0.574219\n",
      "Training loss: 0.620933, accuracy: 0.585938\n",
      "Training loss: 0.605106, accuracy: 0.640625\n",
      "Training loss: 0.611681, accuracy: 0.609375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.76102, accuracy: 0.539063\n",
      "Training loss: 0.739765, accuracy: 0.53125\n",
      "Training loss: 0.7245, accuracy: 0.53125\n",
      "Training loss: 0.724906, accuracy: 0.527344\n",
      "Training loss: 0.681573, accuracy: 0.492188\n",
      "Training loss: 0.66395, accuracy: 0.539063\n",
      "Training loss: 0.637103, accuracy: 0.582031\n",
      "Training loss: 0.648011, accuracy: 0.527344\n",
      "Training loss: 0.629268, accuracy: 0.527344\n",
      "Training loss: 0.630164, accuracy: 0.570313\n",
      "Training loss: 0.627712, accuracy: 0.546875\n",
      "Training loss: 0.627038, accuracy: 0.566406\n",
      "Training loss: 0.631868, accuracy: 0.542969\n",
      "Training loss: 0.63408, accuracy: 0.5\n",
      "Training loss: 0.616537, accuracy: 0.601563\n",
      "Training loss: 0.613129, accuracy: 0.574219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.726242, accuracy: 0.507813\n",
      "Training loss: 0.714565, accuracy: 0.53125\n",
      "Training loss: 0.695171, accuracy: 0.480469\n",
      "Training loss: 0.678947, accuracy: 0.480469\n",
      "Training loss: 0.663579, accuracy: 0.503906\n",
      "Training loss: 0.641268, accuracy: 0.542969\n",
      "Training loss: 0.631396, accuracy: 0.511719\n",
      "Training loss: 0.628215, accuracy: 0.546875\n",
      "Training loss: 0.622934, accuracy: 0.542969\n",
      "Training loss: 0.612276, accuracy: 0.605469\n",
      "Training loss: 0.621302, accuracy: 0.542969\n",
      "Training loss: 0.617794, accuracy: 0.558594\n",
      "Training loss: 0.61493, accuracy: 0.570313\n",
      "Training loss: 0.605858, accuracy: 0.585938\n",
      "Training loss: 0.605005, accuracy: 0.582031\n",
      "Training loss: 0.594263, accuracy: 0.632813\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.674577, accuracy: 0.53125\n",
      "Training loss: 0.673527, accuracy: 0.550781\n",
      "Training loss: 0.669253, accuracy: 0.566406\n",
      "Training loss: 0.667745, accuracy: 0.539063\n",
      "Training loss: 0.643337, accuracy: 0.574219\n",
      "Training loss: 0.626391, accuracy: 0.539063\n",
      "Training loss: 0.618528, accuracy: 0.527344\n",
      "Training loss: 0.60821, accuracy: 0.578125\n",
      "Training loss: 0.611049, accuracy: 0.542969\n",
      "Training loss: 0.600289, accuracy: 0.605469\n",
      "Training loss: 0.607602, accuracy: 0.53125\n",
      "Training loss: 0.593899, accuracy: 0.597656\n",
      "Training loss: 0.604517, accuracy: 0.519531\n",
      "Training loss: 0.601698, accuracy: 0.523438\n",
      "Training loss: 0.600323, accuracy: 0.554688\n",
      "Training loss: 0.591301, accuracy: 0.578125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.655147, accuracy: 0.546875\n",
      "Training loss: 0.672565, accuracy: 0.53125\n",
      "Training loss: 0.639408, accuracy: 0.605469\n",
      "Training loss: 0.634638, accuracy: 0.527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.637994, accuracy: 0.554688\n",
      "Training loss: 0.621435, accuracy: 0.574219\n",
      "Training loss: 0.633591, accuracy: 0.566406\n",
      "Training loss: 0.619717, accuracy: 0.574219\n",
      "Training loss: 0.618137, accuracy: 0.550781\n",
      "Training loss: 0.618135, accuracy: 0.542969\n",
      "Training loss: 0.614691, accuracy: 0.542969\n",
      "Training loss: 0.616361, accuracy: 0.542969\n",
      "Training loss: 0.610548, accuracy: 0.574219\n",
      "Training loss: 0.611649, accuracy: 0.558594\n",
      "Training loss: 0.608792, accuracy: 0.585938\n",
      "Training loss: 0.613345, accuracy: 0.566406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.714863, accuracy: 0.496094\n",
      "Training loss: 0.701563, accuracy: 0.476563\n",
      "Training loss: 0.670141, accuracy: 0.542969\n",
      "Training loss: 0.642459, accuracy: 0.527344\n",
      "Training loss: 0.629883, accuracy: 0.535156\n",
      "Training loss: 0.604955, accuracy: 0.601563\n",
      "Training loss: 0.607883, accuracy: 0.566406\n",
      "Training loss: 0.597177, accuracy: 0.574219\n",
      "Training loss: 0.588314, accuracy: 0.605469\n",
      "Training loss: 0.590732, accuracy: 0.605469\n",
      "Training loss: 0.586259, accuracy: 0.609375\n",
      "Training loss: 0.589273, accuracy: 0.609375\n",
      "Training loss: 0.586874, accuracy: 0.605469\n",
      "Training loss: 0.590627, accuracy: 0.613281\n",
      "Training loss: 0.586973, accuracy: 0.609375\n",
      "Training loss: 0.584267, accuracy: 0.601563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.680881, accuracy: 0.589844\n",
      "Training loss: 0.666515, accuracy: 0.589844\n",
      "Training loss: 0.680885, accuracy: 0.578125\n",
      "Training loss: 0.637127, accuracy: 0.605469\n",
      "Training loss: 0.632955, accuracy: 0.574219\n",
      "Training loss: 0.612518, accuracy: 0.5625\n",
      "Training loss: 0.614073, accuracy: 0.578125\n",
      "Training loss: 0.611876, accuracy: 0.582031\n",
      "Training loss: 0.607309, accuracy: 0.5625\n",
      "Training loss: 0.603053, accuracy: 0.570313\n",
      "Training loss: 0.60711, accuracy: 0.59375\n",
      "Training loss: 0.603977, accuracy: 0.554688\n",
      "Training loss: 0.608684, accuracy: 0.550781\n",
      "Training loss: 0.603237, accuracy: 0.578125\n",
      "Training loss: 0.606363, accuracy: 0.539063\n",
      "Training loss: 0.604803, accuracy: 0.578125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.706289, accuracy: 0.550781\n",
      "Training loss: 0.662415, accuracy: 0.523438\n",
      "Training loss: 0.663974, accuracy: 0.554688\n",
      "Training loss: 0.642733, accuracy: 0.492188\n",
      "Training loss: 0.617737, accuracy: 0.585938\n",
      "Training loss: 0.603725, accuracy: 0.539063\n",
      "Training loss: 0.605494, accuracy: 0.542969\n",
      "Training loss: 0.588784, accuracy: 0.613281\n",
      "Training loss: 0.592317, accuracy: 0.609375\n",
      "Training loss: 0.589296, accuracy: 0.609375\n",
      "Training loss: 0.597518, accuracy: 0.585938\n",
      "Training loss: 0.589414, accuracy: 0.59375\n",
      "Training loss: 0.591877, accuracy: 0.625\n",
      "Training loss: 0.583671, accuracy: 0.632813\n",
      "Training loss: 0.593723, accuracy: 0.609375\n",
      "Training loss: 0.587126, accuracy: 0.597656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.721748, accuracy: 0.523438\n",
      "Training loss: 0.71137, accuracy: 0.527344\n",
      "Training loss: 0.699425, accuracy: 0.546875\n",
      "Training loss: 0.702221, accuracy: 0.535156\n",
      "Training loss: 0.648728, accuracy: 0.515625\n",
      "Training loss: 0.645541, accuracy: 0.589844\n",
      "Training loss: 0.625953, accuracy: 0.5625\n",
      "Training loss: 0.628099, accuracy: 0.527344\n",
      "Training loss: 0.611779, accuracy: 0.609375\n",
      "Training loss: 0.623156, accuracy: 0.546875\n",
      "Training loss: 0.614502, accuracy: 0.589844\n",
      "Training loss: 0.616655, accuracy: 0.566406\n",
      "Training loss: 0.612534, accuracy: 0.554688\n",
      "Training loss: 0.612003, accuracy: 0.566406\n",
      "Training loss: 0.615638, accuracy: 0.558594\n",
      "Training loss: 0.614969, accuracy: 0.574219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.65888, accuracy: 0.503906\n",
      "Training loss: 0.63349, accuracy: 0.578125\n",
      "Training loss: 0.632007, accuracy: 0.589844\n",
      "Training loss: 0.619594, accuracy: 0.578125\n",
      "Training loss: 0.599582, accuracy: 0.636719\n",
      "Training loss: 0.609093, accuracy: 0.558594\n",
      "Training loss: 0.614031, accuracy: 0.566406\n",
      "Training loss: 0.597769, accuracy: 0.566406\n",
      "Training loss: 0.589204, accuracy: 0.585938\n",
      "Training loss: 0.595037, accuracy: 0.578125\n",
      "Training loss: 0.594416, accuracy: 0.578125\n",
      "Training loss: 0.591637, accuracy: 0.617188\n",
      "Training loss: 0.599042, accuracy: 0.558594\n",
      "Training loss: 0.588304, accuracy: 0.605469\n",
      "Training loss: 0.587317, accuracy: 0.609375\n",
      "Training loss: 0.595334, accuracy: 0.550781\n",
      "----------------- Step 80: validation accuracy 0.51024 ----------------\n",
      "Training loss: 0.667944, accuracy: 0.519531\n",
      "Training loss: 0.674568, accuracy: 0.5\n",
      "Training loss: 0.649567, accuracy: 0.53125\n",
      "Training loss: 0.640609, accuracy: 0.566406\n",
      "Training loss: 0.631989, accuracy: 0.542969\n",
      "Training loss: 0.62244, accuracy: 0.523438\n",
      "Training loss: 0.616208, accuracy: 0.53125\n",
      "Training loss: 0.608115, accuracy: 0.558594\n",
      "Training loss: 0.599194, accuracy: 0.632813\n",
      "Training loss: 0.609733, accuracy: 0.566406\n",
      "Training loss: 0.60302, accuracy: 0.566406\n",
      "Training loss: 0.595554, accuracy: 0.632813\n",
      "Training loss: 0.608201, accuracy: 0.546875\n",
      "Training loss: 0.596813, accuracy: 0.601563\n",
      "Training loss: 0.596857, accuracy: 0.597656\n",
      "Training loss: 0.59594, accuracy: 0.59375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.680796, accuracy: 0.535156\n",
      "Training loss: 0.669157, accuracy: 0.566406\n",
      "Training loss: 0.659942, accuracy: 0.578125\n",
      "Training loss: 0.645533, accuracy: 0.558594\n",
      "Training loss: 0.628994, accuracy: 0.550781\n",
      "Training loss: 0.639566, accuracy: 0.535156\n",
      "Training loss: 0.616098, accuracy: 0.558594\n",
      "Training loss: 0.603439, accuracy: 0.589844\n",
      "Training loss: 0.616509, accuracy: 0.550781\n",
      "Training loss: 0.617306, accuracy: 0.5625\n",
      "Training loss: 0.613279, accuracy: 0.5625\n",
      "Training loss: 0.61719, accuracy: 0.550781\n",
      "Training loss: 0.608629, accuracy: 0.570313\n",
      "Training loss: 0.609363, accuracy: 0.585938\n",
      "Training loss: 0.609182, accuracy: 0.570313\n",
      "Training loss: 0.605499, accuracy: 0.578125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.655232, accuracy: 0.542969\n",
      "Training loss: 0.648088, accuracy: 0.542969\n",
      "Training loss: 0.641632, accuracy: 0.546875\n",
      "Training loss: 0.635762, accuracy: 0.578125\n",
      "Training loss: 0.625029, accuracy: 0.5625\n",
      "Training loss: 0.611021, accuracy: 0.601563\n",
      "Training loss: 0.606285, accuracy: 0.585938\n",
      "Training loss: 0.604973, accuracy: 0.601563\n",
      "Training loss: 0.607189, accuracy: 0.585938\n",
      "Training loss: 0.618859, accuracy: 0.527344\n",
      "Training loss: 0.607627, accuracy: 0.570313\n",
      "Training loss: 0.606453, accuracy: 0.566406\n",
      "Training loss: 0.610644, accuracy: 0.570313\n",
      "Training loss: 0.610059, accuracy: 0.585938\n",
      "Training loss: 0.606742, accuracy: 0.582031\n",
      "Training loss: 0.611734, accuracy: 0.546875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.724123, accuracy: 0.523438\n",
      "Training loss: 0.710443, accuracy: 0.527344\n",
      "Training loss: 0.677121, accuracy: 0.539063\n",
      "Training loss: 0.625175, accuracy: 0.585938\n",
      "Training loss: 0.626404, accuracy: 0.558594\n",
      "Training loss: 0.623774, accuracy: 0.542969\n",
      "Training loss: 0.609034, accuracy: 0.550781\n",
      "Training loss: 0.609662, accuracy: 0.582031\n",
      "Training loss: 0.616129, accuracy: 0.554688\n",
      "Training loss: 0.605561, accuracy: 0.558594\n",
      "Training loss: 0.589929, accuracy: 0.628906\n",
      "Training loss: 0.598835, accuracy: 0.601563\n",
      "Training loss: 0.60295, accuracy: 0.601563\n",
      "Training loss: 0.611656, accuracy: 0.578125\n",
      "Training loss: 0.603371, accuracy: 0.632813\n",
      "Training loss: 0.598011, accuracy: 0.601563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.683304, accuracy: 0.527344\n",
      "Training loss: 0.675901, accuracy: 0.578125\n",
      "Training loss: 0.650097, accuracy: 0.539063\n",
      "Training loss: 0.640986, accuracy: 0.554688\n",
      "Training loss: 0.622959, accuracy: 0.519531\n",
      "Training loss: 0.623289, accuracy: 0.550781\n",
      "Training loss: 0.624987, accuracy: 0.507813\n",
      "Training loss: 0.611714, accuracy: 0.574219\n",
      "Training loss: 0.616394, accuracy: 0.546875\n",
      "Training loss: 0.60909, accuracy: 0.605469\n",
      "Training loss: 0.607315, accuracy: 0.617188\n",
      "Training loss: 0.61393, accuracy: 0.578125\n",
      "Training loss: 0.616266, accuracy: 0.554688\n",
      "Training loss: 0.625172, accuracy: 0.484375\n",
      "Training loss: 0.597154, accuracy: 0.609375\n",
      "Training loss: 0.618114, accuracy: 0.539063\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.716462, accuracy: 0.484375\n",
      "Training loss: 0.669589, accuracy: 0.582031\n",
      "Training loss: 0.660232, accuracy: 0.597656\n",
      "Training loss: 0.622568, accuracy: 0.582031\n",
      "Training loss: 0.619215, accuracy: 0.570313\n",
      "Training loss: 0.626301, accuracy: 0.539063\n",
      "Training loss: 0.605652, accuracy: 0.601563\n",
      "Training loss: 0.610054, accuracy: 0.589844\n",
      "Training loss: 0.60662, accuracy: 0.589844\n",
      "Training loss: 0.606162, accuracy: 0.582031\n",
      "Training loss: 0.603055, accuracy: 0.597656\n",
      "Training loss: 0.607267, accuracy: 0.589844\n",
      "Training loss: 0.607429, accuracy: 0.597656\n",
      "Training loss: 0.609764, accuracy: 0.585938\n",
      "Training loss: 0.611556, accuracy: 0.59375\n",
      "Training loss: 0.606081, accuracy: 0.589844\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.621032, accuracy: 0.601563\n",
      "Training loss: 0.624603, accuracy: 0.570313\n",
      "Training loss: 0.630618, accuracy: 0.582031\n",
      "Training loss: 0.597396, accuracy: 0.589844\n",
      "Training loss: 0.595354, accuracy: 0.601563\n",
      "Training loss: 0.599246, accuracy: 0.613281\n",
      "Training loss: 0.595105, accuracy: 0.578125\n",
      "Training loss: 0.593981, accuracy: 0.597656\n",
      "Training loss: 0.580097, accuracy: 0.601563\n",
      "Training loss: 0.588088, accuracy: 0.570313\n",
      "Training loss: 0.580335, accuracy: 0.582031\n",
      "Training loss: 0.581101, accuracy: 0.558594\n",
      "Training loss: 0.583781, accuracy: 0.597656\n",
      "Training loss: 0.577858, accuracy: 0.609375\n",
      "Training loss: 0.583119, accuracy: 0.597656\n",
      "Training loss: 0.569847, accuracy: 0.671875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.639697, accuracy: 0.53125\n",
      "Training loss: 0.64276, accuracy: 0.539063\n",
      "Training loss: 0.624282, accuracy: 0.558594\n",
      "Training loss: 0.610296, accuracy: 0.601563\n",
      "Training loss: 0.613493, accuracy: 0.554688\n",
      "Training loss: 0.603812, accuracy: 0.554688\n",
      "Training loss: 0.606229, accuracy: 0.578125\n",
      "Training loss: 0.603198, accuracy: 0.550781\n",
      "Training loss: 0.591553, accuracy: 0.632813\n",
      "Training loss: 0.591951, accuracy: 0.597656\n",
      "Training loss: 0.595795, accuracy: 0.582031\n",
      "Training loss: 0.592422, accuracy: 0.625\n",
      "Training loss: 0.587005, accuracy: 0.609375\n",
      "Training loss: 0.580462, accuracy: 0.644531\n",
      "Training loss: 0.585206, accuracy: 0.597656\n",
      "Training loss: 0.581376, accuracy: 0.636719\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.630968, accuracy: 0.589844\n",
      "Training loss: 0.616123, accuracy: 0.675781\n",
      "Training loss: 0.617506, accuracy: 0.617188\n",
      "Training loss: 0.590537, accuracy: 0.667969\n",
      "Training loss: 0.593175, accuracy: 0.636719\n",
      "Training loss: 0.563547, accuracy: 0.675781\n",
      "Training loss: 0.561134, accuracy: 0.675781\n",
      "Training loss: 0.554412, accuracy: 0.667969\n",
      "Training loss: 0.536912, accuracy: 0.699219\n",
      "Training loss: 0.518092, accuracy: 0.730469\n",
      "Training loss: 0.501928, accuracy: 0.75\n",
      "Training loss: 0.488642, accuracy: 0.75\n",
      "Training loss: 0.48872, accuracy: 0.761719\n",
      "Training loss: 0.441225, accuracy: 0.773438\n",
      "Training loss: 0.435322, accuracy: 0.8125\n",
      "Training loss: 0.396162, accuracy: 0.84375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.620722, accuracy: 0.730469\n",
      "Training loss: 0.533694, accuracy: 0.777344\n",
      "Training loss: 0.46431, accuracy: 0.796875\n",
      "Training loss: 0.549954, accuracy: 0.703125\n",
      "Training loss: 0.446787, accuracy: 0.804688\n",
      "Training loss: 0.365208, accuracy: 0.847656\n",
      "Training loss: 0.335937, accuracy: 0.875\n",
      "Training loss: 0.346228, accuracy: 0.867188\n",
      "Training loss: 0.33642, accuracy: 0.898438\n",
      "Training loss: 0.303789, accuracy: 0.894531\n",
      "Training loss: 0.286768, accuracy: 0.921875\n",
      "Training loss: 0.262832, accuracy: 0.929688\n",
      "Training loss: 0.236249, accuracy: 0.945313\n",
      "Training loss: 0.21959, accuracy: 0.9375\n",
      "Training loss: 0.190347, accuracy: 0.964844\n",
      "Training loss: 0.201067, accuracy: 0.957031\n",
      "----------------- Step 90: validation accuracy 0.71328 ----------------\n",
      "Training loss: 0.896752, accuracy: 0.679688\n",
      "Training loss: 0.820169, accuracy: 0.714844\n",
      "Training loss: 0.661386, accuracy: 0.757813\n",
      "Training loss: 0.536781, accuracy: 0.785156\n",
      "Training loss: 0.446941, accuracy: 0.8125\n",
      "Training loss: 0.423028, accuracy: 0.835938\n",
      "Training loss: 0.375691, accuracy: 0.867188\n",
      "Training loss: 0.356354, accuracy: 0.867188\n",
      "Training loss: 0.344829, accuracy: 0.878906\n",
      "Training loss: 0.283354, accuracy: 0.90625\n",
      "Training loss: 0.277845, accuracy: 0.917969\n",
      "Training loss: 0.274088, accuracy: 0.910156\n",
      "Training loss: 0.259917, accuracy: 0.921875\n",
      "Training loss: 0.24643, accuracy: 0.925781\n",
      "Training loss: 0.219712, accuracy: 0.9375\n",
      "Training loss: 0.210969, accuracy: 0.941406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.600828, accuracy: 0.738281\n",
      "Training loss: 0.618634, accuracy: 0.722656\n",
      "Training loss: 0.572489, accuracy: 0.789063\n",
      "Training loss: 0.53887, accuracy: 0.769531\n",
      "Training loss: 0.471359, accuracy: 0.832031\n",
      "Training loss: 0.417424, accuracy: 0.847656\n",
      "Training loss: 0.378248, accuracy: 0.847656\n",
      "Training loss: 0.371434, accuracy: 0.878906\n",
      "Training loss: 0.320487, accuracy: 0.902344\n",
      "Training loss: 0.302228, accuracy: 0.902344\n",
      "Training loss: 0.304249, accuracy: 0.90625\n",
      "Training loss: 0.290614, accuracy: 0.917969\n",
      "Training loss: 0.262629, accuracy: 0.917969\n",
      "Training loss: 0.250144, accuracy: 0.933594\n",
      "Training loss: 0.247418, accuracy: 0.925781\n",
      "Training loss: 0.240424, accuracy: 0.941406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.570632, accuracy: 0.75\n",
      "Training loss: 0.516522, accuracy: 0.765625\n",
      "Training loss: 0.511754, accuracy: 0.785156\n",
      "Training loss: 0.484723, accuracy: 0.816406\n",
      "Training loss: 0.427066, accuracy: 0.835938\n",
      "Training loss: 0.408524, accuracy: 0.835938\n",
      "Training loss: 0.370308, accuracy: 0.859375\n",
      "Training loss: 0.338124, accuracy: 0.878906\n",
      "Training loss: 0.330962, accuracy: 0.886719\n",
      "Training loss: 0.324338, accuracy: 0.882813\n",
      "Training loss: 0.30158, accuracy: 0.890625\n",
      "Training loss: 0.28765, accuracy: 0.921875\n",
      "Training loss: 0.284002, accuracy: 0.910156\n",
      "Training loss: 0.265029, accuracy: 0.925781\n",
      "Training loss: 0.245604, accuracy: 0.929688\n",
      "Training loss: 0.235235, accuracy: 0.929688\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.587286, accuracy: 0.699219\n",
      "Training loss: 0.573869, accuracy: 0.71875\n",
      "Training loss: 0.536474, accuracy: 0.742188\n",
      "Training loss: 0.472782, accuracy: 0.789063\n",
      "Training loss: 0.455157, accuracy: 0.800781\n",
      "Training loss: 0.396075, accuracy: 0.839844\n",
      "Training loss: 0.379832, accuracy: 0.859375\n",
      "Training loss: 0.357982, accuracy: 0.875\n",
      "Training loss: 0.329421, accuracy: 0.882813\n",
      "Training loss: 0.309069, accuracy: 0.894531\n",
      "Training loss: 0.299533, accuracy: 0.90625\n",
      "Training loss: 0.271657, accuracy: 0.914063\n",
      "Training loss: 0.277185, accuracy: 0.914063\n",
      "Training loss: 0.239942, accuracy: 0.929688\n",
      "Training loss: 0.239788, accuracy: 0.925781\n",
      "Training loss: 0.204728, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.570203, accuracy: 0.765625\n",
      "Training loss: 0.539681, accuracy: 0.78125\n",
      "Training loss: 0.479462, accuracy: 0.808594\n",
      "Training loss: 0.443314, accuracy: 0.835938\n",
      "Training loss: 0.396704, accuracy: 0.835938\n",
      "Training loss: 0.336563, accuracy: 0.890625\n",
      "Training loss: 0.33438, accuracy: 0.886719\n",
      "Training loss: 0.289101, accuracy: 0.90625\n",
      "Training loss: 0.27398, accuracy: 0.914063\n",
      "Training loss: 0.251468, accuracy: 0.925781\n",
      "Training loss: 0.234466, accuracy: 0.933594\n",
      "Training loss: 0.222205, accuracy: 0.941406\n",
      "Training loss: 0.205162, accuracy: 0.945313\n",
      "Training loss: 0.196884, accuracy: 0.953125\n",
      "Training loss: 0.202947, accuracy: 0.945313\n",
      "Training loss: 0.184649, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.488471, accuracy: 0.78125\n",
      "Training loss: 0.434111, accuracy: 0.808594\n",
      "Training loss: 0.369313, accuracy: 0.851563\n",
      "Training loss: 0.37276, accuracy: 0.847656\n",
      "Training loss: 0.315694, accuracy: 0.890625\n",
      "Training loss: 0.287695, accuracy: 0.902344\n",
      "Training loss: 0.294026, accuracy: 0.90625\n",
      "Training loss: 0.250636, accuracy: 0.921875\n",
      "Training loss: 0.239635, accuracy: 0.925781\n",
      "Training loss: 0.207867, accuracy: 0.941406\n",
      "Training loss: 0.208714, accuracy: 0.945313\n",
      "Training loss: 0.183863, accuracy: 0.957031\n",
      "Training loss: 0.186088, accuracy: 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.168762, accuracy: 0.953125\n",
      "Training loss: 0.17282, accuracy: 0.953125\n",
      "Training loss: 0.148104, accuracy: 0.960938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.597397, accuracy: 0.789063\n",
      "Training loss: 0.562815, accuracy: 0.800781\n",
      "Training loss: 0.503186, accuracy: 0.824219\n",
      "Training loss: 0.450542, accuracy: 0.832031\n",
      "Training loss: 0.426544, accuracy: 0.859375\n",
      "Training loss: 0.36796, accuracy: 0.875\n",
      "Training loss: 0.330535, accuracy: 0.894531\n",
      "Training loss: 0.31098, accuracy: 0.894531\n",
      "Training loss: 0.297256, accuracy: 0.90625\n",
      "Training loss: 0.298443, accuracy: 0.917969\n",
      "Training loss: 0.257605, accuracy: 0.921875\n",
      "Training loss: 0.239266, accuracy: 0.921875\n",
      "Training loss: 0.237568, accuracy: 0.917969\n",
      "Training loss: 0.229093, accuracy: 0.933594\n",
      "Training loss: 0.235843, accuracy: 0.9375\n",
      "Training loss: 0.202369, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.528158, accuracy: 0.792969\n",
      "Training loss: 0.515753, accuracy: 0.796875\n",
      "Training loss: 0.467963, accuracy: 0.808594\n",
      "Training loss: 0.456823, accuracy: 0.832031\n",
      "Training loss: 0.402475, accuracy: 0.832031\n",
      "Training loss: 0.387905, accuracy: 0.855469\n",
      "Training loss: 0.356223, accuracy: 0.863281\n",
      "Training loss: 0.382439, accuracy: 0.847656\n",
      "Training loss: 0.324146, accuracy: 0.878906\n",
      "Training loss: 0.308378, accuracy: 0.878906\n",
      "Training loss: 0.306274, accuracy: 0.898438\n",
      "Training loss: 0.296459, accuracy: 0.902344\n",
      "Training loss: 0.257381, accuracy: 0.917969\n",
      "Training loss: 0.24639, accuracy: 0.917969\n",
      "Training loss: 0.261339, accuracy: 0.921875\n",
      "Training loss: 0.231954, accuracy: 0.925781\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.643732, accuracy: 0.769531\n",
      "Training loss: 0.597378, accuracy: 0.773438\n",
      "Training loss: 0.571611, accuracy: 0.773438\n",
      "Training loss: 0.514411, accuracy: 0.816406\n",
      "Training loss: 0.459573, accuracy: 0.824219\n",
      "Training loss: 0.422822, accuracy: 0.835938\n",
      "Training loss: 0.374054, accuracy: 0.847656\n",
      "Training loss: 0.346108, accuracy: 0.871094\n",
      "Training loss: 0.33461, accuracy: 0.875\n",
      "Training loss: 0.329525, accuracy: 0.875\n",
      "Training loss: 0.322866, accuracy: 0.902344\n",
      "Training loss: 0.285327, accuracy: 0.902344\n",
      "Training loss: 0.289272, accuracy: 0.902344\n",
      "Training loss: 0.283004, accuracy: 0.910156\n",
      "Training loss: 0.259561, accuracy: 0.917969\n",
      "Training loss: 0.25098, accuracy: 0.917969\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.433173, accuracy: 0.832031\n",
      "Training loss: 0.402442, accuracy: 0.839844\n",
      "Training loss: 0.407071, accuracy: 0.839844\n",
      "Training loss: 0.354956, accuracy: 0.882813\n",
      "Training loss: 0.345593, accuracy: 0.886719\n",
      "Training loss: 0.298267, accuracy: 0.894531\n",
      "Training loss: 0.296005, accuracy: 0.90625\n",
      "Training loss: 0.271821, accuracy: 0.917969\n",
      "Training loss: 0.277361, accuracy: 0.917969\n",
      "Training loss: 0.252474, accuracy: 0.921875\n",
      "Training loss: 0.250292, accuracy: 0.917969\n",
      "Training loss: 0.250803, accuracy: 0.929688\n",
      "Training loss: 0.239057, accuracy: 0.929688\n",
      "Training loss: 0.214108, accuracy: 0.933594\n",
      "Training loss: 0.215124, accuracy: 0.929688\n",
      "Training loss: 0.19999, accuracy: 0.945313\n",
      "----------------- Step 100: validation accuracy 0.76528 ----------------\n",
      "Training loss: 0.536611, accuracy: 0.816406\n",
      "Training loss: 0.520116, accuracy: 0.8125\n",
      "Training loss: 0.485188, accuracy: 0.824219\n",
      "Training loss: 0.421077, accuracy: 0.839844\n",
      "Training loss: 0.397137, accuracy: 0.863281\n",
      "Training loss: 0.354937, accuracy: 0.859375\n",
      "Training loss: 0.332293, accuracy: 0.882813\n",
      "Training loss: 0.311996, accuracy: 0.894531\n",
      "Training loss: 0.290423, accuracy: 0.902344\n",
      "Training loss: 0.282781, accuracy: 0.917969\n",
      "Training loss: 0.259894, accuracy: 0.921875\n",
      "Training loss: 0.270054, accuracy: 0.921875\n",
      "Training loss: 0.247203, accuracy: 0.925781\n",
      "Training loss: 0.250821, accuracy: 0.925781\n",
      "Training loss: 0.239311, accuracy: 0.921875\n",
      "Training loss: 0.233632, accuracy: 0.925781\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.485519, accuracy: 0.800781\n",
      "Training loss: 0.498014, accuracy: 0.789063\n",
      "Training loss: 0.46134, accuracy: 0.8125\n",
      "Training loss: 0.441475, accuracy: 0.824219\n",
      "Training loss: 0.402369, accuracy: 0.839844\n",
      "Training loss: 0.352757, accuracy: 0.855469\n",
      "Training loss: 0.363127, accuracy: 0.859375\n",
      "Training loss: 0.319535, accuracy: 0.898438\n",
      "Training loss: 0.286157, accuracy: 0.894531\n",
      "Training loss: 0.272567, accuracy: 0.917969\n",
      "Training loss: 0.254822, accuracy: 0.9375\n",
      "Training loss: 0.227001, accuracy: 0.9375\n",
      "Training loss: 0.211408, accuracy: 0.949219\n",
      "Training loss: 0.196262, accuracy: 0.949219\n",
      "Training loss: 0.175779, accuracy: 0.957031\n",
      "Training loss: 0.16825, accuracy: 0.957031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.531381, accuracy: 0.800781\n",
      "Training loss: 0.53402, accuracy: 0.832031\n",
      "Training loss: 0.451628, accuracy: 0.855469\n",
      "Training loss: 0.391434, accuracy: 0.859375\n",
      "Training loss: 0.322397, accuracy: 0.871094\n",
      "Training loss: 0.30456, accuracy: 0.882813\n",
      "Training loss: 0.309363, accuracy: 0.894531\n",
      "Training loss: 0.246676, accuracy: 0.929688\n",
      "Training loss: 0.216234, accuracy: 0.929688\n",
      "Training loss: 0.222657, accuracy: 0.9375\n",
      "Training loss: 0.198014, accuracy: 0.933594\n",
      "Training loss: 0.179863, accuracy: 0.949219\n",
      "Training loss: 0.168007, accuracy: 0.957031\n",
      "Training loss: 0.152695, accuracy: 0.960938\n",
      "Training loss: 0.148165, accuracy: 0.964844\n",
      "Training loss: 0.136371, accuracy: 0.964844\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.49271, accuracy: 0.835938\n",
      "Training loss: 0.471101, accuracy: 0.835938\n",
      "Training loss: 0.41813, accuracy: 0.839844\n",
      "Training loss: 0.386403, accuracy: 0.851563\n",
      "Training loss: 0.347706, accuracy: 0.859375\n",
      "Training loss: 0.324786, accuracy: 0.894531\n",
      "Training loss: 0.290452, accuracy: 0.90625\n",
      "Training loss: 0.26801, accuracy: 0.917969\n",
      "Training loss: 0.247822, accuracy: 0.921875\n",
      "Training loss: 0.240227, accuracy: 0.933594\n",
      "Training loss: 0.210411, accuracy: 0.945313\n",
      "Training loss: 0.20334, accuracy: 0.941406\n",
      "Training loss: 0.207439, accuracy: 0.9375\n",
      "Training loss: 0.180601, accuracy: 0.953125\n",
      "Training loss: 0.151658, accuracy: 0.972656\n",
      "Training loss: 0.147306, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.499217, accuracy: 0.792969\n",
      "Training loss: 0.468961, accuracy: 0.808594\n",
      "Training loss: 0.453907, accuracy: 0.816406\n",
      "Training loss: 0.42326, accuracy: 0.828125\n",
      "Training loss: 0.383933, accuracy: 0.851563\n",
      "Training loss: 0.358757, accuracy: 0.859375\n",
      "Training loss: 0.327698, accuracy: 0.894531\n",
      "Training loss: 0.321668, accuracy: 0.902344\n",
      "Training loss: 0.285747, accuracy: 0.910156\n",
      "Training loss: 0.277598, accuracy: 0.910156\n",
      "Training loss: 0.253838, accuracy: 0.917969\n",
      "Training loss: 0.24583, accuracy: 0.921875\n",
      "Training loss: 0.23171, accuracy: 0.925781\n",
      "Training loss: 0.2246, accuracy: 0.917969\n",
      "Training loss: 0.220852, accuracy: 0.925781\n",
      "Training loss: 0.214806, accuracy: 0.9375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.441209, accuracy: 0.847656\n",
      "Training loss: 0.408724, accuracy: 0.855469\n",
      "Training loss: 0.359585, accuracy: 0.867188\n",
      "Training loss: 0.317899, accuracy: 0.890625\n",
      "Training loss: 0.294196, accuracy: 0.894531\n",
      "Training loss: 0.283426, accuracy: 0.914063\n",
      "Training loss: 0.242641, accuracy: 0.917969\n",
      "Training loss: 0.231492, accuracy: 0.929688\n",
      "Training loss: 0.208824, accuracy: 0.949219\n",
      "Training loss: 0.181752, accuracy: 0.953125\n",
      "Training loss: 0.183653, accuracy: 0.960938\n",
      "Training loss: 0.170622, accuracy: 0.960938\n",
      "Training loss: 0.152808, accuracy: 0.964844\n",
      "Training loss: 0.150756, accuracy: 0.96875\n",
      "Training loss: 0.150778, accuracy: 0.96875\n",
      "Training loss: 0.146623, accuracy: 0.964844\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.578743, accuracy: 0.789063\n",
      "Training loss: 0.541837, accuracy: 0.789063\n",
      "Training loss: 0.483922, accuracy: 0.820313\n",
      "Training loss: 0.451187, accuracy: 0.863281\n",
      "Training loss: 0.409147, accuracy: 0.859375\n",
      "Training loss: 0.395486, accuracy: 0.863281\n",
      "Training loss: 0.349019, accuracy: 0.878906\n",
      "Training loss: 0.322364, accuracy: 0.894531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.315569, accuracy: 0.902344\n",
      "Training loss: 0.275598, accuracy: 0.910156\n",
      "Training loss: 0.260784, accuracy: 0.914063\n",
      "Training loss: 0.253936, accuracy: 0.925781\n",
      "Training loss: 0.250736, accuracy: 0.933594\n",
      "Training loss: 0.228033, accuracy: 0.9375\n",
      "Training loss: 0.212976, accuracy: 0.933594\n",
      "Training loss: 0.204001, accuracy: 0.945313\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.486965, accuracy: 0.796875\n",
      "Training loss: 0.47064, accuracy: 0.804688\n",
      "Training loss: 0.413382, accuracy: 0.84375\n",
      "Training loss: 0.40819, accuracy: 0.839844\n",
      "Training loss: 0.388876, accuracy: 0.851563\n",
      "Training loss: 0.353281, accuracy: 0.871094\n",
      "Training loss: 0.324019, accuracy: 0.871094\n",
      "Training loss: 0.30666, accuracy: 0.878906\n",
      "Training loss: 0.28999, accuracy: 0.898438\n",
      "Training loss: 0.271931, accuracy: 0.910156\n",
      "Training loss: 0.240032, accuracy: 0.914063\n",
      "Training loss: 0.237329, accuracy: 0.929688\n",
      "Training loss: 0.225955, accuracy: 0.929688\n",
      "Training loss: 0.210858, accuracy: 0.933594\n",
      "Training loss: 0.210985, accuracy: 0.941406\n",
      "Training loss: 0.186078, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.445078, accuracy: 0.820313\n",
      "Training loss: 0.42709, accuracy: 0.835938\n",
      "Training loss: 0.411105, accuracy: 0.832031\n",
      "Training loss: 0.393826, accuracy: 0.84375\n",
      "Training loss: 0.366353, accuracy: 0.867188\n",
      "Training loss: 0.319956, accuracy: 0.886719\n",
      "Training loss: 0.314683, accuracy: 0.886719\n",
      "Training loss: 0.29714, accuracy: 0.894531\n",
      "Training loss: 0.264567, accuracy: 0.902344\n",
      "Training loss: 0.25406, accuracy: 0.910156\n",
      "Training loss: 0.230446, accuracy: 0.925781\n",
      "Training loss: 0.211195, accuracy: 0.929688\n",
      "Training loss: 0.18811, accuracy: 0.945313\n",
      "Training loss: 0.17952, accuracy: 0.945313\n",
      "Training loss: 0.178092, accuracy: 0.957031\n",
      "Training loss: 0.158905, accuracy: 0.957031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.49858, accuracy: 0.785156\n",
      "Training loss: 0.442701, accuracy: 0.832031\n",
      "Training loss: 0.402868, accuracy: 0.84375\n",
      "Training loss: 0.332049, accuracy: 0.890625\n",
      "Training loss: 0.334106, accuracy: 0.890625\n",
      "Training loss: 0.315304, accuracy: 0.894531\n",
      "Training loss: 0.296226, accuracy: 0.898438\n",
      "Training loss: 0.274282, accuracy: 0.910156\n",
      "Training loss: 0.267623, accuracy: 0.910156\n",
      "Training loss: 0.260806, accuracy: 0.929688\n",
      "Training loss: 0.240223, accuracy: 0.9375\n",
      "Training loss: 0.234879, accuracy: 0.933594\n",
      "Training loss: 0.229289, accuracy: 0.929688\n",
      "Training loss: 0.209761, accuracy: 0.941406\n",
      "Training loss: 0.210562, accuracy: 0.941406\n",
      "Training loss: 0.207907, accuracy: 0.953125\n",
      "----------------- Step 110: validation accuracy 0.7896 ----------------\n",
      "Training loss: 0.447948, accuracy: 0.832031\n",
      "Training loss: 0.440537, accuracy: 0.828125\n",
      "Training loss: 0.396299, accuracy: 0.859375\n",
      "Training loss: 0.330097, accuracy: 0.894531\n",
      "Training loss: 0.275042, accuracy: 0.886719\n",
      "Training loss: 0.248005, accuracy: 0.917969\n",
      "Training loss: 0.240089, accuracy: 0.929688\n",
      "Training loss: 0.222965, accuracy: 0.9375\n",
      "Training loss: 0.230235, accuracy: 0.933594\n",
      "Training loss: 0.203686, accuracy: 0.9375\n",
      "Training loss: 0.204346, accuracy: 0.945313\n",
      "Training loss: 0.199357, accuracy: 0.945313\n",
      "Training loss: 0.180095, accuracy: 0.953125\n",
      "Training loss: 0.179733, accuracy: 0.953125\n",
      "Training loss: 0.175151, accuracy: 0.953125\n",
      "Training loss: 0.155607, accuracy: 0.960938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.502033, accuracy: 0.792969\n",
      "Training loss: 0.470495, accuracy: 0.8125\n",
      "Training loss: 0.418598, accuracy: 0.839844\n",
      "Training loss: 0.38511, accuracy: 0.851563\n",
      "Training loss: 0.342277, accuracy: 0.863281\n",
      "Training loss: 0.304997, accuracy: 0.882813\n",
      "Training loss: 0.254921, accuracy: 0.917969\n",
      "Training loss: 0.245515, accuracy: 0.917969\n",
      "Training loss: 0.206546, accuracy: 0.9375\n",
      "Training loss: 0.185352, accuracy: 0.953125\n",
      "Training loss: 0.167359, accuracy: 0.960938\n",
      "Training loss: 0.162223, accuracy: 0.960938\n",
      "Training loss: 0.153401, accuracy: 0.960938\n",
      "Training loss: 0.140621, accuracy: 0.964844\n",
      "Training loss: 0.136687, accuracy: 0.960938\n",
      "Training loss: 0.110732, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.589487, accuracy: 0.796875\n",
      "Training loss: 0.533637, accuracy: 0.828125\n",
      "Training loss: 0.474905, accuracy: 0.847656\n",
      "Training loss: 0.413927, accuracy: 0.875\n",
      "Training loss: 0.346781, accuracy: 0.890625\n",
      "Training loss: 0.324332, accuracy: 0.894531\n",
      "Training loss: 0.299804, accuracy: 0.914063\n",
      "Training loss: 0.27013, accuracy: 0.921875\n",
      "Training loss: 0.243165, accuracy: 0.925781\n",
      "Training loss: 0.210384, accuracy: 0.941406\n",
      "Training loss: 0.212507, accuracy: 0.933594\n",
      "Training loss: 0.201383, accuracy: 0.945313\n",
      "Training loss: 0.190364, accuracy: 0.949219\n",
      "Training loss: 0.190124, accuracy: 0.949219\n",
      "Training loss: 0.186826, accuracy: 0.949219\n",
      "Training loss: 0.167453, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.563036, accuracy: 0.777344\n",
      "Training loss: 0.512801, accuracy: 0.792969\n",
      "Training loss: 0.468861, accuracy: 0.816406\n",
      "Training loss: 0.422858, accuracy: 0.84375\n",
      "Training loss: 0.393634, accuracy: 0.847656\n",
      "Training loss: 0.339789, accuracy: 0.871094\n",
      "Training loss: 0.315904, accuracy: 0.894531\n",
      "Training loss: 0.285894, accuracy: 0.910156\n",
      "Training loss: 0.264273, accuracy: 0.925781\n",
      "Training loss: 0.257793, accuracy: 0.917969\n",
      "Training loss: 0.2404, accuracy: 0.9375\n",
      "Training loss: 0.226119, accuracy: 0.941406\n",
      "Training loss: 0.210888, accuracy: 0.953125\n",
      "Training loss: 0.205132, accuracy: 0.953125\n",
      "Training loss: 0.204548, accuracy: 0.953125\n",
      "Training loss: 0.183673, accuracy: 0.960938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.431618, accuracy: 0.808594\n",
      "Training loss: 0.439532, accuracy: 0.835938\n",
      "Training loss: 0.357003, accuracy: 0.851563\n",
      "Training loss: 0.338591, accuracy: 0.871094\n",
      "Training loss: 0.29048, accuracy: 0.898438\n",
      "Training loss: 0.2641, accuracy: 0.90625\n",
      "Training loss: 0.234693, accuracy: 0.925781\n",
      "Training loss: 0.234715, accuracy: 0.9375\n",
      "Training loss: 0.219728, accuracy: 0.949219\n",
      "Training loss: 0.196103, accuracy: 0.941406\n",
      "Training loss: 0.196712, accuracy: 0.953125\n",
      "Training loss: 0.193343, accuracy: 0.960938\n",
      "Training loss: 0.181199, accuracy: 0.957031\n",
      "Training loss: 0.177409, accuracy: 0.953125\n",
      "Training loss: 0.152928, accuracy: 0.960938\n",
      "Training loss: 0.148867, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.511657, accuracy: 0.828125\n",
      "Training loss: 0.445801, accuracy: 0.84375\n",
      "Training loss: 0.377095, accuracy: 0.871094\n",
      "Training loss: 0.377078, accuracy: 0.875\n",
      "Training loss: 0.332718, accuracy: 0.886719\n",
      "Training loss: 0.328807, accuracy: 0.890625\n",
      "Training loss: 0.297722, accuracy: 0.917969\n",
      "Training loss: 0.281251, accuracy: 0.914063\n",
      "Training loss: 0.271162, accuracy: 0.921875\n",
      "Training loss: 0.252723, accuracy: 0.925781\n",
      "Training loss: 0.245217, accuracy: 0.925781\n",
      "Training loss: 0.2314, accuracy: 0.929688\n",
      "Training loss: 0.215078, accuracy: 0.933594\n",
      "Training loss: 0.205666, accuracy: 0.9375\n",
      "Training loss: 0.198324, accuracy: 0.957031\n",
      "Training loss: 0.191096, accuracy: 0.957031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.435905, accuracy: 0.816406\n",
      "Training loss: 0.430145, accuracy: 0.835938\n",
      "Training loss: 0.396619, accuracy: 0.851563\n",
      "Training loss: 0.382972, accuracy: 0.859375\n",
      "Training loss: 0.35034, accuracy: 0.878906\n",
      "Training loss: 0.321462, accuracy: 0.886719\n",
      "Training loss: 0.314597, accuracy: 0.894531\n",
      "Training loss: 0.289679, accuracy: 0.910156\n",
      "Training loss: 0.287592, accuracy: 0.902344\n",
      "Training loss: 0.27611, accuracy: 0.914063\n",
      "Training loss: 0.277005, accuracy: 0.914063\n",
      "Training loss: 0.261787, accuracy: 0.925781\n",
      "Training loss: 0.237714, accuracy: 0.925781\n",
      "Training loss: 0.234485, accuracy: 0.929688\n",
      "Training loss: 0.23173, accuracy: 0.933594\n",
      "Training loss: 0.214284, accuracy: 0.933594\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.643817, accuracy: 0.769531\n",
      "Training loss: 0.623321, accuracy: 0.769531\n",
      "Training loss: 0.5108, accuracy: 0.804688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.440546, accuracy: 0.820313\n",
      "Training loss: 0.398263, accuracy: 0.839844\n",
      "Training loss: 0.339291, accuracy: 0.886719\n",
      "Training loss: 0.312004, accuracy: 0.886719\n",
      "Training loss: 0.301057, accuracy: 0.890625\n",
      "Training loss: 0.292082, accuracy: 0.902344\n",
      "Training loss: 0.285976, accuracy: 0.902344\n",
      "Training loss: 0.274246, accuracy: 0.90625\n",
      "Training loss: 0.249967, accuracy: 0.925781\n",
      "Training loss: 0.241043, accuracy: 0.921875\n",
      "Training loss: 0.211346, accuracy: 0.929688\n",
      "Training loss: 0.215494, accuracy: 0.9375\n",
      "Training loss: 0.194649, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.453053, accuracy: 0.832031\n",
      "Training loss: 0.414341, accuracy: 0.851563\n",
      "Training loss: 0.380257, accuracy: 0.863281\n",
      "Training loss: 0.344443, accuracy: 0.867188\n",
      "Training loss: 0.306954, accuracy: 0.902344\n",
      "Training loss: 0.260015, accuracy: 0.902344\n",
      "Training loss: 0.248931, accuracy: 0.921875\n",
      "Training loss: 0.240329, accuracy: 0.925781\n",
      "Training loss: 0.225134, accuracy: 0.9375\n",
      "Training loss: 0.208467, accuracy: 0.949219\n",
      "Training loss: 0.2104, accuracy: 0.949219\n",
      "Training loss: 0.1875, accuracy: 0.949219\n",
      "Training loss: 0.191959, accuracy: 0.949219\n",
      "Training loss: 0.187966, accuracy: 0.953125\n",
      "Training loss: 0.173711, accuracy: 0.953125\n",
      "Training loss: 0.178111, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.525941, accuracy: 0.785156\n",
      "Training loss: 0.498531, accuracy: 0.796875\n",
      "Training loss: 0.480714, accuracy: 0.8125\n",
      "Training loss: 0.426909, accuracy: 0.828125\n",
      "Training loss: 0.423903, accuracy: 0.84375\n",
      "Training loss: 0.380634, accuracy: 0.855469\n",
      "Training loss: 0.349904, accuracy: 0.867188\n",
      "Training loss: 0.319319, accuracy: 0.890625\n",
      "Training loss: 0.305461, accuracy: 0.902344\n",
      "Training loss: 0.289729, accuracy: 0.902344\n",
      "Training loss: 0.265772, accuracy: 0.910156\n",
      "Training loss: 0.253469, accuracy: 0.917969\n",
      "Training loss: 0.237194, accuracy: 0.933594\n",
      "Training loss: 0.22241, accuracy: 0.941406\n",
      "Training loss: 0.204446, accuracy: 0.945313\n",
      "Training loss: 0.195642, accuracy: 0.953125\n",
      "----------------- Step 120: validation accuracy 0.79984 ----------------\n",
      "Training loss: 0.542626, accuracy: 0.800781\n",
      "Training loss: 0.515931, accuracy: 0.804688\n",
      "Training loss: 0.492321, accuracy: 0.800781\n",
      "Training loss: 0.440256, accuracy: 0.820313\n",
      "Training loss: 0.432264, accuracy: 0.832031\n",
      "Training loss: 0.405315, accuracy: 0.835938\n",
      "Training loss: 0.393633, accuracy: 0.863281\n",
      "Training loss: 0.357523, accuracy: 0.863281\n",
      "Training loss: 0.347306, accuracy: 0.867188\n",
      "Training loss: 0.324752, accuracy: 0.890625\n",
      "Training loss: 0.311461, accuracy: 0.894531\n",
      "Training loss: 0.29002, accuracy: 0.90625\n",
      "Training loss: 0.287498, accuracy: 0.914063\n",
      "Training loss: 0.270046, accuracy: 0.925781\n",
      "Training loss: 0.258111, accuracy: 0.933594\n",
      "Training loss: 0.251362, accuracy: 0.933594\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.430018, accuracy: 0.8125\n",
      "Training loss: 0.4059, accuracy: 0.847656\n",
      "Training loss: 0.401324, accuracy: 0.855469\n",
      "Training loss: 0.35351, accuracy: 0.867188\n",
      "Training loss: 0.315582, accuracy: 0.890625\n",
      "Training loss: 0.286061, accuracy: 0.917969\n",
      "Training loss: 0.265213, accuracy: 0.914063\n",
      "Training loss: 0.263502, accuracy: 0.917969\n",
      "Training loss: 0.261569, accuracy: 0.921875\n",
      "Training loss: 0.259937, accuracy: 0.925781\n",
      "Training loss: 0.246926, accuracy: 0.929688\n",
      "Training loss: 0.236131, accuracy: 0.929688\n",
      "Training loss: 0.223812, accuracy: 0.929688\n",
      "Training loss: 0.238003, accuracy: 0.933594\n",
      "Training loss: 0.211459, accuracy: 0.9375\n",
      "Training loss: 0.202714, accuracy: 0.941406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.434114, accuracy: 0.832031\n",
      "Training loss: 0.409694, accuracy: 0.839844\n",
      "Training loss: 0.35972, accuracy: 0.855469\n",
      "Training loss: 0.3507, accuracy: 0.863281\n",
      "Training loss: 0.329187, accuracy: 0.871094\n",
      "Training loss: 0.307067, accuracy: 0.890625\n",
      "Training loss: 0.292554, accuracy: 0.894531\n",
      "Training loss: 0.251081, accuracy: 0.914063\n",
      "Training loss: 0.248245, accuracy: 0.933594\n",
      "Training loss: 0.230554, accuracy: 0.929688\n",
      "Training loss: 0.220996, accuracy: 0.929688\n",
      "Training loss: 0.21894, accuracy: 0.941406\n",
      "Training loss: 0.194966, accuracy: 0.941406\n",
      "Training loss: 0.198538, accuracy: 0.949219\n",
      "Training loss: 0.179928, accuracy: 0.949219\n",
      "Training loss: 0.176271, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.544181, accuracy: 0.792969\n",
      "Training loss: 0.542534, accuracy: 0.820313\n",
      "Training loss: 0.470446, accuracy: 0.835938\n",
      "Training loss: 0.401052, accuracy: 0.851563\n",
      "Training loss: 0.344115, accuracy: 0.871094\n",
      "Training loss: 0.312002, accuracy: 0.886719\n",
      "Training loss: 0.289001, accuracy: 0.894531\n",
      "Training loss: 0.259916, accuracy: 0.910156\n",
      "Training loss: 0.232447, accuracy: 0.914063\n",
      "Training loss: 0.192651, accuracy: 0.949219\n",
      "Training loss: 0.193969, accuracy: 0.957031\n",
      "Training loss: 0.17995, accuracy: 0.957031\n",
      "Training loss: 0.170891, accuracy: 0.96875\n",
      "Training loss: 0.163821, accuracy: 0.96875\n",
      "Training loss: 0.155009, accuracy: 0.964844\n",
      "Training loss: 0.151032, accuracy: 0.96875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.494722, accuracy: 0.8125\n",
      "Training loss: 0.490051, accuracy: 0.804688\n",
      "Training loss: 0.419919, accuracy: 0.855469\n",
      "Training loss: 0.396174, accuracy: 0.851563\n",
      "Training loss: 0.330921, accuracy: 0.871094\n",
      "Training loss: 0.310083, accuracy: 0.886719\n",
      "Training loss: 0.278718, accuracy: 0.910156\n",
      "Training loss: 0.261122, accuracy: 0.921875\n",
      "Training loss: 0.228103, accuracy: 0.929688\n",
      "Training loss: 0.211078, accuracy: 0.941406\n",
      "Training loss: 0.181085, accuracy: 0.949219\n",
      "Training loss: 0.165792, accuracy: 0.964844\n",
      "Training loss: 0.169159, accuracy: 0.960938\n",
      "Training loss: 0.156909, accuracy: 0.96875\n",
      "Training loss: 0.140958, accuracy: 0.972656\n",
      "Training loss: 0.122225, accuracy: 0.976563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.534291, accuracy: 0.792969\n",
      "Training loss: 0.486502, accuracy: 0.816406\n",
      "Training loss: 0.451674, accuracy: 0.824219\n",
      "Training loss: 0.422905, accuracy: 0.832031\n",
      "Training loss: 0.366444, accuracy: 0.871094\n",
      "Training loss: 0.333571, accuracy: 0.882813\n",
      "Training loss: 0.301713, accuracy: 0.890625\n",
      "Training loss: 0.275421, accuracy: 0.90625\n",
      "Training loss: 0.253331, accuracy: 0.914063\n",
      "Training loss: 0.233618, accuracy: 0.933594\n",
      "Training loss: 0.215858, accuracy: 0.941406\n",
      "Training loss: 0.205406, accuracy: 0.953125\n",
      "Training loss: 0.186443, accuracy: 0.957031\n",
      "Training loss: 0.183991, accuracy: 0.957031\n",
      "Training loss: 0.175386, accuracy: 0.957031\n",
      "Training loss: 0.18643, accuracy: 0.957031\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.454835, accuracy: 0.8125\n",
      "Training loss: 0.383916, accuracy: 0.855469\n",
      "Training loss: 0.335241, accuracy: 0.878906\n",
      "Training loss: 0.322622, accuracy: 0.90625\n",
      "Training loss: 0.273579, accuracy: 0.917969\n",
      "Training loss: 0.237221, accuracy: 0.925781\n",
      "Training loss: 0.231581, accuracy: 0.941406\n",
      "Training loss: 0.210225, accuracy: 0.933594\n",
      "Training loss: 0.209874, accuracy: 0.949219\n",
      "Training loss: 0.193959, accuracy: 0.953125\n",
      "Training loss: 0.188234, accuracy: 0.953125\n",
      "Training loss: 0.175226, accuracy: 0.953125\n",
      "Training loss: 0.169893, accuracy: 0.960938\n",
      "Training loss: 0.15571, accuracy: 0.960938\n",
      "Training loss: 0.140373, accuracy: 0.96875\n",
      "Training loss: 0.132545, accuracy: 0.96875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.550219, accuracy: 0.816406\n",
      "Training loss: 0.515353, accuracy: 0.808594\n",
      "Training loss: 0.475571, accuracy: 0.832031\n",
      "Training loss: 0.437765, accuracy: 0.863281\n",
      "Training loss: 0.386733, accuracy: 0.867188\n",
      "Training loss: 0.336904, accuracy: 0.878906\n",
      "Training loss: 0.303064, accuracy: 0.898438\n",
      "Training loss: 0.29837, accuracy: 0.902344\n",
      "Training loss: 0.260596, accuracy: 0.914063\n",
      "Training loss: 0.267355, accuracy: 0.921875\n",
      "Training loss: 0.237808, accuracy: 0.925781\n",
      "Training loss: 0.231036, accuracy: 0.9375\n",
      "Training loss: 0.220364, accuracy: 0.945313\n",
      "Training loss: 0.201074, accuracy: 0.941406\n",
      "Training loss: 0.211517, accuracy: 0.941406\n",
      "Training loss: 0.19149, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.458589, accuracy: 0.820313\n",
      "Training loss: 0.471073, accuracy: 0.820313\n",
      "Training loss: 0.474363, accuracy: 0.816406\n",
      "Training loss: 0.397701, accuracy: 0.847656\n",
      "Training loss: 0.363134, accuracy: 0.863281\n",
      "Training loss: 0.327826, accuracy: 0.878906\n",
      "Training loss: 0.319477, accuracy: 0.882813\n",
      "Training loss: 0.309489, accuracy: 0.894531\n",
      "Training loss: 0.279189, accuracy: 0.902344\n",
      "Training loss: 0.273351, accuracy: 0.894531\n",
      "Training loss: 0.255081, accuracy: 0.921875\n",
      "Training loss: 0.23894, accuracy: 0.925781\n",
      "Training loss: 0.215544, accuracy: 0.9375\n",
      "Training loss: 0.212362, accuracy: 0.9375\n",
      "Training loss: 0.196004, accuracy: 0.953125\n",
      "Training loss: 0.187276, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.440574, accuracy: 0.839844\n",
      "Training loss: 0.401493, accuracy: 0.859375\n",
      "Training loss: 0.3921, accuracy: 0.863281\n",
      "Training loss: 0.364201, accuracy: 0.882813\n",
      "Training loss: 0.358375, accuracy: 0.875\n",
      "Training loss: 0.313839, accuracy: 0.902344\n",
      "Training loss: 0.300991, accuracy: 0.902344\n",
      "Training loss: 0.306064, accuracy: 0.902344\n",
      "Training loss: 0.270204, accuracy: 0.914063\n",
      "Training loss: 0.267505, accuracy: 0.910156\n",
      "Training loss: 0.256674, accuracy: 0.914063\n",
      "Training loss: 0.242682, accuracy: 0.929688\n",
      "Training loss: 0.232098, accuracy: 0.9375\n",
      "Training loss: 0.199491, accuracy: 0.945313\n",
      "Training loss: 0.197158, accuracy: 0.945313\n",
      "Training loss: 0.191096, accuracy: 0.949219\n",
      "----------------- Step 130: validation accuracy 0.79488 ----------------\n",
      "Training loss: 0.478452, accuracy: 0.8125\n",
      "Training loss: 0.492454, accuracy: 0.824219\n",
      "Training loss: 0.456388, accuracy: 0.832031\n",
      "Training loss: 0.404226, accuracy: 0.847656\n",
      "Training loss: 0.374432, accuracy: 0.875\n",
      "Training loss: 0.355228, accuracy: 0.871094\n",
      "Training loss: 0.337882, accuracy: 0.882813\n",
      "Training loss: 0.318385, accuracy: 0.894531\n",
      "Training loss: 0.289017, accuracy: 0.90625\n",
      "Training loss: 0.278693, accuracy: 0.914063\n",
      "Training loss: 0.265141, accuracy: 0.910156\n",
      "Training loss: 0.261325, accuracy: 0.917969\n",
      "Training loss: 0.249699, accuracy: 0.921875\n",
      "Training loss: 0.255467, accuracy: 0.921875\n",
      "Training loss: 0.24705, accuracy: 0.921875\n",
      "Training loss: 0.249376, accuracy: 0.925781\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.37947, accuracy: 0.863281\n",
      "Training loss: 0.366059, accuracy: 0.867188\n",
      "Training loss: 0.357074, accuracy: 0.871094\n",
      "Training loss: 0.309729, accuracy: 0.90625\n",
      "Training loss: 0.263957, accuracy: 0.914063\n",
      "Training loss: 0.244976, accuracy: 0.925781\n",
      "Training loss: 0.23675, accuracy: 0.933594\n",
      "Training loss: 0.211678, accuracy: 0.941406\n",
      "Training loss: 0.197377, accuracy: 0.949219\n",
      "Training loss: 0.183798, accuracy: 0.957031\n",
      "Training loss: 0.175115, accuracy: 0.960938\n",
      "Training loss: 0.168631, accuracy: 0.960938\n",
      "Training loss: 0.152222, accuracy: 0.964844\n",
      "Training loss: 0.150775, accuracy: 0.964844\n",
      "Training loss: 0.145754, accuracy: 0.964844\n",
      "Training loss: 0.137876, accuracy: 0.964844\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.564044, accuracy: 0.777344\n",
      "Training loss: 0.496314, accuracy: 0.804688\n",
      "Training loss: 0.466898, accuracy: 0.828125\n",
      "Training loss: 0.383709, accuracy: 0.867188\n",
      "Training loss: 0.341193, accuracy: 0.882813\n",
      "Training loss: 0.31155, accuracy: 0.878906\n",
      "Training loss: 0.295139, accuracy: 0.902344\n",
      "Training loss: 0.285483, accuracy: 0.898438\n",
      "Training loss: 0.264042, accuracy: 0.917969\n",
      "Training loss: 0.246595, accuracy: 0.925781\n",
      "Training loss: 0.234415, accuracy: 0.921875\n",
      "Training loss: 0.246197, accuracy: 0.917969\n",
      "Training loss: 0.242362, accuracy: 0.9375\n",
      "Training loss: 0.202941, accuracy: 0.941406\n",
      "Training loss: 0.200531, accuracy: 0.9375\n",
      "Training loss: 0.19545, accuracy: 0.945313\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.406619, accuracy: 0.84375\n",
      "Training loss: 0.381996, accuracy: 0.859375\n",
      "Training loss: 0.374495, accuracy: 0.863281\n",
      "Training loss: 0.321879, accuracy: 0.875\n",
      "Training loss: 0.306989, accuracy: 0.898438\n",
      "Training loss: 0.284428, accuracy: 0.898438\n",
      "Training loss: 0.256295, accuracy: 0.917969\n",
      "Training loss: 0.260543, accuracy: 0.914063\n",
      "Training loss: 0.248645, accuracy: 0.921875\n",
      "Training loss: 0.22239, accuracy: 0.929688\n",
      "Training loss: 0.219752, accuracy: 0.933594\n",
      "Training loss: 0.211223, accuracy: 0.9375\n",
      "Training loss: 0.196887, accuracy: 0.9375\n",
      "Training loss: 0.207572, accuracy: 0.9375\n",
      "Training loss: 0.189879, accuracy: 0.945313\n",
      "Training loss: 0.182972, accuracy: 0.941406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.362446, accuracy: 0.855469\n",
      "Training loss: 0.362046, accuracy: 0.855469\n",
      "Training loss: 0.332461, accuracy: 0.875\n",
      "Training loss: 0.302109, accuracy: 0.894531\n",
      "Training loss: 0.273744, accuracy: 0.90625\n",
      "Training loss: 0.260741, accuracy: 0.910156\n",
      "Training loss: 0.22617, accuracy: 0.914063\n",
      "Training loss: 0.219823, accuracy: 0.917969\n",
      "Training loss: 0.209843, accuracy: 0.933594\n",
      "Training loss: 0.19672, accuracy: 0.941406\n",
      "Training loss: 0.196345, accuracy: 0.941406\n",
      "Training loss: 0.179719, accuracy: 0.941406\n",
      "Training loss: 0.173996, accuracy: 0.945313\n",
      "Training loss: 0.165609, accuracy: 0.953125\n",
      "Training loss: 0.160915, accuracy: 0.953125\n",
      "Training loss: 0.148363, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.425441, accuracy: 0.875\n",
      "Training loss: 0.356416, accuracy: 0.875\n",
      "Training loss: 0.364643, accuracy: 0.890625\n",
      "Training loss: 0.316819, accuracy: 0.894531\n",
      "Training loss: 0.299913, accuracy: 0.90625\n",
      "Training loss: 0.268854, accuracy: 0.914063\n",
      "Training loss: 0.239088, accuracy: 0.925781\n",
      "Training loss: 0.21503, accuracy: 0.933594\n",
      "Training loss: 0.186458, accuracy: 0.941406\n",
      "Training loss: 0.179152, accuracy: 0.949219\n",
      "Training loss: 0.168855, accuracy: 0.949219\n",
      "Training loss: 0.152374, accuracy: 0.953125\n",
      "Training loss: 0.144073, accuracy: 0.96875\n",
      "Training loss: 0.143683, accuracy: 0.96875\n",
      "Training loss: 0.131323, accuracy: 0.972656\n",
      "Training loss: 0.127275, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.477572, accuracy: 0.847656\n",
      "Training loss: 0.432866, accuracy: 0.847656\n",
      "Training loss: 0.406911, accuracy: 0.863281\n",
      "Training loss: 0.392923, accuracy: 0.875\n",
      "Training loss: 0.342403, accuracy: 0.890625\n",
      "Training loss: 0.33352, accuracy: 0.894531\n",
      "Training loss: 0.33119, accuracy: 0.894531\n",
      "Training loss: 0.3058, accuracy: 0.898438\n",
      "Training loss: 0.287096, accuracy: 0.898438\n",
      "Training loss: 0.272499, accuracy: 0.902344\n",
      "Training loss: 0.255635, accuracy: 0.917969\n",
      "Training loss: 0.239333, accuracy: 0.929688\n",
      "Training loss: 0.217979, accuracy: 0.929688\n",
      "Training loss: 0.238188, accuracy: 0.9375\n",
      "Training loss: 0.224361, accuracy: 0.9375\n",
      "Training loss: 0.19985, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.487125, accuracy: 0.828125\n",
      "Training loss: 0.450839, accuracy: 0.839844\n",
      "Training loss: 0.429315, accuracy: 0.847656\n",
      "Training loss: 0.402252, accuracy: 0.855469\n",
      "Training loss: 0.372861, accuracy: 0.867188\n",
      "Training loss: 0.369361, accuracy: 0.875\n",
      "Training loss: 0.379501, accuracy: 0.875\n",
      "Training loss: 0.349553, accuracy: 0.875\n",
      "Training loss: 0.358806, accuracy: 0.882813\n",
      "Training loss: 0.338575, accuracy: 0.878906\n",
      "Training loss: 0.335372, accuracy: 0.890625\n",
      "Training loss: 0.325541, accuracy: 0.886719\n",
      "Training loss: 0.323488, accuracy: 0.882813\n",
      "Training loss: 0.300838, accuracy: 0.90625\n",
      "Training loss: 0.293266, accuracy: 0.90625\n",
      "Training loss: 0.283347, accuracy: 0.914063\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.41359, accuracy: 0.835938\n",
      "Training loss: 0.424158, accuracy: 0.828125\n",
      "Training loss: 0.370694, accuracy: 0.851563\n",
      "Training loss: 0.364368, accuracy: 0.863281\n",
      "Training loss: 0.34759, accuracy: 0.871094\n",
      "Training loss: 0.325962, accuracy: 0.859375\n",
      "Training loss: 0.299599, accuracy: 0.894531\n",
      "Training loss: 0.274659, accuracy: 0.902344\n",
      "Training loss: 0.270393, accuracy: 0.914063\n",
      "Training loss: 0.258306, accuracy: 0.90625\n",
      "Training loss: 0.226914, accuracy: 0.925781\n",
      "Training loss: 0.230334, accuracy: 0.925781\n",
      "Training loss: 0.220291, accuracy: 0.925781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.207561, accuracy: 0.9375\n",
      "Training loss: 0.20583, accuracy: 0.945313\n",
      "Training loss: 0.19048, accuracy: 0.945313\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.43399, accuracy: 0.824219\n",
      "Training loss: 0.430425, accuracy: 0.816406\n",
      "Training loss: 0.413607, accuracy: 0.835938\n",
      "Training loss: 0.386669, accuracy: 0.828125\n",
      "Training loss: 0.36627, accuracy: 0.851563\n",
      "Training loss: 0.324076, accuracy: 0.878906\n",
      "Training loss: 0.296103, accuracy: 0.890625\n",
      "Training loss: 0.277441, accuracy: 0.910156\n",
      "Training loss: 0.250591, accuracy: 0.910156\n",
      "Training loss: 0.239396, accuracy: 0.933594\n",
      "Training loss: 0.22426, accuracy: 0.929688\n",
      "Training loss: 0.212751, accuracy: 0.945313\n",
      "Training loss: 0.201709, accuracy: 0.941406\n",
      "Training loss: 0.203578, accuracy: 0.941406\n",
      "Training loss: 0.185935, accuracy: 0.949219\n",
      "Training loss: 0.170871, accuracy: 0.957031\n",
      "----------------- Step 140: validation accuracy 0.80704 ----------------\n",
      "Training loss: 0.501637, accuracy: 0.785156\n",
      "Training loss: 0.485052, accuracy: 0.808594\n",
      "Training loss: 0.465565, accuracy: 0.816406\n",
      "Training loss: 0.404441, accuracy: 0.839844\n",
      "Training loss: 0.355479, accuracy: 0.867188\n",
      "Training loss: 0.346252, accuracy: 0.875\n",
      "Training loss: 0.31854, accuracy: 0.882813\n",
      "Training loss: 0.306418, accuracy: 0.878906\n",
      "Training loss: 0.287031, accuracy: 0.90625\n",
      "Training loss: 0.282561, accuracy: 0.898438\n",
      "Training loss: 0.25297, accuracy: 0.914063\n",
      "Training loss: 0.259473, accuracy: 0.914063\n",
      "Training loss: 0.253966, accuracy: 0.914063\n",
      "Training loss: 0.227837, accuracy: 0.921875\n",
      "Training loss: 0.221333, accuracy: 0.933594\n",
      "Training loss: 0.217311, accuracy: 0.945313\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.372083, accuracy: 0.855469\n",
      "Training loss: 0.342881, accuracy: 0.875\n",
      "Training loss: 0.320757, accuracy: 0.886719\n",
      "Training loss: 0.265419, accuracy: 0.90625\n",
      "Training loss: 0.237815, accuracy: 0.910156\n",
      "Training loss: 0.207661, accuracy: 0.9375\n",
      "Training loss: 0.198467, accuracy: 0.9375\n",
      "Training loss: 0.180895, accuracy: 0.953125\n",
      "Training loss: 0.173094, accuracy: 0.960938\n",
      "Training loss: 0.162406, accuracy: 0.960938\n",
      "Training loss: 0.163173, accuracy: 0.964844\n",
      "Training loss: 0.156737, accuracy: 0.96875\n",
      "Training loss: 0.14908, accuracy: 0.972656\n",
      "Training loss: 0.130799, accuracy: 0.972656\n",
      "Training loss: 0.123007, accuracy: 0.972656\n",
      "Training loss: 0.112732, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.445495, accuracy: 0.824219\n",
      "Training loss: 0.419112, accuracy: 0.839844\n",
      "Training loss: 0.349475, accuracy: 0.84375\n",
      "Training loss: 0.326616, accuracy: 0.886719\n",
      "Training loss: 0.253144, accuracy: 0.917969\n",
      "Training loss: 0.251923, accuracy: 0.917969\n",
      "Training loss: 0.221682, accuracy: 0.925781\n",
      "Training loss: 0.206718, accuracy: 0.9375\n",
      "Training loss: 0.196911, accuracy: 0.949219\n",
      "Training loss: 0.177773, accuracy: 0.945313\n",
      "Training loss: 0.184058, accuracy: 0.949219\n",
      "Training loss: 0.158532, accuracy: 0.953125\n",
      "Training loss: 0.147984, accuracy: 0.964844\n",
      "Training loss: 0.140794, accuracy: 0.960938\n",
      "Training loss: 0.130823, accuracy: 0.96875\n",
      "Training loss: 0.120434, accuracy: 0.96875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.552877, accuracy: 0.773438\n",
      "Training loss: 0.493427, accuracy: 0.824219\n",
      "Training loss: 0.449799, accuracy: 0.832031\n",
      "Training loss: 0.404121, accuracy: 0.855469\n",
      "Training loss: 0.38024, accuracy: 0.871094\n",
      "Training loss: 0.339821, accuracy: 0.882813\n",
      "Training loss: 0.301953, accuracy: 0.894531\n",
      "Training loss: 0.286765, accuracy: 0.910156\n",
      "Training loss: 0.267167, accuracy: 0.914063\n",
      "Training loss: 0.240157, accuracy: 0.921875\n",
      "Training loss: 0.245885, accuracy: 0.921875\n",
      "Training loss: 0.22101, accuracy: 0.929688\n",
      "Training loss: 0.206067, accuracy: 0.929688\n",
      "Training loss: 0.21258, accuracy: 0.9375\n",
      "Training loss: 0.203534, accuracy: 0.941406\n",
      "Training loss: 0.204061, accuracy: 0.941406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.485098, accuracy: 0.851563\n",
      "Training loss: 0.44545, accuracy: 0.863281\n",
      "Training loss: 0.410953, accuracy: 0.878906\n",
      "Training loss: 0.406459, accuracy: 0.894531\n",
      "Training loss: 0.354066, accuracy: 0.882813\n",
      "Training loss: 0.336945, accuracy: 0.890625\n",
      "Training loss: 0.311236, accuracy: 0.914063\n",
      "Training loss: 0.27348, accuracy: 0.90625\n",
      "Training loss: 0.256245, accuracy: 0.925781\n",
      "Training loss: 0.245651, accuracy: 0.925781\n",
      "Training loss: 0.235052, accuracy: 0.933594\n",
      "Training loss: 0.226137, accuracy: 0.945313\n",
      "Training loss: 0.231352, accuracy: 0.9375\n",
      "Training loss: 0.232279, accuracy: 0.941406\n",
      "Training loss: 0.212139, accuracy: 0.945313\n",
      "Training loss: 0.211015, accuracy: 0.945313\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.442987, accuracy: 0.820313\n",
      "Training loss: 0.419364, accuracy: 0.835938\n",
      "Training loss: 0.392757, accuracy: 0.84375\n",
      "Training loss: 0.341159, accuracy: 0.882813\n",
      "Training loss: 0.315349, accuracy: 0.890625\n",
      "Training loss: 0.295698, accuracy: 0.898438\n",
      "Training loss: 0.279112, accuracy: 0.90625\n",
      "Training loss: 0.275372, accuracy: 0.921875\n",
      "Training loss: 0.249982, accuracy: 0.925781\n",
      "Training loss: 0.239376, accuracy: 0.933594\n",
      "Training loss: 0.240213, accuracy: 0.933594\n",
      "Training loss: 0.225085, accuracy: 0.9375\n",
      "Training loss: 0.227449, accuracy: 0.933594\n",
      "Training loss: 0.216054, accuracy: 0.941406\n",
      "Training loss: 0.214188, accuracy: 0.949219\n",
      "Training loss: 0.19993, accuracy: 0.945313\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.279722, accuracy: 0.902344\n",
      "Training loss: 0.267739, accuracy: 0.914063\n",
      "Training loss: 0.265886, accuracy: 0.917969\n",
      "Training loss: 0.252286, accuracy: 0.921875\n",
      "Training loss: 0.237684, accuracy: 0.921875\n",
      "Training loss: 0.213882, accuracy: 0.9375\n",
      "Training loss: 0.200967, accuracy: 0.941406\n",
      "Training loss: 0.185124, accuracy: 0.949219\n",
      "Training loss: 0.174432, accuracy: 0.957031\n",
      "Training loss: 0.1708, accuracy: 0.957031\n",
      "Training loss: 0.155847, accuracy: 0.957031\n",
      "Training loss: 0.158926, accuracy: 0.960938\n",
      "Training loss: 0.151811, accuracy: 0.960938\n",
      "Training loss: 0.151593, accuracy: 0.957031\n",
      "Training loss: 0.13276, accuracy: 0.964844\n",
      "Training loss: 0.126735, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.419171, accuracy: 0.855469\n",
      "Training loss: 0.400815, accuracy: 0.867188\n",
      "Training loss: 0.376031, accuracy: 0.875\n",
      "Training loss: 0.352214, accuracy: 0.878906\n",
      "Training loss: 0.323765, accuracy: 0.882813\n",
      "Training loss: 0.294611, accuracy: 0.910156\n",
      "Training loss: 0.286562, accuracy: 0.910156\n",
      "Training loss: 0.270195, accuracy: 0.910156\n",
      "Training loss: 0.259259, accuracy: 0.921875\n",
      "Training loss: 0.227828, accuracy: 0.917969\n",
      "Training loss: 0.216114, accuracy: 0.925781\n",
      "Training loss: 0.215776, accuracy: 0.933594\n",
      "Training loss: 0.198567, accuracy: 0.941406\n",
      "Training loss: 0.186784, accuracy: 0.941406\n",
      "Training loss: 0.175509, accuracy: 0.953125\n",
      "Training loss: 0.172089, accuracy: 0.941406\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.687725, accuracy: 0.757813\n",
      "Training loss: 0.623255, accuracy: 0.765625\n",
      "Training loss: 0.582385, accuracy: 0.785156\n",
      "Training loss: 0.504667, accuracy: 0.824219\n",
      "Training loss: 0.444384, accuracy: 0.835938\n",
      "Training loss: 0.398331, accuracy: 0.847656\n",
      "Training loss: 0.363603, accuracy: 0.875\n",
      "Training loss: 0.326996, accuracy: 0.890625\n",
      "Training loss: 0.313247, accuracy: 0.894531\n",
      "Training loss: 0.29507, accuracy: 0.886719\n",
      "Training loss: 0.282064, accuracy: 0.910156\n",
      "Training loss: 0.273898, accuracy: 0.910156\n",
      "Training loss: 0.253728, accuracy: 0.90625\n",
      "Training loss: 0.243899, accuracy: 0.917969\n",
      "Training loss: 0.250227, accuracy: 0.90625\n",
      "Training loss: 0.24769, accuracy: 0.914063\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.352578, accuracy: 0.859375\n",
      "Training loss: 0.358673, accuracy: 0.847656\n",
      "Training loss: 0.32053, accuracy: 0.867188\n",
      "Training loss: 0.29378, accuracy: 0.878906\n",
      "Training loss: 0.28895, accuracy: 0.882813\n",
      "Training loss: 0.265258, accuracy: 0.910156\n",
      "Training loss: 0.249917, accuracy: 0.90625\n",
      "Training loss: 0.231426, accuracy: 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.231727, accuracy: 0.929688\n",
      "Training loss: 0.217853, accuracy: 0.929688\n",
      "Training loss: 0.210812, accuracy: 0.9375\n",
      "Training loss: 0.192634, accuracy: 0.945313\n",
      "Training loss: 0.190544, accuracy: 0.941406\n",
      "Training loss: 0.176375, accuracy: 0.949219\n",
      "Training loss: 0.174283, accuracy: 0.953125\n",
      "Training loss: 0.16391, accuracy: 0.953125\n",
      "----------------- Step 150: validation accuracy 0.8136 ----------------\n",
      "Training loss: 0.468232, accuracy: 0.820313\n",
      "Training loss: 0.428016, accuracy: 0.847656\n",
      "Training loss: 0.430403, accuracy: 0.832031\n",
      "Training loss: 0.40559, accuracy: 0.859375\n",
      "Training loss: 0.366266, accuracy: 0.878906\n",
      "Training loss: 0.376308, accuracy: 0.875\n",
      "Training loss: 0.339282, accuracy: 0.890625\n",
      "Training loss: 0.307437, accuracy: 0.898438\n",
      "Training loss: 0.298344, accuracy: 0.90625\n",
      "Training loss: 0.27729, accuracy: 0.902344\n",
      "Training loss: 0.277976, accuracy: 0.914063\n",
      "Training loss: 0.274143, accuracy: 0.921875\n",
      "Training loss: 0.252331, accuracy: 0.921875\n",
      "Training loss: 0.242368, accuracy: 0.933594\n",
      "Training loss: 0.230089, accuracy: 0.933594\n",
      "Training loss: 0.227214, accuracy: 0.9375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.442111, accuracy: 0.832031\n",
      "Training loss: 0.431584, accuracy: 0.835938\n",
      "Training loss: 0.384704, accuracy: 0.839844\n",
      "Training loss: 0.376593, accuracy: 0.855469\n",
      "Training loss: 0.33045, accuracy: 0.871094\n",
      "Training loss: 0.286613, accuracy: 0.902344\n",
      "Training loss: 0.257354, accuracy: 0.910156\n",
      "Training loss: 0.251006, accuracy: 0.914063\n",
      "Training loss: 0.23343, accuracy: 0.929688\n",
      "Training loss: 0.216658, accuracy: 0.9375\n",
      "Training loss: 0.210822, accuracy: 0.941406\n",
      "Training loss: 0.200553, accuracy: 0.945313\n",
      "Training loss: 0.184122, accuracy: 0.949219\n",
      "Training loss: 0.174171, accuracy: 0.957031\n",
      "Training loss: 0.158916, accuracy: 0.964844\n",
      "Training loss: 0.155485, accuracy: 0.964844\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.400374, accuracy: 0.832031\n",
      "Training loss: 0.379337, accuracy: 0.851563\n",
      "Training loss: 0.349911, accuracy: 0.847656\n",
      "Training loss: 0.336748, accuracy: 0.859375\n",
      "Training loss: 0.2987, accuracy: 0.890625\n",
      "Training loss: 0.282179, accuracy: 0.90625\n",
      "Training loss: 0.251054, accuracy: 0.917969\n",
      "Training loss: 0.2206, accuracy: 0.933594\n",
      "Training loss: 0.216441, accuracy: 0.9375\n",
      "Training loss: 0.211832, accuracy: 0.933594\n",
      "Training loss: 0.202203, accuracy: 0.941406\n",
      "Training loss: 0.17475, accuracy: 0.945313\n",
      "Training loss: 0.176079, accuracy: 0.949219\n",
      "Training loss: 0.166918, accuracy: 0.949219\n",
      "Training loss: 0.157172, accuracy: 0.953125\n",
      "Training loss: 0.144013, accuracy: 0.960938\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.414864, accuracy: 0.855469\n",
      "Training loss: 0.403312, accuracy: 0.855469\n",
      "Training loss: 0.373239, accuracy: 0.859375\n",
      "Training loss: 0.314813, accuracy: 0.886719\n",
      "Training loss: 0.302551, accuracy: 0.894531\n",
      "Training loss: 0.280274, accuracy: 0.910156\n",
      "Training loss: 0.258805, accuracy: 0.910156\n",
      "Training loss: 0.243703, accuracy: 0.929688\n",
      "Training loss: 0.227874, accuracy: 0.933594\n",
      "Training loss: 0.220406, accuracy: 0.941406\n",
      "Training loss: 0.212463, accuracy: 0.945313\n",
      "Training loss: 0.200152, accuracy: 0.945313\n",
      "Training loss: 0.196391, accuracy: 0.949219\n",
      "Training loss: 0.202382, accuracy: 0.949219\n",
      "Training loss: 0.197654, accuracy: 0.945313\n",
      "Training loss: 0.180888, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.505719, accuracy: 0.8125\n",
      "Training loss: 0.485761, accuracy: 0.8125\n",
      "Training loss: 0.433806, accuracy: 0.839844\n",
      "Training loss: 0.404275, accuracy: 0.851563\n",
      "Training loss: 0.3752, accuracy: 0.863281\n",
      "Training loss: 0.334737, accuracy: 0.871094\n",
      "Training loss: 0.314668, accuracy: 0.886719\n",
      "Training loss: 0.299318, accuracy: 0.890625\n",
      "Training loss: 0.259962, accuracy: 0.902344\n",
      "Training loss: 0.25368, accuracy: 0.917969\n",
      "Training loss: 0.242665, accuracy: 0.929688\n",
      "Training loss: 0.233077, accuracy: 0.9375\n",
      "Training loss: 0.228758, accuracy: 0.9375\n",
      "Training loss: 0.203129, accuracy: 0.945313\n",
      "Training loss: 0.187584, accuracy: 0.953125\n",
      "Training loss: 0.184335, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.340845, accuracy: 0.855469\n",
      "Training loss: 0.323945, accuracy: 0.878906\n",
      "Training loss: 0.26701, accuracy: 0.898438\n",
      "Training loss: 0.232211, accuracy: 0.9375\n",
      "Training loss: 0.225915, accuracy: 0.933594\n",
      "Training loss: 0.21518, accuracy: 0.941406\n",
      "Training loss: 0.206693, accuracy: 0.945313\n",
      "Training loss: 0.186213, accuracy: 0.945313\n",
      "Training loss: 0.186034, accuracy: 0.949219\n",
      "Training loss: 0.166394, accuracy: 0.960938\n",
      "Training loss: 0.164092, accuracy: 0.960938\n",
      "Training loss: 0.155562, accuracy: 0.964844\n",
      "Training loss: 0.145224, accuracy: 0.964844\n",
      "Training loss: 0.142049, accuracy: 0.957031\n",
      "Training loss: 0.148091, accuracy: 0.96875\n",
      "Training loss: 0.131985, accuracy: 0.96875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.480258, accuracy: 0.820313\n",
      "Training loss: 0.435493, accuracy: 0.847656\n",
      "Training loss: 0.377011, accuracy: 0.855469\n",
      "Training loss: 0.316091, accuracy: 0.871094\n",
      "Training loss: 0.291407, accuracy: 0.898438\n",
      "Training loss: 0.255783, accuracy: 0.898438\n",
      "Training loss: 0.255069, accuracy: 0.902344\n",
      "Training loss: 0.236489, accuracy: 0.917969\n",
      "Training loss: 0.231425, accuracy: 0.914063\n",
      "Training loss: 0.214862, accuracy: 0.933594\n",
      "Training loss: 0.208351, accuracy: 0.921875\n",
      "Training loss: 0.200741, accuracy: 0.933594\n",
      "Training loss: 0.164422, accuracy: 0.953125\n",
      "Training loss: 0.154726, accuracy: 0.957031\n",
      "Training loss: 0.145283, accuracy: 0.957031\n",
      "Training loss: 0.131499, accuracy: 0.976563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.425797, accuracy: 0.816406\n",
      "Training loss: 0.402683, accuracy: 0.839844\n",
      "Training loss: 0.389466, accuracy: 0.835938\n",
      "Training loss: 0.319717, accuracy: 0.863281\n",
      "Training loss: 0.312456, accuracy: 0.855469\n",
      "Training loss: 0.26398, accuracy: 0.890625\n",
      "Training loss: 0.252526, accuracy: 0.917969\n",
      "Training loss: 0.230247, accuracy: 0.929688\n",
      "Training loss: 0.203278, accuracy: 0.9375\n",
      "Training loss: 0.193736, accuracy: 0.929688\n",
      "Training loss: 0.181875, accuracy: 0.941406\n",
      "Training loss: 0.164085, accuracy: 0.953125\n",
      "Training loss: 0.153113, accuracy: 0.957031\n",
      "Training loss: 0.14128, accuracy: 0.960938\n",
      "Training loss: 0.127395, accuracy: 0.976563\n",
      "Training loss: 0.124509, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.458251, accuracy: 0.832031\n",
      "Training loss: 0.43047, accuracy: 0.847656\n",
      "Training loss: 0.421551, accuracy: 0.855469\n",
      "Training loss: 0.397077, accuracy: 0.855469\n",
      "Training loss: 0.343955, accuracy: 0.871094\n",
      "Training loss: 0.342095, accuracy: 0.878906\n",
      "Training loss: 0.30256, accuracy: 0.886719\n",
      "Training loss: 0.303461, accuracy: 0.890625\n",
      "Training loss: 0.249505, accuracy: 0.910156\n",
      "Training loss: 0.261634, accuracy: 0.90625\n",
      "Training loss: 0.239356, accuracy: 0.910156\n",
      "Training loss: 0.210064, accuracy: 0.921875\n",
      "Training loss: 0.199253, accuracy: 0.929688\n",
      "Training loss: 0.17726, accuracy: 0.933594\n",
      "Training loss: 0.161502, accuracy: 0.953125\n",
      "Training loss: 0.142973, accuracy: 0.953125\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.308465, accuracy: 0.890625\n",
      "Training loss: 0.289625, accuracy: 0.882813\n",
      "Training loss: 0.271883, accuracy: 0.898438\n",
      "Training loss: 0.252422, accuracy: 0.894531\n",
      "Training loss: 0.24607, accuracy: 0.90625\n",
      "Training loss: 0.203635, accuracy: 0.933594\n",
      "Training loss: 0.196323, accuracy: 0.941406\n",
      "Training loss: 0.168596, accuracy: 0.953125\n",
      "Training loss: 0.175423, accuracy: 0.957031\n",
      "Training loss: 0.162054, accuracy: 0.953125\n",
      "Training loss: 0.143327, accuracy: 0.964844\n",
      "Training loss: 0.149834, accuracy: 0.960938\n",
      "Training loss: 0.133131, accuracy: 0.972656\n",
      "Training loss: 0.130632, accuracy: 0.972656\n",
      "Training loss: 0.123666, accuracy: 0.96875\n",
      "Training loss: 0.113792, accuracy: 0.972656\n",
      "----------------- Step 160: validation accuracy 0.83072 ----------------\n",
      "Training loss: 0.567092, accuracy: 0.796875\n",
      "Training loss: 0.542526, accuracy: 0.8125\n",
      "Training loss: 0.472353, accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.418806, accuracy: 0.855469\n",
      "Training loss: 0.329528, accuracy: 0.867188\n",
      "Training loss: 0.29552, accuracy: 0.886719\n",
      "Training loss: 0.285838, accuracy: 0.898438\n",
      "Training loss: 0.274361, accuracy: 0.886719\n",
      "Training loss: 0.242351, accuracy: 0.910156\n",
      "Training loss: 0.23819, accuracy: 0.925781\n",
      "Training loss: 0.219522, accuracy: 0.933594\n",
      "Training loss: 0.212757, accuracy: 0.933594\n",
      "Training loss: 0.204591, accuracy: 0.945313\n",
      "Training loss: 0.188965, accuracy: 0.945313\n",
      "Training loss: 0.185845, accuracy: 0.941406\n",
      "Training loss: 0.173388, accuracy: 0.949219\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.337209, accuracy: 0.894531\n",
      "Training loss: 0.314046, accuracy: 0.871094\n",
      "Training loss: 0.284932, accuracy: 0.890625\n",
      "Training loss: 0.276321, accuracy: 0.910156\n",
      "Training loss: 0.232785, accuracy: 0.914063\n",
      "Training loss: 0.206644, accuracy: 0.925781\n",
      "Training loss: 0.18139, accuracy: 0.945313\n",
      "Training loss: 0.164313, accuracy: 0.957031\n",
      "Training loss: 0.160689, accuracy: 0.957031\n",
      "Training loss: 0.147859, accuracy: 0.957031\n",
      "Training loss: 0.133516, accuracy: 0.96875\n",
      "Training loss: 0.126637, accuracy: 0.964844\n",
      "Training loss: 0.120143, accuracy: 0.972656\n",
      "Training loss: 0.112753, accuracy: 0.972656\n",
      "Training loss: 0.102111, accuracy: 0.976563\n",
      "Training loss: 0.0918615, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.274058, accuracy: 0.902344\n",
      "Training loss: 0.272897, accuracy: 0.90625\n",
      "Training loss: 0.229924, accuracy: 0.910156\n",
      "Training loss: 0.203607, accuracy: 0.914063\n",
      "Training loss: 0.170925, accuracy: 0.9375\n",
      "Training loss: 0.151308, accuracy: 0.949219\n",
      "Training loss: 0.123841, accuracy: 0.964844\n",
      "Training loss: 0.105744, accuracy: 0.964844\n",
      "Training loss: 0.0919107, accuracy: 0.976563\n",
      "Training loss: 0.0779315, accuracy: 0.984375\n",
      "Training loss: 0.0746166, accuracy: 0.988281\n",
      "Training loss: 0.0693701, accuracy: 0.988281\n",
      "Training loss: 0.0632119, accuracy: 0.992188\n",
      "Training loss: 0.0580695, accuracy: 0.992188\n",
      "Training loss: 0.0551177, accuracy: 0.992188\n",
      "Training loss: 0.0547424, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.294699, accuracy: 0.894531\n",
      "Training loss: 0.292869, accuracy: 0.902344\n",
      "Training loss: 0.270957, accuracy: 0.914063\n",
      "Training loss: 0.224263, accuracy: 0.9375\n",
      "Training loss: 0.181157, accuracy: 0.933594\n",
      "Training loss: 0.130788, accuracy: 0.957031\n",
      "Training loss: 0.120963, accuracy: 0.964844\n",
      "Training loss: 0.0937466, accuracy: 0.972656\n",
      "Training loss: 0.0813853, accuracy: 0.984375\n",
      "Training loss: 0.0799488, accuracy: 0.980469\n",
      "Training loss: 0.0719984, accuracy: 0.988281\n",
      "Training loss: 0.0652113, accuracy: 0.988281\n",
      "Training loss: 0.0630671, accuracy: 0.992188\n",
      "Training loss: 0.0613348, accuracy: 0.992188\n",
      "Training loss: 0.0537776, accuracy: 0.992188\n",
      "Training loss: 0.0506605, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.226073, accuracy: 0.90625\n",
      "Training loss: 0.198134, accuracy: 0.917969\n",
      "Training loss: 0.18271, accuracy: 0.929688\n",
      "Training loss: 0.166212, accuracy: 0.953125\n",
      "Training loss: 0.149521, accuracy: 0.953125\n",
      "Training loss: 0.119343, accuracy: 0.96875\n",
      "Training loss: 0.105668, accuracy: 0.972656\n",
      "Training loss: 0.105551, accuracy: 0.972656\n",
      "Training loss: 0.0919651, accuracy: 0.980469\n",
      "Training loss: 0.0894701, accuracy: 0.976563\n",
      "Training loss: 0.0789876, accuracy: 0.976563\n",
      "Training loss: 0.0766506, accuracy: 0.980469\n",
      "Training loss: 0.0694203, accuracy: 0.980469\n",
      "Training loss: 0.0633358, accuracy: 0.988281\n",
      "Training loss: 0.0539921, accuracy: 0.988281\n",
      "Training loss: 0.0530842, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.400299, accuracy: 0.894531\n",
      "Training loss: 0.327885, accuracy: 0.902344\n",
      "Training loss: 0.301249, accuracy: 0.902344\n",
      "Training loss: 0.234645, accuracy: 0.929688\n",
      "Training loss: 0.205952, accuracy: 0.941406\n",
      "Training loss: 0.189092, accuracy: 0.949219\n",
      "Training loss: 0.167134, accuracy: 0.953125\n",
      "Training loss: 0.151856, accuracy: 0.964844\n",
      "Training loss: 0.141193, accuracy: 0.96875\n",
      "Training loss: 0.135039, accuracy: 0.96875\n",
      "Training loss: 0.139374, accuracy: 0.96875\n",
      "Training loss: 0.12009, accuracy: 0.96875\n",
      "Training loss: 0.126575, accuracy: 0.972656\n",
      "Training loss: 0.115449, accuracy: 0.972656\n",
      "Training loss: 0.10212, accuracy: 0.972656\n",
      "Training loss: 0.10183, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.256843, accuracy: 0.917969\n",
      "Training loss: 0.236725, accuracy: 0.917969\n",
      "Training loss: 0.216079, accuracy: 0.9375\n",
      "Training loss: 0.176311, accuracy: 0.949219\n",
      "Training loss: 0.177775, accuracy: 0.945313\n",
      "Training loss: 0.146906, accuracy: 0.960938\n",
      "Training loss: 0.13413, accuracy: 0.960938\n",
      "Training loss: 0.121723, accuracy: 0.964844\n",
      "Training loss: 0.119379, accuracy: 0.964844\n",
      "Training loss: 0.106177, accuracy: 0.964844\n",
      "Training loss: 0.104353, accuracy: 0.972656\n",
      "Training loss: 0.0856186, accuracy: 0.976563\n",
      "Training loss: 0.065771, accuracy: 0.980469\n",
      "Training loss: 0.0549377, accuracy: 0.988281\n",
      "Training loss: 0.0480783, accuracy: 0.992188\n",
      "Training loss: 0.0448269, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.249134, accuracy: 0.910156\n",
      "Training loss: 0.224253, accuracy: 0.921875\n",
      "Training loss: 0.202176, accuracy: 0.925781\n",
      "Training loss: 0.179871, accuracy: 0.941406\n",
      "Training loss: 0.160976, accuracy: 0.941406\n",
      "Training loss: 0.137715, accuracy: 0.960938\n",
      "Training loss: 0.133966, accuracy: 0.964844\n",
      "Training loss: 0.114711, accuracy: 0.96875\n",
      "Training loss: 0.104134, accuracy: 0.96875\n",
      "Training loss: 0.0853393, accuracy: 0.976563\n",
      "Training loss: 0.0865818, accuracy: 0.976563\n",
      "Training loss: 0.0784482, accuracy: 0.976563\n",
      "Training loss: 0.074101, accuracy: 0.980469\n",
      "Training loss: 0.0584724, accuracy: 0.980469\n",
      "Training loss: 0.059194, accuracy: 0.984375\n",
      "Training loss: 0.0509788, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.251473, accuracy: 0.90625\n",
      "Training loss: 0.260663, accuracy: 0.914063\n",
      "Training loss: 0.20517, accuracy: 0.941406\n",
      "Training loss: 0.183095, accuracy: 0.941406\n",
      "Training loss: 0.160537, accuracy: 0.953125\n",
      "Training loss: 0.125991, accuracy: 0.953125\n",
      "Training loss: 0.105185, accuracy: 0.972656\n",
      "Training loss: 0.0943763, accuracy: 0.976563\n",
      "Training loss: 0.0823024, accuracy: 0.976563\n",
      "Training loss: 0.0754117, accuracy: 0.980469\n",
      "Training loss: 0.0616424, accuracy: 0.988281\n",
      "Training loss: 0.0518652, accuracy: 0.988281\n",
      "Training loss: 0.0561782, accuracy: 0.988281\n",
      "Training loss: 0.0532051, accuracy: 0.988281\n",
      "Training loss: 0.051695, accuracy: 0.988281\n",
      "Training loss: 0.046809, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.241202, accuracy: 0.9375\n",
      "Training loss: 0.208471, accuracy: 0.9375\n",
      "Training loss: 0.189067, accuracy: 0.9375\n",
      "Training loss: 0.168931, accuracy: 0.945313\n",
      "Training loss: 0.14088, accuracy: 0.953125\n",
      "Training loss: 0.118549, accuracy: 0.96875\n",
      "Training loss: 0.0905004, accuracy: 0.976563\n",
      "Training loss: 0.0971859, accuracy: 0.976563\n",
      "Training loss: 0.0961778, accuracy: 0.976563\n",
      "Training loss: 0.0921102, accuracy: 0.976563\n",
      "Training loss: 0.0827589, accuracy: 0.976563\n",
      "Training loss: 0.0677609, accuracy: 0.980469\n",
      "Training loss: 0.0700587, accuracy: 0.980469\n",
      "Training loss: 0.0610748, accuracy: 0.980469\n",
      "Training loss: 0.0618147, accuracy: 0.980469\n",
      "Training loss: 0.056054, accuracy: 0.984375\n",
      "----------------- Step 170: validation accuracy 0.81488 ----------------\n",
      "Training loss: 0.280083, accuracy: 0.90625\n",
      "Training loss: 0.246044, accuracy: 0.921875\n",
      "Training loss: 0.21842, accuracy: 0.925781\n",
      "Training loss: 0.197099, accuracy: 0.925781\n",
      "Training loss: 0.166324, accuracy: 0.953125\n",
      "Training loss: 0.151025, accuracy: 0.957031\n",
      "Training loss: 0.124075, accuracy: 0.957031\n",
      "Training loss: 0.110384, accuracy: 0.96875\n",
      "Training loss: 0.0935647, accuracy: 0.976563\n",
      "Training loss: 0.0881698, accuracy: 0.980469\n",
      "Training loss: 0.0776826, accuracy: 0.980469\n",
      "Training loss: 0.0714413, accuracy: 0.980469\n",
      "Training loss: 0.0694071, accuracy: 0.976563\n",
      "Training loss: 0.054843, accuracy: 0.992188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.060084, accuracy: 0.980469\n",
      "Training loss: 0.0510961, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.278485, accuracy: 0.898438\n",
      "Training loss: 0.281619, accuracy: 0.898438\n",
      "Training loss: 0.218076, accuracy: 0.9375\n",
      "Training loss: 0.215683, accuracy: 0.941406\n",
      "Training loss: 0.204684, accuracy: 0.933594\n",
      "Training loss: 0.191241, accuracy: 0.9375\n",
      "Training loss: 0.170701, accuracy: 0.957031\n",
      "Training loss: 0.147702, accuracy: 0.957031\n",
      "Training loss: 0.12893, accuracy: 0.96875\n",
      "Training loss: 0.120597, accuracy: 0.964844\n",
      "Training loss: 0.119197, accuracy: 0.972656\n",
      "Training loss: 0.103291, accuracy: 0.976563\n",
      "Training loss: 0.0987207, accuracy: 0.980469\n",
      "Training loss: 0.0860052, accuracy: 0.984375\n",
      "Training loss: 0.0897427, accuracy: 0.984375\n",
      "Training loss: 0.0802948, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.393286, accuracy: 0.882813\n",
      "Training loss: 0.363825, accuracy: 0.882813\n",
      "Training loss: 0.309719, accuracy: 0.894531\n",
      "Training loss: 0.264853, accuracy: 0.914063\n",
      "Training loss: 0.248646, accuracy: 0.917969\n",
      "Training loss: 0.230748, accuracy: 0.929688\n",
      "Training loss: 0.187883, accuracy: 0.933594\n",
      "Training loss: 0.189184, accuracy: 0.949219\n",
      "Training loss: 0.16152, accuracy: 0.960938\n",
      "Training loss: 0.161879, accuracy: 0.960938\n",
      "Training loss: 0.151229, accuracy: 0.964844\n",
      "Training loss: 0.131816, accuracy: 0.96875\n",
      "Training loss: 0.136091, accuracy: 0.96875\n",
      "Training loss: 0.131833, accuracy: 0.96875\n",
      "Training loss: 0.128556, accuracy: 0.96875\n",
      "Training loss: 0.121783, accuracy: 0.96875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.376395, accuracy: 0.890625\n",
      "Training loss: 0.32599, accuracy: 0.894531\n",
      "Training loss: 0.254374, accuracy: 0.914063\n",
      "Training loss: 0.234434, accuracy: 0.925781\n",
      "Training loss: 0.185911, accuracy: 0.945313\n",
      "Training loss: 0.152887, accuracy: 0.949219\n",
      "Training loss: 0.14189, accuracy: 0.96875\n",
      "Training loss: 0.138183, accuracy: 0.960938\n",
      "Training loss: 0.128596, accuracy: 0.96875\n",
      "Training loss: 0.119486, accuracy: 0.96875\n",
      "Training loss: 0.107923, accuracy: 0.976563\n",
      "Training loss: 0.10298, accuracy: 0.976563\n",
      "Training loss: 0.0945653, accuracy: 0.984375\n",
      "Training loss: 0.0910186, accuracy: 0.980469\n",
      "Training loss: 0.0884407, accuracy: 0.984375\n",
      "Training loss: 0.0797142, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.26207, accuracy: 0.894531\n",
      "Training loss: 0.232963, accuracy: 0.914063\n",
      "Training loss: 0.224273, accuracy: 0.914063\n",
      "Training loss: 0.209748, accuracy: 0.921875\n",
      "Training loss: 0.18031, accuracy: 0.941406\n",
      "Training loss: 0.176347, accuracy: 0.941406\n",
      "Training loss: 0.136609, accuracy: 0.957031\n",
      "Training loss: 0.116699, accuracy: 0.96875\n",
      "Training loss: 0.115006, accuracy: 0.972656\n",
      "Training loss: 0.115232, accuracy: 0.972656\n",
      "Training loss: 0.109374, accuracy: 0.964844\n",
      "Training loss: 0.101281, accuracy: 0.972656\n",
      "Training loss: 0.0821976, accuracy: 0.980469\n",
      "Training loss: 0.0740033, accuracy: 0.984375\n",
      "Training loss: 0.0743683, accuracy: 0.984375\n",
      "Training loss: 0.0728079, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.219486, accuracy: 0.914063\n",
      "Training loss: 0.179181, accuracy: 0.933594\n",
      "Training loss: 0.145323, accuracy: 0.957031\n",
      "Training loss: 0.129965, accuracy: 0.960938\n",
      "Training loss: 0.11569, accuracy: 0.964844\n",
      "Training loss: 0.102372, accuracy: 0.976563\n",
      "Training loss: 0.0805433, accuracy: 0.980469\n",
      "Training loss: 0.0770669, accuracy: 0.984375\n",
      "Training loss: 0.0737591, accuracy: 0.984375\n",
      "Training loss: 0.0736646, accuracy: 0.988281\n",
      "Training loss: 0.0653074, accuracy: 0.984375\n",
      "Training loss: 0.0615686, accuracy: 0.988281\n",
      "Training loss: 0.0569867, accuracy: 0.988281\n",
      "Training loss: 0.0567055, accuracy: 0.988281\n",
      "Training loss: 0.0553386, accuracy: 0.988281\n",
      "Training loss: 0.0490187, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.147943, accuracy: 0.933594\n",
      "Training loss: 0.152869, accuracy: 0.945313\n",
      "Training loss: 0.127525, accuracy: 0.957031\n",
      "Training loss: 0.111484, accuracy: 0.957031\n",
      "Training loss: 0.097234, accuracy: 0.972656\n",
      "Training loss: 0.0957517, accuracy: 0.972656\n",
      "Training loss: 0.0716739, accuracy: 0.980469\n",
      "Training loss: 0.0778388, accuracy: 0.980469\n",
      "Training loss: 0.0564334, accuracy: 0.980469\n",
      "Training loss: 0.0610981, accuracy: 0.980469\n",
      "Training loss: 0.0517623, accuracy: 0.988281\n",
      "Training loss: 0.0425297, accuracy: 0.992188\n",
      "Training loss: 0.0431319, accuracy: 0.992188\n",
      "Training loss: 0.0423994, accuracy: 0.992188\n",
      "Training loss: 0.0360799, accuracy: 0.992188\n",
      "Training loss: 0.0317229, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.260338, accuracy: 0.921875\n",
      "Training loss: 0.251424, accuracy: 0.921875\n",
      "Training loss: 0.218994, accuracy: 0.9375\n",
      "Training loss: 0.200235, accuracy: 0.957031\n",
      "Training loss: 0.202259, accuracy: 0.953125\n",
      "Training loss: 0.196034, accuracy: 0.953125\n",
      "Training loss: 0.177193, accuracy: 0.957031\n",
      "Training loss: 0.182695, accuracy: 0.957031\n",
      "Training loss: 0.159128, accuracy: 0.957031\n",
      "Training loss: 0.145171, accuracy: 0.960938\n",
      "Training loss: 0.145225, accuracy: 0.964844\n",
      "Training loss: 0.128218, accuracy: 0.96875\n",
      "Training loss: 0.124071, accuracy: 0.96875\n",
      "Training loss: 0.114485, accuracy: 0.96875\n",
      "Training loss: 0.0985336, accuracy: 0.972656\n",
      "Training loss: 0.0934456, accuracy: 0.976563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.16659, accuracy: 0.953125\n",
      "Training loss: 0.130688, accuracy: 0.957031\n",
      "Training loss: 0.112709, accuracy: 0.964844\n",
      "Training loss: 0.094285, accuracy: 0.96875\n",
      "Training loss: 0.0752262, accuracy: 0.980469\n",
      "Training loss: 0.0756834, accuracy: 0.976563\n",
      "Training loss: 0.0645817, accuracy: 0.988281\n",
      "Training loss: 0.0596484, accuracy: 0.988281\n",
      "Training loss: 0.0527602, accuracy: 0.996094\n",
      "Training loss: 0.0467357, accuracy: 0.996094\n",
      "Training loss: 0.0449974, accuracy: 0.996094\n",
      "Training loss: 0.0434029, accuracy: 0.996094\n",
      "Training loss: 0.0452442, accuracy: 0.996094\n",
      "Training loss: 0.0434074, accuracy: 0.996094\n",
      "Training loss: 0.0396865, accuracy: 0.996094\n",
      "Training loss: 0.0395744, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.466606, accuracy: 0.875\n",
      "Training loss: 0.412226, accuracy: 0.878906\n",
      "Training loss: 0.404124, accuracy: 0.894531\n",
      "Training loss: 0.333106, accuracy: 0.902344\n",
      "Training loss: 0.303493, accuracy: 0.921875\n",
      "Training loss: 0.281277, accuracy: 0.929688\n",
      "Training loss: 0.251182, accuracy: 0.933594\n",
      "Training loss: 0.227619, accuracy: 0.9375\n",
      "Training loss: 0.202, accuracy: 0.945313\n",
      "Training loss: 0.171417, accuracy: 0.949219\n",
      "Training loss: 0.168325, accuracy: 0.953125\n",
      "Training loss: 0.146869, accuracy: 0.960938\n",
      "Training loss: 0.139064, accuracy: 0.960938\n",
      "Training loss: 0.131885, accuracy: 0.964844\n",
      "Training loss: 0.134224, accuracy: 0.964844\n",
      "Training loss: 0.118198, accuracy: 0.96875\n",
      "----------------- Step 180: validation accuracy 0.81376 ----------------\n",
      "Training loss: 0.272631, accuracy: 0.882813\n",
      "Training loss: 0.251371, accuracy: 0.890625\n",
      "Training loss: 0.217593, accuracy: 0.914063\n",
      "Training loss: 0.177704, accuracy: 0.933594\n",
      "Training loss: 0.154031, accuracy: 0.941406\n",
      "Training loss: 0.136977, accuracy: 0.957031\n",
      "Training loss: 0.113125, accuracy: 0.964844\n",
      "Training loss: 0.107676, accuracy: 0.96875\n",
      "Training loss: 0.0977356, accuracy: 0.972656\n",
      "Training loss: 0.0832068, accuracy: 0.988281\n",
      "Training loss: 0.0805312, accuracy: 0.988281\n",
      "Training loss: 0.0698688, accuracy: 0.984375\n",
      "Training loss: 0.0724525, accuracy: 0.984375\n",
      "Training loss: 0.0672388, accuracy: 0.984375\n",
      "Training loss: 0.0579197, accuracy: 0.988281\n",
      "Training loss: 0.056682, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.234052, accuracy: 0.921875\n",
      "Training loss: 0.204337, accuracy: 0.925781\n",
      "Training loss: 0.176016, accuracy: 0.929688\n",
      "Training loss: 0.156606, accuracy: 0.9375\n",
      "Training loss: 0.125317, accuracy: 0.957031\n",
      "Training loss: 0.100285, accuracy: 0.972656\n",
      "Training loss: 0.091033, accuracy: 0.984375\n",
      "Training loss: 0.0794522, accuracy: 0.988281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.07764, accuracy: 0.984375\n",
      "Training loss: 0.0713759, accuracy: 0.988281\n",
      "Training loss: 0.0689176, accuracy: 0.984375\n",
      "Training loss: 0.0662085, accuracy: 0.988281\n",
      "Training loss: 0.0669881, accuracy: 0.988281\n",
      "Training loss: 0.0640223, accuracy: 0.988281\n",
      "Training loss: 0.0640553, accuracy: 0.988281\n",
      "Training loss: 0.0587173, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.27293, accuracy: 0.898438\n",
      "Training loss: 0.280674, accuracy: 0.914063\n",
      "Training loss: 0.213758, accuracy: 0.9375\n",
      "Training loss: 0.20823, accuracy: 0.945313\n",
      "Training loss: 0.182659, accuracy: 0.949219\n",
      "Training loss: 0.156073, accuracy: 0.964844\n",
      "Training loss: 0.145172, accuracy: 0.964844\n",
      "Training loss: 0.141868, accuracy: 0.964844\n",
      "Training loss: 0.121114, accuracy: 0.96875\n",
      "Training loss: 0.109819, accuracy: 0.972656\n",
      "Training loss: 0.105003, accuracy: 0.980469\n",
      "Training loss: 0.0947791, accuracy: 0.984375\n",
      "Training loss: 0.0876917, accuracy: 0.984375\n",
      "Training loss: 0.0738123, accuracy: 0.984375\n",
      "Training loss: 0.0797138, accuracy: 0.988281\n",
      "Training loss: 0.0723189, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.286481, accuracy: 0.910156\n",
      "Training loss: 0.210669, accuracy: 0.941406\n",
      "Training loss: 0.184414, accuracy: 0.949219\n",
      "Training loss: 0.140245, accuracy: 0.960938\n",
      "Training loss: 0.134493, accuracy: 0.964844\n",
      "Training loss: 0.112802, accuracy: 0.972656\n",
      "Training loss: 0.0916485, accuracy: 0.976563\n",
      "Training loss: 0.0780061, accuracy: 0.984375\n",
      "Training loss: 0.099699, accuracy: 0.972656\n",
      "Training loss: 0.0752609, accuracy: 0.984375\n",
      "Training loss: 0.0645915, accuracy: 0.988281\n",
      "Training loss: 0.0633248, accuracy: 0.988281\n",
      "Training loss: 0.0551609, accuracy: 0.992188\n",
      "Training loss: 0.0534841, accuracy: 0.992188\n",
      "Training loss: 0.0441265, accuracy: 0.992188\n",
      "Training loss: 0.0430016, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.226306, accuracy: 0.914063\n",
      "Training loss: 0.226867, accuracy: 0.917969\n",
      "Training loss: 0.183931, accuracy: 0.9375\n",
      "Training loss: 0.165362, accuracy: 0.945313\n",
      "Training loss: 0.134047, accuracy: 0.949219\n",
      "Training loss: 0.137901, accuracy: 0.960938\n",
      "Training loss: 0.123632, accuracy: 0.964844\n",
      "Training loss: 0.11467, accuracy: 0.972656\n",
      "Training loss: 0.108173, accuracy: 0.96875\n",
      "Training loss: 0.0942904, accuracy: 0.980469\n",
      "Training loss: 0.097319, accuracy: 0.980469\n",
      "Training loss: 0.0918901, accuracy: 0.980469\n",
      "Training loss: 0.0971469, accuracy: 0.980469\n",
      "Training loss: 0.0779094, accuracy: 0.980469\n",
      "Training loss: 0.0836107, accuracy: 0.976563\n",
      "Training loss: 0.0764205, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.23513, accuracy: 0.921875\n",
      "Training loss: 0.247346, accuracy: 0.914063\n",
      "Training loss: 0.215375, accuracy: 0.929688\n",
      "Training loss: 0.213646, accuracy: 0.933594\n",
      "Training loss: 0.183655, accuracy: 0.949219\n",
      "Training loss: 0.170746, accuracy: 0.953125\n",
      "Training loss: 0.154724, accuracy: 0.953125\n",
      "Training loss: 0.144772, accuracy: 0.953125\n",
      "Training loss: 0.143928, accuracy: 0.960938\n",
      "Training loss: 0.126791, accuracy: 0.972656\n",
      "Training loss: 0.112207, accuracy: 0.972656\n",
      "Training loss: 0.109534, accuracy: 0.972656\n",
      "Training loss: 0.10424, accuracy: 0.976563\n",
      "Training loss: 0.0972454, accuracy: 0.976563\n",
      "Training loss: 0.0983844, accuracy: 0.980469\n",
      "Training loss: 0.0920981, accuracy: 0.976563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.315993, accuracy: 0.914063\n",
      "Training loss: 0.276635, accuracy: 0.910156\n",
      "Training loss: 0.249575, accuracy: 0.917969\n",
      "Training loss: 0.219519, accuracy: 0.9375\n",
      "Training loss: 0.196645, accuracy: 0.9375\n",
      "Training loss: 0.16491, accuracy: 0.945313\n",
      "Training loss: 0.146068, accuracy: 0.953125\n",
      "Training loss: 0.119375, accuracy: 0.964844\n",
      "Training loss: 0.114805, accuracy: 0.96875\n",
      "Training loss: 0.107124, accuracy: 0.972656\n",
      "Training loss: 0.0922859, accuracy: 0.972656\n",
      "Training loss: 0.0970498, accuracy: 0.96875\n",
      "Training loss: 0.0903412, accuracy: 0.980469\n",
      "Training loss: 0.0859393, accuracy: 0.980469\n",
      "Training loss: 0.073801, accuracy: 0.984375\n",
      "Training loss: 0.0736796, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.201026, accuracy: 0.933594\n",
      "Training loss: 0.194728, accuracy: 0.929688\n",
      "Training loss: 0.193409, accuracy: 0.945313\n",
      "Training loss: 0.175393, accuracy: 0.945313\n",
      "Training loss: 0.147805, accuracy: 0.953125\n",
      "Training loss: 0.129146, accuracy: 0.957031\n",
      "Training loss: 0.122891, accuracy: 0.960938\n",
      "Training loss: 0.110837, accuracy: 0.972656\n",
      "Training loss: 0.115377, accuracy: 0.964844\n",
      "Training loss: 0.0947745, accuracy: 0.980469\n",
      "Training loss: 0.0931393, accuracy: 0.976563\n",
      "Training loss: 0.0838797, accuracy: 0.976563\n",
      "Training loss: 0.08339, accuracy: 0.980469\n",
      "Training loss: 0.0755613, accuracy: 0.984375\n",
      "Training loss: 0.0729071, accuracy: 0.984375\n",
      "Training loss: 0.0725117, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.235995, accuracy: 0.933594\n",
      "Training loss: 0.254583, accuracy: 0.933594\n",
      "Training loss: 0.225132, accuracy: 0.9375\n",
      "Training loss: 0.205805, accuracy: 0.945313\n",
      "Training loss: 0.193115, accuracy: 0.953125\n",
      "Training loss: 0.170657, accuracy: 0.957031\n",
      "Training loss: 0.156192, accuracy: 0.957031\n",
      "Training loss: 0.156464, accuracy: 0.964844\n",
      "Training loss: 0.136438, accuracy: 0.964844\n",
      "Training loss: 0.121822, accuracy: 0.972656\n",
      "Training loss: 0.119632, accuracy: 0.976563\n",
      "Training loss: 0.106, accuracy: 0.980469\n",
      "Training loss: 0.101101, accuracy: 0.976563\n",
      "Training loss: 0.101198, accuracy: 0.976563\n",
      "Training loss: 0.0964947, accuracy: 0.980469\n",
      "Training loss: 0.0941716, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.266383, accuracy: 0.90625\n",
      "Training loss: 0.237718, accuracy: 0.90625\n",
      "Training loss: 0.208215, accuracy: 0.933594\n",
      "Training loss: 0.162393, accuracy: 0.953125\n",
      "Training loss: 0.146774, accuracy: 0.957031\n",
      "Training loss: 0.129647, accuracy: 0.96875\n",
      "Training loss: 0.123182, accuracy: 0.972656\n",
      "Training loss: 0.115737, accuracy: 0.972656\n",
      "Training loss: 0.105747, accuracy: 0.976563\n",
      "Training loss: 0.0992426, accuracy: 0.980469\n",
      "Training loss: 0.0829207, accuracy: 0.980469\n",
      "Training loss: 0.0724876, accuracy: 0.980469\n",
      "Training loss: 0.0707629, accuracy: 0.984375\n",
      "Training loss: 0.0723241, accuracy: 0.976563\n",
      "Training loss: 0.0625203, accuracy: 0.988281\n",
      "Training loss: 0.058852, accuracy: 0.988281\n",
      "----------------- Step 190: validation accuracy 0.8336 ----------------\n",
      "Training loss: 0.334432, accuracy: 0.886719\n",
      "Training loss: 0.293407, accuracy: 0.898438\n",
      "Training loss: 0.287535, accuracy: 0.890625\n",
      "Training loss: 0.233107, accuracy: 0.914063\n",
      "Training loss: 0.210212, accuracy: 0.925781\n",
      "Training loss: 0.18778, accuracy: 0.929688\n",
      "Training loss: 0.150338, accuracy: 0.953125\n",
      "Training loss: 0.133364, accuracy: 0.96875\n",
      "Training loss: 0.109845, accuracy: 0.960938\n",
      "Training loss: 0.110504, accuracy: 0.972656\n",
      "Training loss: 0.0971063, accuracy: 0.976563\n",
      "Training loss: 0.0946885, accuracy: 0.980469\n",
      "Training loss: 0.0914345, accuracy: 0.976563\n",
      "Training loss: 0.0874596, accuracy: 0.980469\n",
      "Training loss: 0.0817349, accuracy: 0.984375\n",
      "Training loss: 0.0807336, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.265364, accuracy: 0.917969\n",
      "Training loss: 0.251245, accuracy: 0.921875\n",
      "Training loss: 0.223452, accuracy: 0.9375\n",
      "Training loss: 0.212254, accuracy: 0.945313\n",
      "Training loss: 0.189694, accuracy: 0.957031\n",
      "Training loss: 0.180239, accuracy: 0.953125\n",
      "Training loss: 0.154856, accuracy: 0.960938\n",
      "Training loss: 0.151864, accuracy: 0.96875\n",
      "Training loss: 0.148586, accuracy: 0.964844\n",
      "Training loss: 0.150736, accuracy: 0.96875\n",
      "Training loss: 0.136807, accuracy: 0.96875\n",
      "Training loss: 0.140137, accuracy: 0.96875\n",
      "Training loss: 0.126149, accuracy: 0.96875\n",
      "Training loss: 0.133141, accuracy: 0.96875\n",
      "Training loss: 0.129027, accuracy: 0.96875\n",
      "Training loss: 0.131008, accuracy: 0.96875\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.255263, accuracy: 0.917969\n",
      "Training loss: 0.217598, accuracy: 0.925781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.209688, accuracy: 0.933594\n",
      "Training loss: 0.172599, accuracy: 0.949219\n",
      "Training loss: 0.156224, accuracy: 0.960938\n",
      "Training loss: 0.123996, accuracy: 0.96875\n",
      "Training loss: 0.125742, accuracy: 0.96875\n",
      "Training loss: 0.101101, accuracy: 0.980469\n",
      "Training loss: 0.101541, accuracy: 0.972656\n",
      "Training loss: 0.0970735, accuracy: 0.984375\n",
      "Training loss: 0.0918862, accuracy: 0.984375\n",
      "Training loss: 0.0807181, accuracy: 0.988281\n",
      "Training loss: 0.0804883, accuracy: 0.988281\n",
      "Training loss: 0.07635, accuracy: 0.988281\n",
      "Training loss: 0.0690055, accuracy: 0.988281\n",
      "Training loss: 0.0703411, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.291812, accuracy: 0.914063\n",
      "Training loss: 0.241902, accuracy: 0.929688\n",
      "Training loss: 0.243604, accuracy: 0.929688\n",
      "Training loss: 0.184639, accuracy: 0.941406\n",
      "Training loss: 0.163469, accuracy: 0.957031\n",
      "Training loss: 0.145788, accuracy: 0.957031\n",
      "Training loss: 0.139333, accuracy: 0.957031\n",
      "Training loss: 0.121589, accuracy: 0.960938\n",
      "Training loss: 0.105245, accuracy: 0.96875\n",
      "Training loss: 0.10143, accuracy: 0.96875\n",
      "Training loss: 0.0979894, accuracy: 0.972656\n",
      "Training loss: 0.0890857, accuracy: 0.980469\n",
      "Training loss: 0.0804866, accuracy: 0.980469\n",
      "Training loss: 0.0735228, accuracy: 0.984375\n",
      "Training loss: 0.0639416, accuracy: 0.984375\n",
      "Training loss: 0.0705693, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.356932, accuracy: 0.882813\n",
      "Training loss: 0.320784, accuracy: 0.902344\n",
      "Training loss: 0.312118, accuracy: 0.90625\n",
      "Training loss: 0.247841, accuracy: 0.921875\n",
      "Training loss: 0.227958, accuracy: 0.929688\n",
      "Training loss: 0.191204, accuracy: 0.941406\n",
      "Training loss: 0.184492, accuracy: 0.945313\n",
      "Training loss: 0.162884, accuracy: 0.957031\n",
      "Training loss: 0.152003, accuracy: 0.960938\n",
      "Training loss: 0.131012, accuracy: 0.96875\n",
      "Training loss: 0.138793, accuracy: 0.960938\n",
      "Training loss: 0.127994, accuracy: 0.964844\n",
      "Training loss: 0.109566, accuracy: 0.96875\n",
      "Training loss: 0.10809, accuracy: 0.976563\n",
      "Training loss: 0.10976, accuracy: 0.976563\n",
      "Training loss: 0.0934395, accuracy: 0.976563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.167046, accuracy: 0.9375\n",
      "Training loss: 0.133165, accuracy: 0.953125\n",
      "Training loss: 0.145766, accuracy: 0.953125\n",
      "Training loss: 0.126343, accuracy: 0.957031\n",
      "Training loss: 0.0935494, accuracy: 0.964844\n",
      "Training loss: 0.0895847, accuracy: 0.96875\n",
      "Training loss: 0.0716699, accuracy: 0.984375\n",
      "Training loss: 0.058651, accuracy: 0.992188\n",
      "Training loss: 0.0593618, accuracy: 0.996094\n",
      "Training loss: 0.052107, accuracy: 0.996094\n",
      "Training loss: 0.0611326, accuracy: 0.988281\n",
      "Training loss: 0.0453372, accuracy: 0.996094\n",
      "Training loss: 0.048335, accuracy: 0.996094\n",
      "Training loss: 0.0463132, accuracy: 0.996094\n",
      "Training loss: 0.0445185, accuracy: 0.996094\n",
      "Training loss: 0.0385964, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.227302, accuracy: 0.933594\n",
      "Training loss: 0.237855, accuracy: 0.929688\n",
      "Training loss: 0.199939, accuracy: 0.941406\n",
      "Training loss: 0.152852, accuracy: 0.957031\n",
      "Training loss: 0.143671, accuracy: 0.964844\n",
      "Training loss: 0.145615, accuracy: 0.96875\n",
      "Training loss: 0.13353, accuracy: 0.964844\n",
      "Training loss: 0.11458, accuracy: 0.972656\n",
      "Training loss: 0.119684, accuracy: 0.972656\n",
      "Training loss: 0.117072, accuracy: 0.972656\n",
      "Training loss: 0.107063, accuracy: 0.972656\n",
      "Training loss: 0.106074, accuracy: 0.972656\n",
      "Training loss: 0.100378, accuracy: 0.972656\n",
      "Training loss: 0.105198, accuracy: 0.96875\n",
      "Training loss: 0.0931541, accuracy: 0.972656\n",
      "Training loss: 0.0783376, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.321871, accuracy: 0.90625\n",
      "Training loss: 0.301891, accuracy: 0.917969\n",
      "Training loss: 0.254907, accuracy: 0.925781\n",
      "Training loss: 0.215494, accuracy: 0.9375\n",
      "Training loss: 0.210235, accuracy: 0.941406\n",
      "Training loss: 0.176834, accuracy: 0.945313\n",
      "Training loss: 0.161563, accuracy: 0.960938\n",
      "Training loss: 0.140882, accuracy: 0.960938\n",
      "Training loss: 0.129879, accuracy: 0.96875\n",
      "Training loss: 0.127031, accuracy: 0.964844\n",
      "Training loss: 0.111245, accuracy: 0.972656\n",
      "Training loss: 0.110518, accuracy: 0.976563\n",
      "Training loss: 0.104201, accuracy: 0.976563\n",
      "Training loss: 0.0923692, accuracy: 0.972656\n",
      "Training loss: 0.0878249, accuracy: 0.984375\n",
      "Training loss: 0.0694343, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.236691, accuracy: 0.921875\n",
      "Training loss: 0.219994, accuracy: 0.933594\n",
      "Training loss: 0.18737, accuracy: 0.945313\n",
      "Training loss: 0.165399, accuracy: 0.953125\n",
      "Training loss: 0.159192, accuracy: 0.953125\n",
      "Training loss: 0.145501, accuracy: 0.96875\n",
      "Training loss: 0.142915, accuracy: 0.96875\n",
      "Training loss: 0.137085, accuracy: 0.964844\n",
      "Training loss: 0.126442, accuracy: 0.96875\n",
      "Training loss: 0.123699, accuracy: 0.96875\n",
      "Training loss: 0.117794, accuracy: 0.96875\n",
      "Training loss: 0.114637, accuracy: 0.96875\n",
      "Training loss: 0.108408, accuracy: 0.972656\n",
      "Training loss: 0.0997503, accuracy: 0.976563\n",
      "Training loss: 0.0987568, accuracy: 0.980469\n",
      "Training loss: 0.0931312, accuracy: 0.976563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.243699, accuracy: 0.910156\n",
      "Training loss: 0.232992, accuracy: 0.921875\n",
      "Training loss: 0.205756, accuracy: 0.9375\n",
      "Training loss: 0.185785, accuracy: 0.941406\n",
      "Training loss: 0.162083, accuracy: 0.953125\n",
      "Training loss: 0.128697, accuracy: 0.949219\n",
      "Training loss: 0.109619, accuracy: 0.972656\n",
      "Training loss: 0.092171, accuracy: 0.976563\n",
      "Training loss: 0.0831778, accuracy: 0.980469\n",
      "Training loss: 0.0763217, accuracy: 0.984375\n",
      "Training loss: 0.0681624, accuracy: 0.988281\n",
      "Training loss: 0.0645605, accuracy: 0.988281\n",
      "Training loss: 0.0602276, accuracy: 0.988281\n",
      "Training loss: 0.0528456, accuracy: 0.988281\n",
      "Training loss: 0.0510647, accuracy: 0.992188\n",
      "Training loss: 0.0501648, accuracy: 0.988281\n",
      "----------------- Step 200: validation accuracy 0.81744 ----------------\n",
      "Training loss: 0.306273, accuracy: 0.898438\n",
      "Training loss: 0.249525, accuracy: 0.917969\n",
      "Training loss: 0.221882, accuracy: 0.933594\n",
      "Training loss: 0.188683, accuracy: 0.945313\n",
      "Training loss: 0.182737, accuracy: 0.941406\n",
      "Training loss: 0.15335, accuracy: 0.957031\n",
      "Training loss: 0.141061, accuracy: 0.964844\n",
      "Training loss: 0.122073, accuracy: 0.972656\n",
      "Training loss: 0.109141, accuracy: 0.976563\n",
      "Training loss: 0.118134, accuracy: 0.976563\n",
      "Training loss: 0.108021, accuracy: 0.976563\n",
      "Training loss: 0.110381, accuracy: 0.976563\n",
      "Training loss: 0.106367, accuracy: 0.972656\n",
      "Training loss: 0.103152, accuracy: 0.976563\n",
      "Training loss: 0.102126, accuracy: 0.976563\n",
      "Training loss: 0.0912347, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.38471, accuracy: 0.878906\n",
      "Training loss: 0.298039, accuracy: 0.90625\n",
      "Training loss: 0.240625, accuracy: 0.921875\n",
      "Training loss: 0.230228, accuracy: 0.925781\n",
      "Training loss: 0.202588, accuracy: 0.925781\n",
      "Training loss: 0.209768, accuracy: 0.921875\n",
      "Training loss: 0.190856, accuracy: 0.921875\n",
      "Training loss: 0.17067, accuracy: 0.949219\n",
      "Training loss: 0.161326, accuracy: 0.941406\n",
      "Training loss: 0.163267, accuracy: 0.949219\n",
      "Training loss: 0.124431, accuracy: 0.972656\n",
      "Training loss: 0.123156, accuracy: 0.964844\n",
      "Training loss: 0.121408, accuracy: 0.972656\n",
      "Training loss: 0.117909, accuracy: 0.976563\n",
      "Training loss: 0.096479, accuracy: 0.972656\n",
      "Training loss: 0.104855, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.178957, accuracy: 0.945313\n",
      "Training loss: 0.184285, accuracy: 0.949219\n",
      "Training loss: 0.160666, accuracy: 0.953125\n",
      "Training loss: 0.158633, accuracy: 0.960938\n",
      "Training loss: 0.144674, accuracy: 0.960938\n",
      "Training loss: 0.132091, accuracy: 0.957031\n",
      "Training loss: 0.116399, accuracy: 0.964844\n",
      "Training loss: 0.09867, accuracy: 0.96875\n",
      "Training loss: 0.0837008, accuracy: 0.980469\n",
      "Training loss: 0.090495, accuracy: 0.976563\n",
      "Training loss: 0.0772176, accuracy: 0.976563\n",
      "Training loss: 0.0661579, accuracy: 0.988281\n",
      "Training loss: 0.0636117, accuracy: 0.988281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0554357, accuracy: 0.992188\n",
      "Training loss: 0.0551829, accuracy: 0.992188\n",
      "Training loss: 0.0517774, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.353721, accuracy: 0.890625\n",
      "Training loss: 0.333963, accuracy: 0.894531\n",
      "Training loss: 0.316996, accuracy: 0.910156\n",
      "Training loss: 0.291817, accuracy: 0.914063\n",
      "Training loss: 0.270192, accuracy: 0.925781\n",
      "Training loss: 0.240608, accuracy: 0.929688\n",
      "Training loss: 0.226508, accuracy: 0.933594\n",
      "Training loss: 0.201311, accuracy: 0.941406\n",
      "Training loss: 0.177261, accuracy: 0.941406\n",
      "Training loss: 0.153992, accuracy: 0.949219\n",
      "Training loss: 0.146954, accuracy: 0.949219\n",
      "Training loss: 0.131561, accuracy: 0.96875\n",
      "Training loss: 0.118565, accuracy: 0.96875\n",
      "Training loss: 0.12441, accuracy: 0.964844\n",
      "Training loss: 0.108325, accuracy: 0.972656\n",
      "Training loss: 0.103233, accuracy: 0.972656\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.176377, accuracy: 0.933594\n",
      "Training loss: 0.16975, accuracy: 0.921875\n",
      "Training loss: 0.149279, accuracy: 0.949219\n",
      "Training loss: 0.132629, accuracy: 0.953125\n",
      "Training loss: 0.0901062, accuracy: 0.976563\n",
      "Training loss: 0.108687, accuracy: 0.96875\n",
      "Training loss: 0.0942085, accuracy: 0.980469\n",
      "Training loss: 0.0789034, accuracy: 0.984375\n",
      "Training loss: 0.0736849, accuracy: 0.980469\n",
      "Training loss: 0.0665821, accuracy: 0.984375\n",
      "Training loss: 0.0584327, accuracy: 0.984375\n",
      "Training loss: 0.045509, accuracy: 0.996094\n",
      "Training loss: 0.0448687, accuracy: 0.992188\n",
      "Training loss: 0.0412981, accuracy: 0.996094\n",
      "Training loss: 0.0387406, accuracy: 0.996094\n",
      "Training loss: 0.0376546, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.239904, accuracy: 0.917969\n",
      "Training loss: 0.210893, accuracy: 0.933594\n",
      "Training loss: 0.207865, accuracy: 0.933594\n",
      "Training loss: 0.173309, accuracy: 0.949219\n",
      "Training loss: 0.145122, accuracy: 0.964844\n",
      "Training loss: 0.15564, accuracy: 0.960938\n",
      "Training loss: 0.139403, accuracy: 0.96875\n",
      "Training loss: 0.122096, accuracy: 0.972656\n",
      "Training loss: 0.117527, accuracy: 0.976563\n",
      "Training loss: 0.101771, accuracy: 0.972656\n",
      "Training loss: 0.0925832, accuracy: 0.980469\n",
      "Training loss: 0.096504, accuracy: 0.980469\n",
      "Training loss: 0.0890054, accuracy: 0.980469\n",
      "Training loss: 0.0911773, accuracy: 0.980469\n",
      "Training loss: 0.0906625, accuracy: 0.980469\n",
      "Training loss: 0.0817958, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.204011, accuracy: 0.9375\n",
      "Training loss: 0.189293, accuracy: 0.949219\n",
      "Training loss: 0.185495, accuracy: 0.953125\n",
      "Training loss: 0.169763, accuracy: 0.953125\n",
      "Training loss: 0.164775, accuracy: 0.953125\n",
      "Training loss: 0.144285, accuracy: 0.960938\n",
      "Training loss: 0.148949, accuracy: 0.964844\n",
      "Training loss: 0.140608, accuracy: 0.964844\n",
      "Training loss: 0.132342, accuracy: 0.964844\n",
      "Training loss: 0.126948, accuracy: 0.964844\n",
      "Training loss: 0.110061, accuracy: 0.96875\n",
      "Training loss: 0.103302, accuracy: 0.96875\n",
      "Training loss: 0.0951118, accuracy: 0.976563\n",
      "Training loss: 0.0972549, accuracy: 0.980469\n",
      "Training loss: 0.0921488, accuracy: 0.980469\n",
      "Training loss: 0.0881789, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.21074, accuracy: 0.933594\n",
      "Training loss: 0.197788, accuracy: 0.9375\n",
      "Training loss: 0.190554, accuracy: 0.945313\n",
      "Training loss: 0.165229, accuracy: 0.949219\n",
      "Training loss: 0.150623, accuracy: 0.957031\n",
      "Training loss: 0.141019, accuracy: 0.96875\n",
      "Training loss: 0.113701, accuracy: 0.96875\n",
      "Training loss: 0.107102, accuracy: 0.976563\n",
      "Training loss: 0.0984863, accuracy: 0.976563\n",
      "Training loss: 0.0988688, accuracy: 0.976563\n",
      "Training loss: 0.0985655, accuracy: 0.976563\n",
      "Training loss: 0.097171, accuracy: 0.976563\n",
      "Training loss: 0.0903923, accuracy: 0.976563\n",
      "Training loss: 0.0894946, accuracy: 0.976563\n",
      "Training loss: 0.0769636, accuracy: 0.980469\n",
      "Training loss: 0.0800035, accuracy: 0.976563\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.220638, accuracy: 0.933594\n",
      "Training loss: 0.18264, accuracy: 0.9375\n",
      "Training loss: 0.171329, accuracy: 0.949219\n",
      "Training loss: 0.142685, accuracy: 0.957031\n",
      "Training loss: 0.109643, accuracy: 0.96875\n",
      "Training loss: 0.0878639, accuracy: 0.976563\n",
      "Training loss: 0.0868274, accuracy: 0.984375\n",
      "Training loss: 0.08088, accuracy: 0.984375\n",
      "Training loss: 0.070589, accuracy: 0.988281\n",
      "Training loss: 0.0709307, accuracy: 0.988281\n",
      "Training loss: 0.071585, accuracy: 0.988281\n",
      "Training loss: 0.0668479, accuracy: 0.988281\n",
      "Training loss: 0.0662516, accuracy: 0.988281\n",
      "Training loss: 0.0651075, accuracy: 0.988281\n",
      "Training loss: 0.0609051, accuracy: 0.988281\n",
      "Training loss: 0.0550788, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.299924, accuracy: 0.914063\n",
      "Training loss: 0.238156, accuracy: 0.921875\n",
      "Training loss: 0.211765, accuracy: 0.925781\n",
      "Training loss: 0.190958, accuracy: 0.945313\n",
      "Training loss: 0.174456, accuracy: 0.949219\n",
      "Training loss: 0.167749, accuracy: 0.953125\n",
      "Training loss: 0.141566, accuracy: 0.957031\n",
      "Training loss: 0.132305, accuracy: 0.964844\n",
      "Training loss: 0.116599, accuracy: 0.964844\n",
      "Training loss: 0.0997901, accuracy: 0.976563\n",
      "Training loss: 0.0835309, accuracy: 0.976563\n",
      "Training loss: 0.0894613, accuracy: 0.976563\n",
      "Training loss: 0.0876102, accuracy: 0.980469\n",
      "Training loss: 0.0798177, accuracy: 0.976563\n",
      "Training loss: 0.0655626, accuracy: 0.984375\n",
      "Training loss: 0.0646683, accuracy: 0.984375\n",
      "----------------- Step 210: validation accuracy 0.81104 ----------------\n",
      "Training loss: 0.234419, accuracy: 0.929688\n",
      "Training loss: 0.22084, accuracy: 0.917969\n",
      "Training loss: 0.214328, accuracy: 0.925781\n",
      "Training loss: 0.167214, accuracy: 0.941406\n",
      "Training loss: 0.146546, accuracy: 0.953125\n",
      "Training loss: 0.127256, accuracy: 0.96875\n",
      "Training loss: 0.105954, accuracy: 0.976563\n",
      "Training loss: 0.100842, accuracy: 0.976563\n",
      "Training loss: 0.105572, accuracy: 0.976563\n",
      "Training loss: 0.106454, accuracy: 0.976563\n",
      "Training loss: 0.0888601, accuracy: 0.980469\n",
      "Training loss: 0.0880516, accuracy: 0.984375\n",
      "Training loss: 0.0862442, accuracy: 0.984375\n",
      "Training loss: 0.0772638, accuracy: 0.984375\n",
      "Training loss: 0.0701033, accuracy: 0.980469\n",
      "Training loss: 0.0642983, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.32388, accuracy: 0.90625\n",
      "Training loss: 0.296965, accuracy: 0.914063\n",
      "Training loss: 0.251781, accuracy: 0.921875\n",
      "Training loss: 0.231041, accuracy: 0.933594\n",
      "Training loss: 0.20315, accuracy: 0.945313\n",
      "Training loss: 0.174301, accuracy: 0.957031\n",
      "Training loss: 0.174842, accuracy: 0.957031\n",
      "Training loss: 0.164855, accuracy: 0.953125\n",
      "Training loss: 0.146602, accuracy: 0.960938\n",
      "Training loss: 0.134839, accuracy: 0.957031\n",
      "Training loss: 0.132078, accuracy: 0.960938\n",
      "Training loss: 0.121647, accuracy: 0.960938\n",
      "Training loss: 0.112389, accuracy: 0.960938\n",
      "Training loss: 0.116499, accuracy: 0.960938\n",
      "Training loss: 0.10744, accuracy: 0.964844\n",
      "Training loss: 0.0875418, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.207407, accuracy: 0.929688\n",
      "Training loss: 0.173795, accuracy: 0.941406\n",
      "Training loss: 0.155414, accuracy: 0.953125\n",
      "Training loss: 0.137522, accuracy: 0.964844\n",
      "Training loss: 0.13987, accuracy: 0.957031\n",
      "Training loss: 0.121273, accuracy: 0.972656\n",
      "Training loss: 0.107607, accuracy: 0.972656\n",
      "Training loss: 0.109952, accuracy: 0.972656\n",
      "Training loss: 0.0930619, accuracy: 0.976563\n",
      "Training loss: 0.0827575, accuracy: 0.988281\n",
      "Training loss: 0.0862954, accuracy: 0.976563\n",
      "Training loss: 0.0786622, accuracy: 0.988281\n",
      "Training loss: 0.0692, accuracy: 0.988281\n",
      "Training loss: 0.0654328, accuracy: 0.992188\n",
      "Training loss: 0.0628938, accuracy: 0.988281\n",
      "Training loss: 0.0581797, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.253918, accuracy: 0.90625\n",
      "Training loss: 0.236715, accuracy: 0.921875\n",
      "Training loss: 0.211775, accuracy: 0.933594\n",
      "Training loss: 0.213099, accuracy: 0.9375\n",
      "Training loss: 0.193645, accuracy: 0.945313\n",
      "Training loss: 0.180965, accuracy: 0.949219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.145717, accuracy: 0.960938\n",
      "Training loss: 0.14193, accuracy: 0.96875\n",
      "Training loss: 0.132138, accuracy: 0.964844\n",
      "Training loss: 0.123052, accuracy: 0.96875\n",
      "Training loss: 0.119742, accuracy: 0.96875\n",
      "Training loss: 0.117589, accuracy: 0.96875\n",
      "Training loss: 0.100253, accuracy: 0.972656\n",
      "Training loss: 0.0964347, accuracy: 0.976563\n",
      "Training loss: 0.0927182, accuracy: 0.976563\n",
      "Training loss: 0.0791233, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.194055, accuracy: 0.9375\n",
      "Training loss: 0.190314, accuracy: 0.949219\n",
      "Training loss: 0.165678, accuracy: 0.949219\n",
      "Training loss: 0.127602, accuracy: 0.96875\n",
      "Training loss: 0.129465, accuracy: 0.96875\n",
      "Training loss: 0.14544, accuracy: 0.957031\n",
      "Training loss: 0.104448, accuracy: 0.976563\n",
      "Training loss: 0.102503, accuracy: 0.972656\n",
      "Training loss: 0.0966946, accuracy: 0.976563\n",
      "Training loss: 0.0855578, accuracy: 0.984375\n",
      "Training loss: 0.0841985, accuracy: 0.984375\n",
      "Training loss: 0.0859364, accuracy: 0.984375\n",
      "Training loss: 0.0771407, accuracy: 0.984375\n",
      "Training loss: 0.080083, accuracy: 0.984375\n",
      "Training loss: 0.0778885, accuracy: 0.984375\n",
      "Training loss: 0.076493, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.189517, accuracy: 0.933594\n",
      "Training loss: 0.170695, accuracy: 0.953125\n",
      "Training loss: 0.133443, accuracy: 0.960938\n",
      "Training loss: 0.126323, accuracy: 0.964844\n",
      "Training loss: 0.109178, accuracy: 0.972656\n",
      "Training loss: 0.0899516, accuracy: 0.976563\n",
      "Training loss: 0.0822599, accuracy: 0.984375\n",
      "Training loss: 0.0753109, accuracy: 0.984375\n",
      "Training loss: 0.0658968, accuracy: 0.992188\n",
      "Training loss: 0.0620125, accuracy: 0.988281\n",
      "Training loss: 0.0554768, accuracy: 0.988281\n",
      "Training loss: 0.0552402, accuracy: 0.992188\n",
      "Training loss: 0.0501018, accuracy: 0.992188\n",
      "Training loss: 0.0462341, accuracy: 0.996094\n",
      "Training loss: 0.0447362, accuracy: 0.996094\n",
      "Training loss: 0.0430052, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.258314, accuracy: 0.925781\n",
      "Training loss: 0.250123, accuracy: 0.925781\n",
      "Training loss: 0.185111, accuracy: 0.945313\n",
      "Training loss: 0.180327, accuracy: 0.953125\n",
      "Training loss: 0.170938, accuracy: 0.953125\n",
      "Training loss: 0.148032, accuracy: 0.953125\n",
      "Training loss: 0.140123, accuracy: 0.957031\n",
      "Training loss: 0.12238, accuracy: 0.96875\n",
      "Training loss: 0.117631, accuracy: 0.972656\n",
      "Training loss: 0.0998563, accuracy: 0.976563\n",
      "Training loss: 0.099389, accuracy: 0.976563\n",
      "Training loss: 0.0902215, accuracy: 0.980469\n",
      "Training loss: 0.0891195, accuracy: 0.980469\n",
      "Training loss: 0.0845249, accuracy: 0.980469\n",
      "Training loss: 0.0753486, accuracy: 0.980469\n",
      "Training loss: 0.0831191, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.174998, accuracy: 0.933594\n",
      "Training loss: 0.179842, accuracy: 0.9375\n",
      "Training loss: 0.156077, accuracy: 0.945313\n",
      "Training loss: 0.130238, accuracy: 0.960938\n",
      "Training loss: 0.111887, accuracy: 0.96875\n",
      "Training loss: 0.0903898, accuracy: 0.980469\n",
      "Training loss: 0.0826212, accuracy: 0.984375\n",
      "Training loss: 0.0795979, accuracy: 0.984375\n",
      "Training loss: 0.0685159, accuracy: 0.984375\n",
      "Training loss: 0.0717346, accuracy: 0.984375\n",
      "Training loss: 0.0633764, accuracy: 0.988281\n",
      "Training loss: 0.0600371, accuracy: 0.988281\n",
      "Training loss: 0.0577947, accuracy: 0.988281\n",
      "Training loss: 0.0507644, accuracy: 0.992188\n",
      "Training loss: 0.0497424, accuracy: 0.992188\n",
      "Training loss: 0.0442893, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.196815, accuracy: 0.9375\n",
      "Training loss: 0.170136, accuracy: 0.9375\n",
      "Training loss: 0.146108, accuracy: 0.953125\n",
      "Training loss: 0.137082, accuracy: 0.964844\n",
      "Training loss: 0.126867, accuracy: 0.96875\n",
      "Training loss: 0.114704, accuracy: 0.976563\n",
      "Training loss: 0.108593, accuracy: 0.972656\n",
      "Training loss: 0.103306, accuracy: 0.976563\n",
      "Training loss: 0.100432, accuracy: 0.976563\n",
      "Training loss: 0.0858911, accuracy: 0.976563\n",
      "Training loss: 0.0889746, accuracy: 0.976563\n",
      "Training loss: 0.0750787, accuracy: 0.980469\n",
      "Training loss: 0.0712693, accuracy: 0.984375\n",
      "Training loss: 0.0598466, accuracy: 0.988281\n",
      "Training loss: 0.0583466, accuracy: 0.988281\n",
      "Training loss: 0.0492781, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.0893299, accuracy: 0.972656\n",
      "Training loss: 0.0762461, accuracy: 0.984375\n",
      "Training loss: 0.074852, accuracy: 0.984375\n",
      "Training loss: 0.0720451, accuracy: 0.984375\n",
      "Training loss: 0.0683235, accuracy: 0.984375\n",
      "Training loss: 0.0686477, accuracy: 0.984375\n",
      "Training loss: 0.0614784, accuracy: 0.984375\n",
      "Training loss: 0.0535894, accuracy: 0.988281\n",
      "Training loss: 0.0547554, accuracy: 0.984375\n",
      "Training loss: 0.0543458, accuracy: 0.984375\n",
      "Training loss: 0.0454769, accuracy: 0.988281\n",
      "Training loss: 0.0467061, accuracy: 0.988281\n",
      "Training loss: 0.0439606, accuracy: 0.988281\n",
      "Training loss: 0.0422137, accuracy: 0.992188\n",
      "Training loss: 0.0323955, accuracy: 0.992188\n",
      "Training loss: 0.0375806, accuracy: 0.992188\n",
      "----------------- Step 220: validation accuracy 0.83344 ----------------\n",
      "Training loss: 0.220995, accuracy: 0.929688\n",
      "Training loss: 0.198064, accuracy: 0.925781\n",
      "Training loss: 0.177703, accuracy: 0.949219\n",
      "Training loss: 0.123712, accuracy: 0.960938\n",
      "Training loss: 0.128724, accuracy: 0.964844\n",
      "Training loss: 0.103894, accuracy: 0.972656\n",
      "Training loss: 0.0880882, accuracy: 0.976563\n",
      "Training loss: 0.0846877, accuracy: 0.976563\n",
      "Training loss: 0.0746539, accuracy: 0.984375\n",
      "Training loss: 0.0632462, accuracy: 0.984375\n",
      "Training loss: 0.0580064, accuracy: 0.984375\n",
      "Training loss: 0.0507202, accuracy: 0.988281\n",
      "Training loss: 0.0441124, accuracy: 0.992188\n",
      "Training loss: 0.0354075, accuracy: 0.992188\n",
      "Training loss: 0.0383131, accuracy: 0.992188\n",
      "Training loss: 0.0353046, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.382991, accuracy: 0.914063\n",
      "Training loss: 0.320077, accuracy: 0.910156\n",
      "Training loss: 0.262071, accuracy: 0.921875\n",
      "Training loss: 0.205283, accuracy: 0.925781\n",
      "Training loss: 0.186598, accuracy: 0.9375\n",
      "Training loss: 0.152485, accuracy: 0.953125\n",
      "Training loss: 0.138305, accuracy: 0.957031\n",
      "Training loss: 0.127763, accuracy: 0.964844\n",
      "Training loss: 0.113717, accuracy: 0.964844\n",
      "Training loss: 0.106835, accuracy: 0.964844\n",
      "Training loss: 0.103539, accuracy: 0.96875\n",
      "Training loss: 0.0851587, accuracy: 0.976563\n",
      "Training loss: 0.0837145, accuracy: 0.96875\n",
      "Training loss: 0.0746829, accuracy: 0.980469\n",
      "Training loss: 0.0698968, accuracy: 0.988281\n",
      "Training loss: 0.0658709, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.196851, accuracy: 0.925781\n",
      "Training loss: 0.174509, accuracy: 0.933594\n",
      "Training loss: 0.162441, accuracy: 0.941406\n",
      "Training loss: 0.150699, accuracy: 0.949219\n",
      "Training loss: 0.127167, accuracy: 0.953125\n",
      "Training loss: 0.10361, accuracy: 0.976563\n",
      "Training loss: 0.0949875, accuracy: 0.980469\n",
      "Training loss: 0.088098, accuracy: 0.976563\n",
      "Training loss: 0.0758403, accuracy: 0.984375\n",
      "Training loss: 0.0669063, accuracy: 0.988281\n",
      "Training loss: 0.0647262, accuracy: 0.988281\n",
      "Training loss: 0.0599967, accuracy: 0.988281\n",
      "Training loss: 0.0513727, accuracy: 0.992188\n",
      "Training loss: 0.0469384, accuracy: 0.992188\n",
      "Training loss: 0.0508224, accuracy: 0.992188\n",
      "Training loss: 0.04756, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.313863, accuracy: 0.890625\n",
      "Training loss: 0.269529, accuracy: 0.90625\n",
      "Training loss: 0.250435, accuracy: 0.921875\n",
      "Training loss: 0.22443, accuracy: 0.933594\n",
      "Training loss: 0.195402, accuracy: 0.945313\n",
      "Training loss: 0.175425, accuracy: 0.949219\n",
      "Training loss: 0.160849, accuracy: 0.957031\n",
      "Training loss: 0.131822, accuracy: 0.960938\n",
      "Training loss: 0.12772, accuracy: 0.964844\n",
      "Training loss: 0.11259, accuracy: 0.972656\n",
      "Training loss: 0.0969421, accuracy: 0.972656\n",
      "Training loss: 0.0916586, accuracy: 0.976563\n",
      "Training loss: 0.0904476, accuracy: 0.980469\n",
      "Training loss: 0.0822198, accuracy: 0.976563\n",
      "Training loss: 0.0678202, accuracy: 0.984375\n",
      "Training loss: 0.0758628, accuracy: 0.980469\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.188159, accuracy: 0.945313\n",
      "Training loss: 0.180595, accuracy: 0.933594\n",
      "Training loss: 0.162851, accuracy: 0.945313\n",
      "Training loss: 0.156448, accuracy: 0.949219\n",
      "Training loss: 0.142591, accuracy: 0.96875\n",
      "Training loss: 0.129938, accuracy: 0.972656\n",
      "Training loss: 0.108652, accuracy: 0.972656\n",
      "Training loss: 0.0936038, accuracy: 0.984375\n",
      "Training loss: 0.0897531, accuracy: 0.980469\n",
      "Training loss: 0.0824777, accuracy: 0.984375\n",
      "Training loss: 0.0805447, accuracy: 0.980469\n",
      "Training loss: 0.0748525, accuracy: 0.984375\n",
      "Training loss: 0.0711925, accuracy: 0.984375\n",
      "Training loss: 0.0665709, accuracy: 0.988281\n",
      "Training loss: 0.0611983, accuracy: 0.988281\n",
      "Training loss: 0.0632926, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.190685, accuracy: 0.941406\n",
      "Training loss: 0.165601, accuracy: 0.945313\n",
      "Training loss: 0.133126, accuracy: 0.960938\n",
      "Training loss: 0.109196, accuracy: 0.96875\n",
      "Training loss: 0.0898544, accuracy: 0.96875\n",
      "Training loss: 0.0688755, accuracy: 0.988281\n",
      "Training loss: 0.0706069, accuracy: 0.988281\n",
      "Training loss: 0.0642311, accuracy: 0.988281\n",
      "Training loss: 0.0593299, accuracy: 0.988281\n",
      "Training loss: 0.0519112, accuracy: 0.988281\n",
      "Training loss: 0.0506369, accuracy: 0.992188\n",
      "Training loss: 0.044909, accuracy: 0.996094\n",
      "Training loss: 0.046918, accuracy: 0.988281\n",
      "Training loss: 0.0393268, accuracy: 0.996094\n",
      "Training loss: 0.0343773, accuracy: 0.996094\n",
      "Training loss: 0.0374752, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.305499, accuracy: 0.902344\n",
      "Training loss: 0.301403, accuracy: 0.898438\n",
      "Training loss: 0.248332, accuracy: 0.917969\n",
      "Training loss: 0.20617, accuracy: 0.941406\n",
      "Training loss: 0.168312, accuracy: 0.949219\n",
      "Training loss: 0.156475, accuracy: 0.960938\n",
      "Training loss: 0.145839, accuracy: 0.960938\n",
      "Training loss: 0.12353, accuracy: 0.960938\n",
      "Training loss: 0.11434, accuracy: 0.96875\n",
      "Training loss: 0.0931271, accuracy: 0.976563\n",
      "Training loss: 0.0901664, accuracy: 0.972656\n",
      "Training loss: 0.0718981, accuracy: 0.980469\n",
      "Training loss: 0.065165, accuracy: 0.988281\n",
      "Training loss: 0.06828, accuracy: 0.984375\n",
      "Training loss: 0.0549482, accuracy: 0.988281\n",
      "Training loss: 0.0482764, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.317347, accuracy: 0.898438\n",
      "Training loss: 0.265377, accuracy: 0.910156\n",
      "Training loss: 0.218858, accuracy: 0.929688\n",
      "Training loss: 0.196596, accuracy: 0.941406\n",
      "Training loss: 0.174095, accuracy: 0.953125\n",
      "Training loss: 0.15305, accuracy: 0.964844\n",
      "Training loss: 0.135896, accuracy: 0.972656\n",
      "Training loss: 0.122807, accuracy: 0.972656\n",
      "Training loss: 0.107645, accuracy: 0.972656\n",
      "Training loss: 0.0993517, accuracy: 0.976563\n",
      "Training loss: 0.0940704, accuracy: 0.984375\n",
      "Training loss: 0.0822016, accuracy: 0.984375\n",
      "Training loss: 0.0781378, accuracy: 0.980469\n",
      "Training loss: 0.0783373, accuracy: 0.984375\n",
      "Training loss: 0.0776403, accuracy: 0.984375\n",
      "Training loss: 0.0688954, accuracy: 0.984375\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.205093, accuracy: 0.941406\n",
      "Training loss: 0.16896, accuracy: 0.949219\n",
      "Training loss: 0.136665, accuracy: 0.957031\n",
      "Training loss: 0.123493, accuracy: 0.964844\n",
      "Training loss: 0.11307, accuracy: 0.964844\n",
      "Training loss: 0.0994983, accuracy: 0.972656\n",
      "Training loss: 0.0889653, accuracy: 0.980469\n",
      "Training loss: 0.0846754, accuracy: 0.976563\n",
      "Training loss: 0.0812634, accuracy: 0.980469\n",
      "Training loss: 0.0709496, accuracy: 0.984375\n",
      "Training loss: 0.0680541, accuracy: 0.984375\n",
      "Training loss: 0.0657943, accuracy: 0.988281\n",
      "Training loss: 0.0621196, accuracy: 0.988281\n",
      "Training loss: 0.0627078, accuracy: 0.988281\n",
      "Training loss: 0.0588161, accuracy: 0.988281\n",
      "Training loss: 0.0512031, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.275058, accuracy: 0.9375\n",
      "Training loss: 0.217343, accuracy: 0.941406\n",
      "Training loss: 0.175152, accuracy: 0.957031\n",
      "Training loss: 0.142779, accuracy: 0.960938\n",
      "Training loss: 0.131306, accuracy: 0.964844\n",
      "Training loss: 0.119429, accuracy: 0.96875\n",
      "Training loss: 0.104834, accuracy: 0.96875\n",
      "Training loss: 0.0963058, accuracy: 0.972656\n",
      "Training loss: 0.0902958, accuracy: 0.976563\n",
      "Training loss: 0.0702908, accuracy: 0.984375\n",
      "Training loss: 0.0620312, accuracy: 0.984375\n",
      "Training loss: 0.0554716, accuracy: 0.992188\n",
      "Training loss: 0.0448721, accuracy: 0.992188\n",
      "Training loss: 0.0447241, accuracy: 0.992188\n",
      "Training loss: 0.0393645, accuracy: 0.992188\n",
      "Training loss: 0.0319182, accuracy: 0.992188\n",
      "----------------- Step 230: validation accuracy 0.82384 ----------------\n",
      "Training loss: 0.189103, accuracy: 0.945313\n",
      "Training loss: 0.152789, accuracy: 0.945313\n",
      "Training loss: 0.114163, accuracy: 0.957031\n",
      "Training loss: 0.106454, accuracy: 0.964844\n",
      "Training loss: 0.0791326, accuracy: 0.972656\n",
      "Training loss: 0.0607508, accuracy: 0.988281\n",
      "Training loss: 0.0572242, accuracy: 0.988281\n",
      "Training loss: 0.049607, accuracy: 0.988281\n",
      "Training loss: 0.0482651, accuracy: 0.992188\n",
      "Training loss: 0.0369253, accuracy: 1.0\n",
      "Training loss: 0.0283017, accuracy: 1.0\n",
      "Training loss: 0.0257718, accuracy: 1.0\n",
      "Training loss: 0.0256811, accuracy: 1.0\n",
      "Training loss: 0.0238261, accuracy: 1.0\n",
      "Training loss: 0.0192476, accuracy: 1.0\n",
      "Training loss: 0.0184631, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.193214, accuracy: 0.929688\n",
      "Training loss: 0.1501, accuracy: 0.945313\n",
      "Training loss: 0.144262, accuracy: 0.964844\n",
      "Training loss: 0.0977481, accuracy: 0.976563\n",
      "Training loss: 0.0870765, accuracy: 0.976563\n",
      "Training loss: 0.0699783, accuracy: 0.976563\n",
      "Training loss: 0.0556478, accuracy: 0.980469\n",
      "Training loss: 0.0445606, accuracy: 0.992188\n",
      "Training loss: 0.0373041, accuracy: 0.992188\n",
      "Training loss: 0.026722, accuracy: 0.996094\n",
      "Training loss: 0.0297841, accuracy: 0.996094\n",
      "Training loss: 0.0258823, accuracy: 0.996094\n",
      "Training loss: 0.0293703, accuracy: 0.996094\n",
      "Training loss: 0.0222675, accuracy: 0.996094\n",
      "Training loss: 0.0155092, accuracy: 0.996094\n",
      "Training loss: 0.0141076, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.164778, accuracy: 0.953125\n",
      "Training loss: 0.165618, accuracy: 0.957031\n",
      "Training loss: 0.129062, accuracy: 0.964844\n",
      "Training loss: 0.121407, accuracy: 0.96875\n",
      "Training loss: 0.0994134, accuracy: 0.976563\n",
      "Training loss: 0.0867689, accuracy: 0.980469\n",
      "Training loss: 0.0788761, accuracy: 0.980469\n",
      "Training loss: 0.0590528, accuracy: 0.984375\n",
      "Training loss: 0.0467238, accuracy: 0.988281\n",
      "Training loss: 0.0485, accuracy: 0.988281\n",
      "Training loss: 0.0374138, accuracy: 0.988281\n",
      "Training loss: 0.0270217, accuracy: 0.996094\n",
      "Training loss: 0.0237577, accuracy: 0.992188\n",
      "Training loss: 0.0196456, accuracy: 0.996094\n",
      "Training loss: 0.0168427, accuracy: 0.996094\n",
      "Training loss: 0.01017, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.270607, accuracy: 0.914063\n",
      "Training loss: 0.239453, accuracy: 0.921875\n",
      "Training loss: 0.205017, accuracy: 0.945313\n",
      "Training loss: 0.163158, accuracy: 0.9375\n",
      "Training loss: 0.130547, accuracy: 0.972656\n",
      "Training loss: 0.117187, accuracy: 0.96875\n",
      "Training loss: 0.0789819, accuracy: 0.976563\n",
      "Training loss: 0.0606839, accuracy: 0.992188\n",
      "Training loss: 0.0518631, accuracy: 0.988281\n",
      "Training loss: 0.0581187, accuracy: 0.984375\n",
      "Training loss: 0.0544195, accuracy: 0.992188\n",
      "Training loss: 0.0477408, accuracy: 0.992188\n",
      "Training loss: 0.0433553, accuracy: 0.992188\n",
      "Training loss: 0.0412964, accuracy: 0.992188\n",
      "Training loss: 0.0454314, accuracy: 0.992188\n",
      "Training loss: 0.0388301, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.175538, accuracy: 0.945313\n",
      "Training loss: 0.141873, accuracy: 0.949219\n",
      "Training loss: 0.0928047, accuracy: 0.972656\n",
      "Training loss: 0.0891642, accuracy: 0.964844\n",
      "Training loss: 0.0580666, accuracy: 0.976563\n",
      "Training loss: 0.0727537, accuracy: 0.976563\n",
      "Training loss: 0.0660247, accuracy: 0.976563\n",
      "Training loss: 0.046833, accuracy: 0.984375\n",
      "Training loss: 0.0661495, accuracy: 0.976563\n",
      "Training loss: 0.0347474, accuracy: 0.996094\n",
      "Training loss: 0.0306197, accuracy: 0.996094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.030126, accuracy: 0.996094\n",
      "Training loss: 0.024158, accuracy: 0.996094\n",
      "Training loss: 0.0263785, accuracy: 0.996094\n",
      "Training loss: 0.0211942, accuracy: 0.996094\n",
      "Training loss: 0.01955, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.0925799, accuracy: 0.976563\n",
      "Training loss: 0.0847029, accuracy: 0.984375\n",
      "Training loss: 0.0851921, accuracy: 0.984375\n",
      "Training loss: 0.0509463, accuracy: 0.992188\n",
      "Training loss: 0.0439558, accuracy: 0.992188\n",
      "Training loss: 0.0420916, accuracy: 0.992188\n",
      "Training loss: 0.030655, accuracy: 0.992188\n",
      "Training loss: 0.0322526, accuracy: 0.996094\n",
      "Training loss: 0.0271083, accuracy: 0.996094\n",
      "Training loss: 0.0282397, accuracy: 0.996094\n",
      "Training loss: 0.0251361, accuracy: 0.996094\n",
      "Training loss: 0.0275345, accuracy: 0.996094\n",
      "Training loss: 0.0205703, accuracy: 0.996094\n",
      "Training loss: 0.0263338, accuracy: 0.996094\n",
      "Training loss: 0.0255114, accuracy: 0.996094\n",
      "Training loss: 0.0242025, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.0736029, accuracy: 0.96875\n",
      "Training loss: 0.06901, accuracy: 0.976563\n",
      "Training loss: 0.0606669, accuracy: 0.980469\n",
      "Training loss: 0.0461123, accuracy: 0.988281\n",
      "Training loss: 0.0282439, accuracy: 0.988281\n",
      "Training loss: 0.0249415, accuracy: 0.992188\n",
      "Training loss: 0.0149602, accuracy: 0.996094\n",
      "Training loss: 0.0125229, accuracy: 0.996094\n",
      "Training loss: 0.0143783, accuracy: 0.996094\n",
      "Training loss: 0.010254, accuracy: 1.0\n",
      "Training loss: 0.0141709, accuracy: 1.0\n",
      "Training loss: 0.0128723, accuracy: 1.0\n",
      "Training loss: 0.00862762, accuracy: 1.0\n",
      "Training loss: 0.00789229, accuracy: 1.0\n",
      "Training loss: 0.00779276, accuracy: 1.0\n",
      "Training loss: 0.00629828, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.106344, accuracy: 0.964844\n",
      "Training loss: 0.0702113, accuracy: 0.984375\n",
      "Training loss: 0.0798599, accuracy: 0.976563\n",
      "Training loss: 0.0613615, accuracy: 0.984375\n",
      "Training loss: 0.0456363, accuracy: 0.992188\n",
      "Training loss: 0.0456454, accuracy: 0.988281\n",
      "Training loss: 0.0445404, accuracy: 0.992188\n",
      "Training loss: 0.034513, accuracy: 0.992188\n",
      "Training loss: 0.0290339, accuracy: 0.992188\n",
      "Training loss: 0.0293961, accuracy: 0.992188\n",
      "Training loss: 0.035044, accuracy: 0.992188\n",
      "Training loss: 0.0226773, accuracy: 0.992188\n",
      "Training loss: 0.0282626, accuracy: 0.992188\n",
      "Training loss: 0.0164318, accuracy: 0.996094\n",
      "Training loss: 0.0146372, accuracy: 0.996094\n",
      "Training loss: 0.0210062, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.149088, accuracy: 0.953125\n",
      "Training loss: 0.137719, accuracy: 0.960938\n",
      "Training loss: 0.115029, accuracy: 0.96875\n",
      "Training loss: 0.080348, accuracy: 0.980469\n",
      "Training loss: 0.0685975, accuracy: 0.984375\n",
      "Training loss: 0.060539, accuracy: 0.984375\n",
      "Training loss: 0.0550477, accuracy: 0.980469\n",
      "Training loss: 0.0302742, accuracy: 0.992188\n",
      "Training loss: 0.0274268, accuracy: 0.992188\n",
      "Training loss: 0.0242061, accuracy: 0.992188\n",
      "Training loss: 0.0246118, accuracy: 0.988281\n",
      "Training loss: 0.0136631, accuracy: 1.0\n",
      "Training loss: 0.010852, accuracy: 1.0\n",
      "Training loss: 0.00835813, accuracy: 1.0\n",
      "Training loss: 0.00704879, accuracy: 1.0\n",
      "Training loss: 0.00629068, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.169345, accuracy: 0.953125\n",
      "Training loss: 0.120688, accuracy: 0.957031\n",
      "Training loss: 0.0662678, accuracy: 0.980469\n",
      "Training loss: 0.0609094, accuracy: 0.984375\n",
      "Training loss: 0.0316216, accuracy: 0.996094\n",
      "Training loss: 0.017725, accuracy: 0.992188\n",
      "Training loss: 0.0226375, accuracy: 0.996094\n",
      "Training loss: 0.011156, accuracy: 0.996094\n",
      "Training loss: 0.0211705, accuracy: 0.996094\n",
      "Training loss: 0.0327854, accuracy: 0.988281\n",
      "Training loss: 0.0616177, accuracy: 0.972656\n",
      "Training loss: 0.0496011, accuracy: 0.976563\n",
      "Training loss: 0.02536, accuracy: 0.992188\n",
      "Training loss: 0.0286207, accuracy: 0.992188\n",
      "Training loss: 0.0153435, accuracy: 1.0\n",
      "Training loss: 0.012199, accuracy: 1.0\n",
      "----------------- Step 240: validation accuracy 0.81792 ----------------\n",
      "Training loss: 0.214916, accuracy: 0.9375\n",
      "Training loss: 0.176262, accuracy: 0.945313\n",
      "Training loss: 0.187283, accuracy: 0.945313\n",
      "Training loss: 0.149759, accuracy: 0.953125\n",
      "Training loss: 0.117149, accuracy: 0.960938\n",
      "Training loss: 0.086574, accuracy: 0.976563\n",
      "Training loss: 0.063883, accuracy: 0.984375\n",
      "Training loss: 0.0577372, accuracy: 0.980469\n",
      "Training loss: 0.0522219, accuracy: 0.988281\n",
      "Training loss: 0.0478164, accuracy: 0.988281\n",
      "Training loss: 0.0311957, accuracy: 0.992188\n",
      "Training loss: 0.0384863, accuracy: 0.992188\n",
      "Training loss: 0.0302455, accuracy: 0.996094\n",
      "Training loss: 0.0371885, accuracy: 0.992188\n",
      "Training loss: 0.0282103, accuracy: 0.996094\n",
      "Training loss: 0.0219352, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.298195, accuracy: 0.917969\n",
      "Training loss: 0.245057, accuracy: 0.941406\n",
      "Training loss: 0.146631, accuracy: 0.960938\n",
      "Training loss: 0.113402, accuracy: 0.96875\n",
      "Training loss: 0.0929876, accuracy: 0.976563\n",
      "Training loss: 0.0867849, accuracy: 0.976563\n",
      "Training loss: 0.0705734, accuracy: 0.984375\n",
      "Training loss: 0.0656784, accuracy: 0.984375\n",
      "Training loss: 0.0518466, accuracy: 0.992188\n",
      "Training loss: 0.039085, accuracy: 0.992188\n",
      "Training loss: 0.0369657, accuracy: 0.992188\n",
      "Training loss: 0.0245883, accuracy: 0.992188\n",
      "Training loss: 0.020724, accuracy: 0.996094\n",
      "Training loss: 0.0149575, accuracy: 1.0\n",
      "Training loss: 0.0136221, accuracy: 1.0\n",
      "Training loss: 0.0109457, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.150577, accuracy: 0.941406\n",
      "Training loss: 0.153489, accuracy: 0.941406\n",
      "Training loss: 0.119573, accuracy: 0.960938\n",
      "Training loss: 0.101429, accuracy: 0.976563\n",
      "Training loss: 0.0908332, accuracy: 0.96875\n",
      "Training loss: 0.0839816, accuracy: 0.96875\n",
      "Training loss: 0.0613188, accuracy: 0.980469\n",
      "Training loss: 0.043297, accuracy: 0.988281\n",
      "Training loss: 0.036991, accuracy: 0.996094\n",
      "Training loss: 0.0330564, accuracy: 0.992188\n",
      "Training loss: 0.0345375, accuracy: 0.988281\n",
      "Training loss: 0.0231764, accuracy: 0.996094\n",
      "Training loss: 0.023892, accuracy: 0.992188\n",
      "Training loss: 0.0160148, accuracy: 0.996094\n",
      "Training loss: 0.022039, accuracy: 0.996094\n",
      "Training loss: 0.0142859, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.147826, accuracy: 0.945313\n",
      "Training loss: 0.12174, accuracy: 0.941406\n",
      "Training loss: 0.0880322, accuracy: 0.964844\n",
      "Training loss: 0.0588233, accuracy: 0.980469\n",
      "Training loss: 0.0585044, accuracy: 0.984375\n",
      "Training loss: 0.045904, accuracy: 0.984375\n",
      "Training loss: 0.0280024, accuracy: 0.992188\n",
      "Training loss: 0.0231087, accuracy: 0.992188\n",
      "Training loss: 0.0233412, accuracy: 0.996094\n",
      "Training loss: 0.0182441, accuracy: 1.0\n",
      "Training loss: 0.0183896, accuracy: 0.996094\n",
      "Training loss: 0.0163867, accuracy: 0.996094\n",
      "Training loss: 0.0135602, accuracy: 1.0\n",
      "Training loss: 0.0111129, accuracy: 1.0\n",
      "Training loss: 0.018011, accuracy: 0.996094\n",
      "Training loss: 0.00859603, accuracy: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.115217, accuracy: 0.96875\n",
      "Training loss: 0.112524, accuracy: 0.960938\n",
      "Training loss: 0.0935568, accuracy: 0.976563\n",
      "Training loss: 0.0886973, accuracy: 0.984375\n",
      "Training loss: 0.0714985, accuracy: 0.980469\n",
      "Training loss: 0.0769337, accuracy: 0.984375\n",
      "Training loss: 0.0626674, accuracy: 0.988281\n",
      "Training loss: 0.0605938, accuracy: 0.988281\n",
      "Training loss: 0.0528452, accuracy: 0.988281\n",
      "Training loss: 0.0423013, accuracy: 0.992188\n",
      "Training loss: 0.0458322, accuracy: 0.992188\n",
      "Training loss: 0.0420135, accuracy: 0.992188\n",
      "Training loss: 0.0408307, accuracy: 0.992188\n",
      "Training loss: 0.0374855, accuracy: 0.992188\n",
      "Training loss: 0.0347271, accuracy: 0.992188\n",
      "Training loss: 0.0283331, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.312259, accuracy: 0.917969\n",
      "Training loss: 0.252735, accuracy: 0.921875\n",
      "Training loss: 0.185892, accuracy: 0.9375\n",
      "Training loss: 0.139919, accuracy: 0.964844\n",
      "Training loss: 0.131939, accuracy: 0.964844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.119486, accuracy: 0.960938\n",
      "Training loss: 0.0955361, accuracy: 0.972656\n",
      "Training loss: 0.102085, accuracy: 0.972656\n",
      "Training loss: 0.0758498, accuracy: 0.976563\n",
      "Training loss: 0.0779579, accuracy: 0.980469\n",
      "Training loss: 0.0598346, accuracy: 0.988281\n",
      "Training loss: 0.0637367, accuracy: 0.984375\n",
      "Training loss: 0.0615871, accuracy: 0.988281\n",
      "Training loss: 0.0556784, accuracy: 0.992188\n",
      "Training loss: 0.0447465, accuracy: 0.992188\n",
      "Training loss: 0.0506967, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.158547, accuracy: 0.953125\n",
      "Training loss: 0.161928, accuracy: 0.953125\n",
      "Training loss: 0.141728, accuracy: 0.960938\n",
      "Training loss: 0.131251, accuracy: 0.96875\n",
      "Training loss: 0.113114, accuracy: 0.976563\n",
      "Training loss: 0.103514, accuracy: 0.976563\n",
      "Training loss: 0.0983755, accuracy: 0.972656\n",
      "Training loss: 0.0765239, accuracy: 0.984375\n",
      "Training loss: 0.0692936, accuracy: 0.984375\n",
      "Training loss: 0.0640931, accuracy: 0.984375\n",
      "Training loss: 0.0557164, accuracy: 0.988281\n",
      "Training loss: 0.0602943, accuracy: 0.984375\n",
      "Training loss: 0.0433753, accuracy: 0.988281\n",
      "Training loss: 0.0421667, accuracy: 0.992188\n",
      "Training loss: 0.04568, accuracy: 0.992188\n",
      "Training loss: 0.0431361, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.21959, accuracy: 0.929688\n",
      "Training loss: 0.163633, accuracy: 0.945313\n",
      "Training loss: 0.142178, accuracy: 0.953125\n",
      "Training loss: 0.112387, accuracy: 0.964844\n",
      "Training loss: 0.0754817, accuracy: 0.976563\n",
      "Training loss: 0.0670661, accuracy: 0.980469\n",
      "Training loss: 0.063261, accuracy: 0.984375\n",
      "Training loss: 0.0520261, accuracy: 0.992188\n",
      "Training loss: 0.0505775, accuracy: 0.992188\n",
      "Training loss: 0.0517745, accuracy: 0.984375\n",
      "Training loss: 0.0511181, accuracy: 0.992188\n",
      "Training loss: 0.0498518, accuracy: 0.992188\n",
      "Training loss: 0.0493809, accuracy: 0.992188\n",
      "Training loss: 0.0463219, accuracy: 0.992188\n",
      "Training loss: 0.0458292, accuracy: 0.992188\n",
      "Training loss: 0.0434457, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.129835, accuracy: 0.957031\n",
      "Training loss: 0.0885772, accuracy: 0.972656\n",
      "Training loss: 0.0668443, accuracy: 0.980469\n",
      "Training loss: 0.0487942, accuracy: 0.992188\n",
      "Training loss: 0.0491146, accuracy: 0.984375\n",
      "Training loss: 0.0390178, accuracy: 0.996094\n",
      "Training loss: 0.0372598, accuracy: 0.996094\n",
      "Training loss: 0.0359766, accuracy: 0.996094\n",
      "Training loss: 0.0325204, accuracy: 0.996094\n",
      "Training loss: 0.0334375, accuracy: 0.996094\n",
      "Training loss: 0.0272633, accuracy: 0.996094\n",
      "Training loss: 0.0298989, accuracy: 0.996094\n",
      "Training loss: 0.0278068, accuracy: 0.996094\n",
      "Training loss: 0.0251851, accuracy: 0.996094\n",
      "Training loss: 0.023177, accuracy: 0.996094\n",
      "Training loss: 0.018661, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.0790458, accuracy: 0.96875\n",
      "Training loss: 0.0505413, accuracy: 0.984375\n",
      "Training loss: 0.0407926, accuracy: 0.992188\n",
      "Training loss: 0.0311237, accuracy: 0.992188\n",
      "Training loss: 0.0268108, accuracy: 0.996094\n",
      "Training loss: 0.0230635, accuracy: 0.996094\n",
      "Training loss: 0.0194023, accuracy: 0.996094\n",
      "Training loss: 0.0218608, accuracy: 0.996094\n",
      "Training loss: 0.0180147, accuracy: 0.996094\n",
      "Training loss: 0.0155663, accuracy: 0.996094\n",
      "Training loss: 0.0138858, accuracy: 0.996094\n",
      "Training loss: 0.0117505, accuracy: 0.996094\n",
      "Training loss: 0.0108728, accuracy: 0.996094\n",
      "Training loss: 0.00867648, accuracy: 1.0\n",
      "Training loss: 0.00851429, accuracy: 1.0\n",
      "Training loss: 0.00792782, accuracy: 1.0\n",
      "----------------- Step 250: validation accuracy 0.83168 ----------------\n",
      "Training loss: 0.140915, accuracy: 0.949219\n",
      "Training loss: 0.143376, accuracy: 0.949219\n",
      "Training loss: 0.109554, accuracy: 0.96875\n",
      "Training loss: 0.0940255, accuracy: 0.976563\n",
      "Training loss: 0.0850104, accuracy: 0.980469\n",
      "Training loss: 0.0798382, accuracy: 0.980469\n",
      "Training loss: 0.0677266, accuracy: 0.984375\n",
      "Training loss: 0.0624697, accuracy: 0.984375\n",
      "Training loss: 0.0544927, accuracy: 0.984375\n",
      "Training loss: 0.0518941, accuracy: 0.988281\n",
      "Training loss: 0.0502608, accuracy: 0.988281\n",
      "Training loss: 0.0438485, accuracy: 0.988281\n",
      "Training loss: 0.0424682, accuracy: 0.988281\n",
      "Training loss: 0.0428047, accuracy: 0.988281\n",
      "Training loss: 0.0402891, accuracy: 0.988281\n",
      "Training loss: 0.0330697, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.139955, accuracy: 0.964844\n",
      "Training loss: 0.118365, accuracy: 0.96875\n",
      "Training loss: 0.0841282, accuracy: 0.984375\n",
      "Training loss: 0.0847053, accuracy: 0.980469\n",
      "Training loss: 0.068741, accuracy: 0.988281\n",
      "Training loss: 0.0573334, accuracy: 0.988281\n",
      "Training loss: 0.0524463, accuracy: 0.988281\n",
      "Training loss: 0.0504373, accuracy: 0.992188\n",
      "Training loss: 0.0499113, accuracy: 0.992188\n",
      "Training loss: 0.0491127, accuracy: 0.992188\n",
      "Training loss: 0.0440869, accuracy: 0.992188\n",
      "Training loss: 0.0464011, accuracy: 0.992188\n",
      "Training loss: 0.0435006, accuracy: 0.992188\n",
      "Training loss: 0.0445884, accuracy: 0.992188\n",
      "Training loss: 0.0451819, accuracy: 0.992188\n",
      "Training loss: 0.0385502, accuracy: 0.992188\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.137805, accuracy: 0.953125\n",
      "Training loss: 0.118474, accuracy: 0.960938\n",
      "Training loss: 0.114784, accuracy: 0.972656\n",
      "Training loss: 0.111955, accuracy: 0.980469\n",
      "Training loss: 0.110242, accuracy: 0.972656\n",
      "Training loss: 0.0966699, accuracy: 0.976563\n",
      "Training loss: 0.101069, accuracy: 0.976563\n",
      "Training loss: 0.0772635, accuracy: 0.980469\n",
      "Training loss: 0.0837338, accuracy: 0.980469\n",
      "Training loss: 0.0792774, accuracy: 0.980469\n",
      "Training loss: 0.0744779, accuracy: 0.980469\n",
      "Training loss: 0.0590653, accuracy: 0.984375\n",
      "Training loss: 0.0596867, accuracy: 0.984375\n",
      "Training loss: 0.0554088, accuracy: 0.984375\n",
      "Training loss: 0.0453157, accuracy: 0.988281\n",
      "Training loss: 0.0439753, accuracy: 0.988281\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.0890709, accuracy: 0.964844\n",
      "Training loss: 0.0891567, accuracy: 0.964844\n",
      "Training loss: 0.070295, accuracy: 0.976563\n",
      "Training loss: 0.0664796, accuracy: 0.980469\n",
      "Training loss: 0.0659721, accuracy: 0.976563\n",
      "Training loss: 0.0488241, accuracy: 0.984375\n",
      "Training loss: 0.0434535, accuracy: 0.992188\n",
      "Training loss: 0.0422138, accuracy: 0.992188\n",
      "Training loss: 0.0448725, accuracy: 0.988281\n",
      "Training loss: 0.0402543, accuracy: 0.992188\n",
      "Training loss: 0.0432589, accuracy: 0.992188\n",
      "Training loss: 0.0372704, accuracy: 0.992188\n",
      "Training loss: 0.0342151, accuracy: 0.992188\n",
      "Training loss: 0.0333013, accuracy: 0.996094\n",
      "Training loss: 0.0353927, accuracy: 0.996094\n",
      "Training loss: 0.024724, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n",
      "Training loss: 0.129035, accuracy: 0.964844\n",
      "Training loss: 0.137467, accuracy: 0.957031\n",
      "Training loss: 0.0984745, accuracy: 0.976563\n",
      "Training loss: 0.0933649, accuracy: 0.976563\n",
      "Training loss: 0.0663128, accuracy: 0.984375\n",
      "Training loss: 0.0574161, accuracy: 0.984375\n",
      "Training loss: 0.0544887, accuracy: 0.988281\n",
      "Training loss: 0.0419344, accuracy: 0.992188\n",
      "Training loss: 0.056439, accuracy: 0.992188\n",
      "Training loss: 0.0571946, accuracy: 0.988281\n",
      "Training loss: 0.0391979, accuracy: 0.992188\n",
      "Training loss: 0.0472936, accuracy: 0.992188\n",
      "Training loss: 0.0452774, accuracy: 0.992188\n",
      "Training loss: 0.0378181, accuracy: 0.992188\n",
      "Training loss: 0.0349807, accuracy: 0.992188\n",
      "Training loss: 0.0246785, accuracy: 0.996094\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lstm_model.train_model(steps=16, epochs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
